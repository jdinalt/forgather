[tokenizer]
tokenizer: &tokenizer !call:forgather:from_project

[model_args]
model_args: &model_args !call:torchtitan.models.llama3.model.args:TransformerModelArgs
    vocab_size: !call:len [ *tokenizer ]
    eos_id: !call:getattr [ *tokenizer, 'eos_token_id' ]
    max_seq_len: !call:getattr [ *tokenizer, "model_max_length" ]

[model_factory]
model_factory: &model_factory !partial:torchtitan.models.llama3.model.model:Transformer
    model_args: *model_args

[parallelize_fn]
parallelize_fn: &parallelize_fn !partial:torchtitan.models.llama3.infra.parallelize:parallelize_llama

[pipeline_fn]
pipeline_fn: &pipeline_fn !partial:torchtitan.models.llama3.infra.pipeline:pipeline_llama

[loss_fn]
loss_fn: &loss_fn !call:forgather.ml.loss:CausalLoss

[state_dict_adapter]
state_dict_adapter: &state_dict_adapter !call:torchtitan.models.llama3.model.state_dict_adapter:Llama3StateDictAdapter
    model_args: *model_args
    hf_assets_path: null