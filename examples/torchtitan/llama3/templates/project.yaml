-- extends "projects/base_titan.yaml"
## This is mostly derived from the Torch Titan Llama3 debug model, for defaults
[config_metadata]
    == super()
    -- set ns.config_name = "Llama3"
    -- set ns.config_description = "Llama 3 Torch Titan project"
    -- set ns.model_name = "llam3"

[profiling]
=> super()
    enable_profiling: False
    save_traces_folder: "profile_trace"
    profile_freq: 10
    enable_memory_snapshot: False
    save_memory_snapshot_folder: "memory_snapshot"

[metrics]
=> super()
    log_freq: 1
    disable_color_printing: False
    enable_tensorboard: False
    save_tb_folder: "{{ ns.logging_dir }}"
    enable_wandb: False

[model]
=> super()
    name: "llama3"
    ## Presently requires mantually construction via 'forgather -t titain_128k.yaml construct'
    ## TODO: Setup automatic build trigger
    hf_assets_path: "{{ joinpath(ns.tokenizers_dir, "wikitext_titan_128k") }}"

[optimizer]
=> super()
    name: "AdamW"
    lr: !!float 8e-4
    eps: !!float 1e-8

[lr_scheduler]
=> super()
    warmup_steps: 2  # lr scheduler warm up, normally 20% of the train steps
    decay_ratio: 0.8  # lr scheduler decay ratio, 80% of the train steps
    decay_type: "linear"
    min_lr_factor: 0.0

[training]
=> super()
    local_batch_size: 8
    seq_len: 2048
    max_norm: 1.0
    steps: 10
    dataset: "c4"

[parallelism]
=> super()
    data_parallel_replicate_degree: 1
    data_parallel_shard_degree: -1
    fsdp_reshard_after_forward: "default" # default / never / always
    tensor_parallel_degree: 1
    enable_async_tensor_parallel: False
    pipeline_parallel_degree: 1
    context_parallel_degree: 1

[checkpoint]
=> super()
    enable: False
    folder: "checkpoint"
    interval: 10
    last_save_model_only: False
    export_dtype: "float32"
    async_mode: "disabled" # ["disabled", "async", "async_with_pinned_mem"]

[activation_checkpoint]
=> super()
    mode: "selective" # ["none", "selective", "full"]
    selective_ac_option: '2'  # 'int' = ac every positive int layer or 'op', ac based on ops policy

[compile]
=> super()
    enable: False
    components: ["model", "loss"]

[float8]
=> super()
    enable_fsdp_float8_all_gather: False
    precompute_float8_dynamic_scale_for_fsdp: False
    filter_fqns: ["output"]

[validation]
=> super()
    enable: False
    dataset: "c4_validation"
    freq: 5
    steps: 10