-- extends 'project.yaml'

[config_metadata]
    == super()
    ## Overrides
    -- set ns.config_name = "Hugginface Llama"
    -- set ns.config_description = "Train with HF LLama implementation for comparison"
    -- set ns.model_name = "hf_llama"

## Replace the model definition
[construct_new_model]
    -- include "config.model_config"

#-------------------- config.model_config --------------------
-- extends 'models/transformers/llama.yaml'

[model_tokenizer]
## Replace the default Llama tokenizer with the tiny_2k tokenizer.
    -- include 'tokenizers/tiny_2k.yaml'

## Make the model much smaller.
[model_config]
    == super()
    # Tiny Llama overrides
    hidden_size: 256
    intermediate_size: 1024
    num_attention_heads: 2
    num_key_value_heads: 2
    num_hidden_layers: 4
