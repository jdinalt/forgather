-- extends 'models/transformers/llama.yaml'


-- block model_tokenizer
## Replace the default Llama tokenizer with the tiny_2k tokenizer.
    -- include 'tokenizers/tiny_2k.yaml'
<< endblock model_tokenizer


## Make the model much smaller.
-- block model_config
    == super()

    # Tiny Llama overrides
    hidden_size: 256
    intermediate_size: 1024
    num_attention_heads: 2
    num_key_value_heads: 2
    num_hidden_layers: 4
<< endblock model_config


