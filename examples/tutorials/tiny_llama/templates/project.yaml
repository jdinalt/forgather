-- extends "training_script/causal_lm/causal_lm.yaml"

[config_metadata]
    == super()
    ## Overrides
    -- set ns.config_name = "Tiny Llama"
    -- set ns.config_description = "A demo of training a tiny llama model from scratch"
    -- set ns.model_name = "tiny_llama"

    ## This will trigger a save at the end of training; this is in addtion to the checkpoint settings.
    -- set ns.do_save = True

    ## The dataset sub-project to use
    -- set ns.dataset_proj = joinpath(ns.forgather_dir, 'examples', 'datasets', 'roneneldan')

    ## The configuration in the dataset sub-project
    -- set ns.dataset_config = "tinystories-abridged.yaml"

    ## Set predefined model project to import
    -- set ns.model_project_dir = joinpath(ns.forgather_dir, "examples", 'models', "llama")
    
    ## Select 4 million parameter Llama model
    ## Others definitions: 117M.yaml, 7B.yaml
    -- set ns.model_project_config = "4M.yaml"

[datasets_preprocessor_args]
tokenizer_args: &tokenizer_args !dict
    truncation: True
    max_length: 512

## Pull dataset loader from template definition
[datasets_definition]
    -- include 'datasets/llm_dataset_project.yaml'

## This includes an inline template, defined below.
## The need to do this relates to Jinja2 disallowing a template from
## directly having more than one parent template. We can get around 
## this limitation by extending in 'project.model_config' and including
## the resulting template.
[construct_new_model]
    -- include "models/causal_lm/import_model_project.yaml"

## Definition is inlined, below.
[trainer_definition]
    -- include 'project.trainer_config'

## Override loggers
[trainer_callbacks]
    -- include 'project.logger_config'

## Explicitly set the optimizer.
[optimizer]
optimizer: &optimizer !partial:torch:optim.AdamW
    lr: 1.0e-3

## Override the default LR Scheduler
[lr_scheduler]
# https://arxiv.org/html/2503.02844v1
lr_scheduler: &lr_scheduler !lambda:forgather.ml.optim.infinite_lr_scheduler:InfiniteLRScheduler@lr_scheduler
    warmup_steps: 500
    cooldown_steps: 50000
    constant_lr: 1.0e-4

[datacollator]
    == super()
    # Tiny Llama
    ## Limit maximum sequence length 512 tokens, at the data-collator level.
    truncation: True
    max_length: 512

[main_output]
    == super()
    ## This will trigger saving the model weights in the output directory at end.
    ## We normally would just use checkpointin (see save_strategy), but this saves
    ## the weights in a "checkpoints" sub-directory. For the tutorial, we would like
    ## to be able to just load the model with .from_pretrained() at the end, which 
    ## requires saving the weights directly in the model directory.
    ## TODO: Find a good way to not have to use this kludge!
    do_save: True

#-------------------- project.model_config --------------------
-- extends "models/tiny_dynamic_llama.yaml"
## Project can override values here...


#-------------------- project.trainer_config --------------------
-- extends 'trainers/trainer.yaml'

[trainer_args]
    == super()
    # Tiny Llama Project Overrides
    eval_strategy: "steps"
    save_strategy: "{{ save_strategy | default('steps') }}"
    save_steps: 10000
    # Safetensors can't handle tied parameters/buffers, so fallback to PyTorch format.
    save_safetensors: False
    seed: 42
    per_device_train_batch_size: 32
    per_device_eval_batch_size: 64
    logging_steps: 100
    eval_steps: 500
    num_train_epochs: 1
    dataloader_num_workers: 1

#-------------------- project.logger_config --------------------
-- extends 'callbacks/loggers.yaml'
## Add experiment loggers to the callbacks list.
## The parent creates a Tensor Board SummaryWriter, which we can use.

## This adds a text-generationn sample every 'generation_steps'
[callback_list]
    -- include 'prompts/tiny_stories.yaml'

    == super()
    text_gen_callback: !singleton:forgather.ml.trainer.callbacks:TextgenCallback
        summary_writer: *summary_writer
        prompts: *testprompts
        generation_config: *generation_config
        max_new_tokens: 40
        generation_steps: 1000
    
    # Allow remote control of the training process
    trainer_control: !singleton:forgather.ml.trainer.callbacks:TrainerControlCallback