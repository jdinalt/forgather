-- extends 'project.yaml'

[config_metadata]
    == super()
    -- set ns.config_name = "AdamW32"
    -- set ns.config_description = "Train in full float32 with AdamW"
    -- set ns.model_name = "adamw32"

[trainer_args]
    == super()
    default_dtype: "float32"

[optimizer]
optimizer: &optimizer !partial:torch.optim:AdamW
    lr: {{ (ns.base_learning_rate * ns.lr_scale) | toyaml }}
