{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e422f35-7a08-4a50-a075-51a68b5c3994",
   "metadata": {},
   "source": [
    "# Project Index\n",
    "\n",
    "[Custom Model Notebook](../../../notebooks/custom_model.ipynb)  \n",
    "[Training Notebook](../../../notebooks/train.ipynb)  \n",
    "[Project Config Notebook](../../../notebooks/project_config.ipynb)  \n",
    "[Forgather Notebook](../../../notebooks/forgather.ipynb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26bffdcc-00ac-4adc-b3fd-974df44d09fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Test Various Weight Initialization Methods\n",
       "\n",
       "### Control\n",
       "\n",
       "This uses the standard PyTorch initializaiton methods for Linear and Embedding layers.\n",
       "\n",
       "Torch uses code equivalent to the followning for initializing linear layers:\n",
       "\n",
       "```python\n",
       "stdv = 1. / math.sqrt(self.weight.size(1))\n",
       "self.weight.data.uniform_(-stdv, stdv)\n",
       "```\n",
       "\n",
       "See interesting discussions about this method:\n",
       "\n",
       "https://github.com/pytorch/pytorch/issues/57109\n",
       "https://soumith.ch/files/20141213_gplus_nninit_discussion.htm\n",
       "\n",
       "### Regex\n",
       "\n",
       "This is the same initialization as \"Control,\" but it uses regular-expressions to control how the parameters are initialized.\n",
       "\n",
       "This is more complex, but far more flexible.\n",
       "\n",
       "### Xavier Uniform\n",
       "\n",
       "Here. we use regex again, but use it to replace the torch default init with Xavier Unifrom initializaiton.\n",
       "\n",
       "This performs relatively poorly.\n",
       "\n",
       "### Xavier Uniform No Feedforward\n",
       "\n",
       "This is the same as Xavier Unifrom, except for the feedforward layers, which are initialized with the \"torch\" method.\n",
       "\n",
       "This demonstrates that the primary issue is with using fan-out to compute the scaling-factor, where fan-out is 4x fan-in.\n",
       "\n",
       "Note that both methods are effectively the same for symetric matrices, like those used by the attention layers.\n",
       "\n",
       "The only difference in this case is with the initialization of the output layers.\n",
       "\n",
       "### Deepnet\n",
       "\n",
       "DeepNet: Scaling Transformers to 1,000 Layers  \n",
       "https://arxiv.org/pdf/2203.00555\n",
       "\n",
       "Here we try using the method described in the above paper. Among the changes, this rescales both the feedforward initialization and that of the \n",
       "attention value and output layers by \"beta,\" which is computed from the number of transformer layers and scales the residuals by \"alpha,\" \n",
       "also dervived from the number of layers.\n",
       "\n",
       "Even though this is using Xavier Uniform initializaiton, this performs on-par with the control, thus not showing the issue identified when \n",
       "testing with a simple Xavier Unifrom initialization.\n",
       "\n",
       "### Deepnet Init\n",
       "\n",
       "This uses the deepnet initialization method, but not the residual scaling factor. Performance is close to the other good methods.\n",
       "\n",
       "### Deepnet Torch\n",
       "\n",
       "This is the same as Deepnet, but we replace Xavier Uniform with the \"Torch\" method. Again, similar performance.\n",
       "\n",
       "\n",
       "\n",
       "#### Project Directory: \"/home/dinalt/ai_assets/forgather/examples/trainers/init_weights\"\n",
       "\n",
       "## Meta Config\n",
       "Meta Config: [/home/dinalt/ai_assets/forgather/examples/trainers/init_weights/meta.yaml](meta.yaml)\n",
       "\n",
       "- [meta.yaml](meta.yaml)\n",
       "    - [meta_defaults.yaml](../../../forgather_workspace/meta_defaults.yaml)\n",
       "        - [base_directories.yaml](../../../forgather_workspace/base_directories.yaml)\n",
       "\n",
       "Template Search Paths:\n",
       "- [/home/dinalt/ai_assets/forgather/examples/trainers/init_weights/templates](templates)\n",
       "- [/home/dinalt/ai_assets/forgather/forgather_workspace](../../../forgather_workspace)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/tiny_experiments](../../../templates/tiny_experiments)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/modellib](../../../templates/modellib)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/base](../../../templates/base)\n",
       "\n",
       "## Available Configurations\n",
       "- [deepnet_torch.yaml](templates/configs/deepnet_torch.yaml)\n",
       "- [deepnet.yaml](templates/configs/deepnet.yaml)\n",
       "- [xavier_uniform_noff.yaml](templates/configs/xavier_uniform_noff.yaml)\n",
       "- [regex.yaml](templates/configs/regex.yaml)\n",
       "- [xavier_uniform.yaml](templates/configs/xavier_uniform.yaml)\n",
       "- [deepnet_init.yaml](templates/configs/deepnet_init.yaml)\n",
       "- [he_relu.yaml](templates/configs/he_relu.yaml)\n",
       "- [control.yaml](templates/configs/control.yaml)\n",
       "\n",
       "Default Configuration: control.yaml\n",
       "\n",
       "Active Configuration: control.yaml\n",
       "\n",
       "## Included Templates\n",
       "- [configs/control.yaml](templates/configs/control.yaml)\n",
       "    - [project.yaml](templates/project.yaml)\n",
       "        - [projects/tiny.yaml](../../../templates/tiny_experiments/projects/tiny.yaml)\n",
       "            - [prompts/tiny_stories.yaml](../../../templates/tiny_experiments/prompts/tiny_stories.yaml)\n",
       "            - [types/training_script/causal_lm/causal_lm.yaml](../../../templates/base/types/training_script/causal_lm/causal_lm.yaml)\n",
       "                - [trainers/trainer.yaml](../../../templates/base/trainers/trainer.yaml)\n",
       "                    - [trainers/base_trainer.yaml](../../../templates/base/trainers/base_trainer.yaml)\n",
       "                        - [trainers/minimal_trainer.yaml](../../../templates/base/trainers/minimal_trainer.yaml)\n",
       "                - [callbacks/loggers.yaml](../../../templates/base/callbacks/loggers.yaml)\n",
       "                    - [callbacks/base_callbacks.yaml](../../../templates/base/callbacks/base_callbacks.yaml)\n",
       "                - [models/abstract/load_model.yaml](../../../templates/base/models/abstract/load_model.yaml)\n",
       "                    - [models/abstract/causal_lm_from_pretrained.yaml](../../../templates/base/models/abstract/causal_lm_from_pretrained.yaml)\n",
       "                        - [models/abstract/base_language_model.yaml](../../../templates/base/models/abstract/base_language_model.yaml)\n",
       "                - [types/training_script/training_script.yaml](../../../templates/base/types/training_script/training_script.yaml)\n",
       "                    - [types/type.yaml](../../../templates/base/types/type.yaml)\n",
       "                        - [base_directories.yaml](../../../forgather_workspace/base_directories.yaml)\n",
       "                - [inc/formatting.jinja](../../../templates/base/inc/formatting.jinja)\n",
       "            - [tiny.callbacks](../../../templates/tiny_experiments/projects/tiny.yaml)\n",
       "            - [tiny.model_config](../../../templates/tiny_experiments/projects/tiny.yaml)\n",
       "                - [models/tiny/tiny_causal.yaml](../../../templates/tiny_experiments/models/tiny/tiny_causal.yaml)\n",
       "                    - [tokenizers/tiny_2k.yaml](../../../templates/tiny_experiments/tokenizers/tiny_2k.yaml)\n",
       "                    - [models/dynamic_causal_transformer.yaml](../../../templates/modellib/models/dynamic_causal_transformer.yaml)\n",
       "                        - [models/abstract/dynamic_causal_lm.yaml](../../../templates/base/models/abstract/dynamic_causal_lm.yaml)\n",
       "                            - [models/abstract/custom_causal_lm.yaml](../../../templates/base/models/abstract/custom_causal_lm.yaml)\n",
       "            - [tiny.trainer_config](../../../templates/tiny_experiments/projects/tiny.yaml)\n",
       "            - [tiny.dataset_config](../../../templates/tiny_experiments/projects/tiny.yaml)\n",
       "                - [datasets/tiny/tiny_stories_abridged.yaml](../../../templates/tiny_experiments/datasets/tiny/tiny_stories_abridged.yaml)\n",
       "                    - [datasets/tiny/tiny_stories.yaml](../../../templates/tiny_experiments/datasets/tiny/tiny_stories.yaml)\n",
       "                        - [datasets/abstract/base_datasets.yaml](../../../templates/base/datasets/abstract/base_datasets.yaml)\n",
       "        - [project.model_config](templates/project.yaml)\n",
       "        - [project.trainer_config](templates/project.yaml)\n",
       "    - [experiment.model_config](templates/configs/control.yaml)\n",
       "### Config Metadata:\n",
       "\n",
       "```python\n",
       "{'config_class': 'type.training_script.causal_lm',\n",
       " 'config_description': 'Baseline Simple Init',\n",
       " 'config_name': 'Control',\n",
       " 'create_new_model': 'True',\n",
       " 'datasets_dir': '/home/dinalt/ai_assets/forgather/datasets',\n",
       " 'eval': 'False',\n",
       " 'forgather_dir': '/home/dinalt/ai_assets/forgather',\n",
       " 'logging_dir': './output_models/simple_init/runs/simple_init_2025-05-24T20-19-08',\n",
       " 'model_src_dir': '/home/dinalt/ai_assets/forgather/model_src',\n",
       " 'models_dir': './output_models',\n",
       " 'output_dir': './output_models/simple_init',\n",
       " 'project_dir': '.',\n",
       " 'save_model': 'False',\n",
       " 'tokenizers_dir': '/home/dinalt/ai_assets/forgather/tokenizers',\n",
       " 'train': 'True',\n",
       " 'workspace_root': '/home/dinalt/ai_assets/forgather'}\n",
       "\n",
       "```\n",
       "\n",
       "## Modules\n",
       "- [./output_models/simple_init/tiny_causal_transformer.py](output_models/simple_init/tiny_causal_transformer.py) : DynamicCasualLM\n",
       "    - [/home/dinalt/ai_assets/forgather/examples/trainers/init_weights/./output_models/xavier_uniform_noff/tiny_causal_transformer.py](output_models/xavier_uniform_noff/tiny_causal_transformer.py) : tiny_causal_transformer\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/causal_lm.py](../../../model_src/bits/causal_lm.py) : tiny_causal_transformer.causal_lm\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/causal_loss.py](../../../model_src/bits/causal_loss.py) : tiny_causal_transformer.causal_loss\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/causal_multihead_attn.py](../../../model_src/bits/causal_multihead_attn.py) : tiny_causal_transformer.causal_multihead_attn\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/feedforward_layer.py](../../../model_src/bits/feedforward_layer.py) : tiny_causal_transformer.feedforward_layer\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/init_weights.py](../../../model_src/bits/init_weights.py) : tiny_causal_transformer.init_weights\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/input_encoder.py](../../../model_src/bits/input_encoder.py) : tiny_causal_transformer.input_encoder\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/layer_stack.py](../../../model_src/bits/layer_stack.py) : tiny_causal_transformer.layer_stack\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/post_ln_layer.py](../../../model_src/bits/post_ln_layer.py) : tiny_causal_transformer.post_ln_layer\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/sinusoidal_pe.py](../../../model_src/bits/sinusoidal_pe.py) : tiny_causal_transformer.sinusoidal_pe\n",
       "- [./output_models/simple_init/tiny_causal_transformer.py](output_models/simple_init/tiny_causal_transformer.py) : DynamicCausalLMConfig\n",
       "## Output Targets\n",
       "- meta\n",
       "- main\n",
       "- model_code_writer\n",
       "- distributed_env\n",
       "- model\n",
       "- trainer\n",
       "- train_dataset\n",
       "- eval_dataset\n",
       "- data_collator\n",
       "- trainer_callbacks\n",
       "- trainer_args\n",
       "- optimizer\n",
       "- lr_scheduler\n",
       "- model_constructor_args\n",
       "- tokenizer\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import forgather.nb.notebooks as nb\n",
    "\n",
    "nb.display_project_index(\n",
    "    config_template=\"control.yaml\",\n",
    "    show_available_templates=False,\n",
    "    show_pp_config=False,\n",
    "    show_loaded_config=False,\n",
    "    show_generated_code=False,\n",
    "    materialize=False,\n",
    "    pp_first=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546c0dab-e03d-4ba9-a3cb-86a0319a6f08",
   "metadata": {},
   "source": [
    "## Constuct Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf6c458-ec39-4c4b-a978-f54ed6a544d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import forgather.nb.notebooks as nb\n",
    "from forgather import Project\n",
    "\n",
    "# Pass config name\n",
    "proj = Project(\"xavier_uniform_noff.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce429870-2eb3-49b6-ab1f-2a3bb9a3e4b3",
   "metadata": {},
   "source": [
    "## Dump Model Param Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b880e-472b-4ee6-b69c-a8b93cc46ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = proj(\"model\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68e2a0-4aa7-479a-bec8-09d2e5399e04",
   "metadata": {},
   "source": [
    "## Train Model in Notebook\n",
    "This only works for a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f419ac-aec8-4edb-93ef-2850487ec34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use default config and default output target (training script, in this example).\n",
    "training_script = proj()\n",
    "training_script.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e30fa78-b4e4-44f2-a12d-ce0138fd8c48",
   "metadata": {},
   "source": [
    "## Start Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bc0f013-5494-49c6-b6d4-432ea0555af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Tensorboard Command\n",
       "\n",
       "```bash\n",
       "tensorboard --bind_all --logdir \"/home/dinalt/ai_assets/forgather/examples/trainers/init_weights/output_models/simple_init\"\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show command to run tensorboard; local_host should be false if tensorboard should run on all network interfaces.\n",
    "nb.display_tb_command(proj, local_host=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232926b8-13ba-4742-846a-08d07fbe0935",
   "metadata": {},
   "source": [
    "## Generate Trainingscript\n",
    "The preferred way of running training is via the command-line. This generates a simple bash script to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0188b-8ade-43e7-ba5d-11785e5b528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second arg specifies which GPUs may be used. For example, \"0,2\" only allows the first and third GPU.\n",
    "# Note that multi-GPU training requires a trainer implementation which supports this. e.g. \"accel_trainer\"\n",
    "nb.generate_trainingscript(proj, \"0\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
