-- extends 'project.yaml'

[config_metadata]
    == super()
    -- set ns.config_name = "Batch x10"
    -- set ns.config_description = "Test with batch size x10"
    -- set ns.model_name = "control"
    -- set ns.log_name = "batch_10"

[lr_scheduler]
    == super()
    
    # **experiment**
    # Scale by same factor as batch size
    warmup_steps: 50
    cooldown_steps: 5000

[optimizer]
    == super()
    # **experiment**
    # Scale LR by sqrt(10)
    lr: 3.16e-3

[trainer_definition]
    -- include 'experiment.trainer_config'

[trainer_callbacks]
    -- include 'experiment.callbacks'

#-------------------- experiment.trainer_config --------------------
-- extends 'tiny.trainer_config'

[trainer_args]
    == super()
    # **Experiment overrides**
    # Multiply batch size by 10
    per_device_train_batch_size: 320

    # Scale steps by factor of 10, relative to baseline
    logging_steps: 10
    eval_steps: 50
    save_steps: 1000

#-------------------- experiment.callbacks --------------------
-- extends 'tiny.callbacks'

[text_gen_callback_args]
    == super()
    # **experiment**
    generation_steps: 200