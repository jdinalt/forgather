-- extends 'models/transformers/dynamic_llama.yaml'

-- block model_meta_config
    == super()
    -- set model_def.name = "Tiny Dynamic Llama"
    -- set model_def.description = "A scaled-down version of the base Dynamic Llama Transformer"
    -- set model_def.short_name = "tiny_dllama"
<< endblock model_meta_config


-- block model_tokenizer
    ## Use a smaller tokenizer.
    -- include 'tokenizers/tiny_2k.yaml'
<< endblock model_tokenizer


## Add overrides to make the model smaller and disable all dropouts.
-- block model_config
    == super()
    
    # Tiny Causal overrides
    hidden_size: 256
    dim_feedforward: 1024
    num_attention_heads: 2
    d_head: 128
    num_hidden_layers: 4
    embedding_dropout: 0.0
    layer_dropout: 0.0
<< endblock model_config
