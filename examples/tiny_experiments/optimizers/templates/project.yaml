-- extends 'projects/tinyv2_packed.yaml'

[config_metadata]
    == super()
    -- set ns.dataset_proj = dataset_project | default(joinpath(ns.forgather_dir, 'examples', 'datasets', 'roneneldan'))
    -- set ns.dataset_config = dataset_config | default("fast-iter-packed.yaml")
    -- set ns.nproc_per_node = 1
    -- set ns.default_attn_implementation = "sdpa"
    
    ## Use a bigger model, to reduce impact of execution latency
    ## This model has 28 parameters, thus Chinchilla optimal is 560M tokens
    ## Set predefined model project to import
    -- set ns.model_project_dir = abspath(model_project | default((joinpath(ns.forgather_dir, "examples", "models", "llama"))))
    -- set ns.model_project_config = model_config | default("small.yaml")

    -- set ns.total_tokens = total_tokens | default(560)
    -- set ns.warmup_tokens = warmup_tokens | default(56)
    -- set ns.min_cooldown_tokens = min_cooldown_tokens | default(0)

    -- set ns.seq_len = seq_len | default(512)
    -- set ns.per_device_train_batch_size = batch_size | default(32)

    -- set ns.base_lr = base_lr | default(3.0e-6)
    -- set ns.base_linear_lr = 1.0e-2

[globals]
    == super()
    -- set ns.effective_linear_lr = ns.base_linear_lr * ns.global_batch_size

[variable_listing]
    == super()
# ns.effective_linear_lr: {{ ns.effective_linear_lr }}

[trainer_callbacks]
    -- include 'project.callbacks'

#-------------------- project.callbacks --------------------
-- extends 'tiny.callbacks'

[callback_list]
    == super()
    text_gen_callback: null # Disable text gen