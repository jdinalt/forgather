-- extends 'models/tiny/tiny_causal.yaml'

## Add the project model_src directory to the search path
[model_submodule_searchpath]
    - "{{ ns.project_model_src_dir }}"
    == super()

[model_config]
    == super()
    
    # Pipeline Trainer Project
    hidden_size: 1024
    dim_feedforward: 4096
    num_attention_heads: 16
    num_hidden_layers: 16
    embedding_dropout: 0.1
    layer_dropout: 0.1

[model_tokenizer]
    -- include 'tokenizers/tiny_8k.yaml'

[layer_factory]
layer_factory: &layer_factory !partial:.deepnet:DeepnetLayer@layer_factory
    feedforward_factory: *feedforward_factory
    attention_factory: *attention_factory
    norm_factory: *layer_norm_factory
    dropout: !var "layer_dropout"
    residual_dropout: !var "residual_dropout"
    alpha: !call:.deepnet:deepnet_alpha@dn_alpha [ !var "num_hidden_layers", 0 ]

[init_weights]
init_weights: &init_weights !partial:.init_weights:init_weights_by_regex@init_weights
    regex_list:
        - [ 'norm', "pass" ]
        - [ 'bias', "zeros" ]
        - [ 'embedding\.weight', "embedding" ]
        - [ 'feedforward|value_linear|output_linear', "deepnet" ]
        - [ 'attention|output_decoder', "linear" ]
    init_f_map:
        pass: !partial:.init_weights:init_pass
        zeros: !partial:torch.nn.init:zeros_ []
        embedding: !partial:.init_weights:init_embeddings
            padding_index: !var "pad_token_id"
        linear: !partial:torch.nn.init:xavier_uniform_ []
        deepnet: !partial:torch.nn.init:xavier_uniform_
            gain: !call:.deepnet:deepnet_beta [ !var "num_hidden_layers", 0 ]