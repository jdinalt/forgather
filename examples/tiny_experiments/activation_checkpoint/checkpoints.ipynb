{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e422f35-7a08-4a50-a075-51a68b5c3994",
   "metadata": {},
   "source": [
    "# Project Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb0735c-f30f-4a45-b969-3cc2077126d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Activation Checkpoint Test\n",
       "\n",
       "Testing activation checkpointing.\n",
       "\n",
       "#### Project Directory: \"/home/dinalt/ai_assets/forgather/examples/trainers/activation_checkpoint\"\n",
       "\n",
       "## Meta Config\n",
       "Meta Config: [/home/dinalt/ai_assets/forgather/examples/trainers/activation_checkpoint/meta.yaml](meta.yaml)\n",
       "\n",
       "- [meta.yaml](meta.yaml)\n",
       "    - [meta_defaults.yaml](../../../forgather_workspace/meta_defaults.yaml)\n",
       "        - [base_directories.yaml](../../../forgather_workspace/base_directories.yaml)\n",
       "\n",
       "Template Search Paths:\n",
       "- [/home/dinalt/ai_assets/forgather/examples/trainers/activation_checkpoint/templates](templates)\n",
       "- [/home/dinalt/ai_assets/forgather/forgather_workspace](../../../forgather_workspace)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/tiny_experiments](../../../templates/tiny_experiments)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/modellib](../../../templates/modellib)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/base](../../../templates/base)\n",
       "\n",
       "## Available Configurations\n",
       "- [test_cp.yaml](templates/experiments/test_cp.yaml)\n",
       "- [control.yaml](templates/experiments/control.yaml)\n",
       "\n",
       "Default Configuration: control.yaml\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import forgather.nb.notebooks as nb\n",
    "nb.display_project_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d78a670-1483-4d8f-bf28-615b82489d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.display_config(config_template=\"test_cp.yaml\", show_pp_config=False, show_generated_code=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba48601-bae1-44cd-ab21-7f7b7245c329",
   "metadata": {},
   "source": [
    "#### View Memory Snapshot Files Here\n",
    "\n",
    "https://docs.pytorch.org/memory_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09251b9-1080-4894-9da4-0554fd45ebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgather.project import Project\n",
    "from forgather.ml.utils import count_parameters\n",
    "\n",
    "# Load project assests\n",
    "proj = Project(\"test_cp.yaml\")\n",
    "model_f, data_collator, train_dataset, optimizer = proj(\"model\", \"data_collator\", \"train_dataset\", \"optimizer\")\n",
    "\n",
    "model = model_f()\n",
    "print(model)\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d956a85-ada7-4101-a2a8-230080b044cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pickle import dump\n",
    "import torch\n",
    "from pickle import dump\n",
    "import forgather\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "from forgather.ml.optim.adafactor import Adafactor\n",
    "from pprint import pp\n",
    "\n",
    "# Substitute with the project optimizer to test memory requirements with these.\n",
    "adamw_factory = partial(torch.optim.AdamW, lr=1e-3)\n",
    "sgd_factory = partial(torch.optim.SGD, lr=1e-1)\n",
    "adafactor_factory = partial(Adafactor, lr=1e-4)\n",
    "\n",
    "def profile_training_memory(\n",
    "    model,\n",
    "    dataset,\n",
    "    data_collator,\n",
    "    opt_factory,\n",
    "    device,\n",
    "    batch_size,\n",
    "    max_steps,\n",
    "    truncate_to=None,\n",
    "    shuffle=False,\n",
    "    show_details=False,\n",
    "    profiler_file=None\n",
    "):\n",
    "    try:\n",
    "        train_progress_bar = tqdm(total=max_steps, dynamic_ncols=True)\n",
    "        \n",
    "        if profiler_file:\n",
    "            torch.cuda.memory._record_memory_history(enabled='all')\n",
    "            \n",
    "        model.train()\n",
    "        model.to(device)\n",
    "        if shuffle:\n",
    "            dataset = dataset.shuffle()\n",
    "        \n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator, pin_memory=True)\n",
    "        opt = opt_factory(model.named_parameters())\n",
    "        max_sequence = 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            labels = batch[\"labels\"]\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "\n",
    "            if truncate_to:\n",
    "                labels = labels[:, :truncate_to]\n",
    "                input_ids = labels[:, :truncate_to]\n",
    "            \n",
    "            if max_sequence < input_ids.shape[1]:\n",
    "                max_sequence = input_ids.shape[1]\n",
    "\n",
    "            input_ids = input_ids.to(device)\n",
    "            labels = labels.to(device)\n",
    "    \n",
    "            try:\n",
    "                loss, logits = model(input_ids=input_ids, labels=labels)\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "            except:\n",
    "                print(f\"Exception raised on batch {step} of {max_steps} : {input_ids.shape}\")\n",
    "                raise\n",
    "            opt.zero_grad()\n",
    "            train_progress_bar.update()\n",
    "            train_progress_bar.write(f\"loss: {loss.item():.4}\")\n",
    "            if step == max_steps:\n",
    "                break\n",
    "        del opt\n",
    "        \n",
    "        # save a snapshot of the memory allocation to file\n",
    "        if profiler_file:\n",
    "            s = torch.cuda.memory._snapshot()\n",
    "            with open(profiler_file, \"wb\") as f:\n",
    "                dump(s, f)\n",
    "        torch.cuda.memory._record_memory_history(enabled=None)\n",
    "        max_allocated = torch.cuda.max_memory_allocated()\n",
    "        model.cpu()\n",
    "        print(f\"maximum_sequence_length={max_sequence}\")\n",
    "        print(f\"final loss={loss.item()}\")\n",
    "        print(f\"max_allocated={max_allocated / 1000000000.:.3f} GB\")\n",
    "        if show_details:\n",
    "            pp(torch.cuda.memory_stats(device))\n",
    "    finally:\n",
    "        train_progress_bar.close()\n",
    "        train_progress_bar = None\n",
    "\n",
    "profile_training_memory(\n",
    "    model=model,\n",
    "    dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    opt_factory=adafactor_factory,\n",
    "    device=\"cuda:0\",\n",
    "    batch_size=32,\n",
    "    max_steps=3,\n",
    "    truncate_to=None,\n",
    "    shuffle=True,\n",
    "    show_details=True,\n",
    "    profiler_file=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a2b368-deae-40d8-95b8-d143376523dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.reset_max_memory_allocated(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972b0f7-0b7f-464c-82e4-338500bd85ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgather.project import Project\n",
    "\n",
    "proj = Project(\"test_cp.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0165e7bd-df76-43f1-a62d-7889a28685d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.generate_trainingscript(proj, \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ce13d-3db8-4329-a34c-5690f423befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.display_tb_command(proj, local_host=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
