-- extends 'types/training_script/causal_lm/causal_lm.yaml'

-- block config_metadata
    == super()
    -- set ns.config_name = "External Workspace Example"
    -- set ns.config_description = "External workspace example training an 8M parameter model on TinyStories"
    -- set ns.create_new_model = True
    -- set ns.save_model = True
-- endblock config_metadata

-- block model_definition
    -- include 'tokenizers/tiny_2k.yaml'
    -- include 'models/custom_alibi_glu.yaml'
-- endblock model_definition

-- block datasets_definition
    -- include 'datasets/roneneldan/tinystories-abridged.yaml'
-- endblock datasets_definition

-- block trainer_definition
    -- include 'project.trainer_config'
-- endblock trainer_definition

#-------------------- project.trainer_config --------------------
-- extends 'trainers/trainer.yaml'

-- block trainer_args
    == super()
    
    output_dir: "./output_models/tiny_story_model"
    
    ## Training schedule
    num_train_epochs: 1
    per_device_train_batch_size: 8
    per_device_eval_batch_size: 8
    
    ## Optimization
    learning_rate: 3e-4
    weight_decay: 0.01
    warmup_steps: 100
    
    ## Logging and evaluation
    logging_steps: 50
    eval_steps: 200
    eval_strategy: "steps"
    
    ## Checkpointing
    save_steps: 500
    save_strategy: "steps"
    save_total_limit: 2
    save_optimizer_state: true
    save_scheduler_state: true
    
    ## Hardware
    dataloader_num_workers: 4
    dataloader_pin_memory: true
    
-- endblock trainer_args