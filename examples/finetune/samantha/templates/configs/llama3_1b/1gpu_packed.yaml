-- extends 'samantha_packed.yaml'

[config_metadata]
    == super()
    -- set ns.config_name = "Samantha Llama3 1B Packed"
    -- set ns.config_description = "Train with 4096 token context on single GPU, 24 GBs"
    -- set ns.log_name = log_name | default('1gpu_4096_packed')
    -- set ns.log_memory_to_tb = True

[trainer_args]
    == super()

    # **config**
    per_device_train_batch_size: 12
    per_device_eval_batch_size: 12
    logging_steps: 2
    eval_steps: 5
    save_steps: 1000
    gradient_checkpointing: True
    fuse_optim_with_backward: True
    #enable_activation_offloading: True
    #detect_anomaly: True
    #activation_memory_budget: 0.05
    gc_threshold: 0.9
    torch_compile: True
    torch_compile_dynamic: False
    speed_metrics_start_step: 1
    num_train_epochs: {{ epochs | default(2) }}

[optimizer]
    == super()
    lr: !!float {{ lr | default(1.0e-4) }}

[lr_scheduler]
    == super()
    warmup_steps: {{ warmup_steps | default(10) }}

[fused_loss_factory]
# Fused output-linear x cross-entropy-loss kernel
.define: &fused_loss_factory !partial:forgather.ml.loss:LinearCrossEntropyLoss
    impl: "cce"
