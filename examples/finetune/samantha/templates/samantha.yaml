-- extends 'projects/finetune.yaml'

## Default Assumptions:
## The
-- block resource_directories
    == super()
    ## Change this to point to where your models are stored
    -- set ns.models_dir = joinpath(user_home_dir(), 'ai_assets', 'models')

    ## Directory in which local datasets are stored
    -- set ns.datasets_dir = joinpath(user_home_dir(), 'ai_assets', 'datasets')
<< endblock resource_directories

-- block config_metadata
    == super()
    # Set ot name of model to train
    -- set ns.model_name = "llama-2-7b-fg"
    -- set ns.debug_memory_detials = False
    -- set ns.log_peak_memmory = True
    -- set ns.log_memory_to_tb = True
-- endblock config_metadata


-- block trainer_definition
    -- include 'samantha.trainer_config'
-- endblock trainer_definition


-- block datasets_definition
    -- include 'samantha.dataset_config'
-- endblock datasets_definition


#-------------------- samantha.trainer_config --------------------
-- extends 'finetune.trainer_config'

-- block trainer_args
    == super()
    # project overrides
    sdpa_backend: [ "flash", "efficient" ]
    sdpa_set_priority: True
    ## max_steps: 500
-- endblock trainer_args

#-------------------- samantha.dataset_config --------------------
-- extends 'datasets/QuixiAI/samantha.yaml'
