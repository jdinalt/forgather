{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e422f35-7a08-4a50-a075-51a68b5c3994",
   "metadata": {},
   "source": [
    "# Project Index\n",
    "\n",
    "[Custom Model Notebook](../../../notebooks/custom_model.ipynb)  \n",
    "[Training Notebook](../../../notebooks/train.ipynb)  \n",
    "[Project Config Notebook](../../../notebooks/project_config.ipynb)  \n",
    "[Forgather Notebook](../../../notebooks/forgather.ipynb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bffdcc-00ac-4adc-b3fd-974df44d09fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Causal Transformer\n",
       "\n",
       "A custom transformer constructed from composible 'bits.'\n",
       "\n",
       "## Meta Config\n",
       "Project Directory: /home/dinalt/ai_assets/forgather/examples/models/transformers\n",
       "\n",
       "Meta Config: [/home/dinalt/ai_assets/forgather/examples/models/transformers/meta.yaml](meta.yaml)\n",
       "\n",
       "- [meta.yaml](meta.yaml)\n",
       "\n",
       "Template Search Paths:\n",
       "- [/home/dinalt/ai_assets/forgather/examples/models/transformers/templates](templates)\n",
       "- [/home/dinalt/ai_assets/forgather/templates](../../../templates)\n",
       "\n",
       "## Available Configurations\n",
       "- [walsh_pe.yaml](templates/configs/walsh_pe.yaml)\n",
       "- [causal_transformer.yaml](templates/configs/causal_transformer.yaml)\n",
       "- [swi-glu.yaml](templates/configs/swi-glu.yaml)\n",
       "- [tiny.yaml](templates/configs/tiny.yaml)\n",
       "- [base_dynamic.yaml](templates/configs/base_dynamic.yaml)\n",
       "Default Configuration: base_dynamic.yaml\n",
       "\n",
       "Active Configuration: causal_transformer.yaml\n",
       "\n",
       "## Available Templates\n",
       "- [project.yaml](templates/project.yaml)\n",
       "- [configs/walsh_pe.yaml](templates/configs/walsh_pe.yaml)\n",
       "- [configs/causal_transformer.yaml](templates/configs/causal_transformer.yaml)\n",
       "- [configs/swi-glu.yaml](templates/configs/swi-glu.yaml)\n",
       "- [configs/tiny.yaml](templates/configs/tiny.yaml)\n",
       "- [configs/base_dynamic.yaml](templates/configs/base_dynamic.yaml)\n",
       "- [trainers/accel_trainer.yaml](../../../templates/trainers/accel_trainer.yaml)\n",
       "- [trainers/trainer.yaml](../../../templates/trainers/trainer.yaml)\n",
       "- [trainers/hf_trainer.yaml](../../../templates/trainers/hf_trainer.yaml)\n",
       "- [trainers/base_trainer.yaml](../../../templates/trainers/base_trainer.yaml)\n",
       "- [model_ctor/args.yaml](../../../templates/model_ctor/args.yaml)\n",
       "- [projects/tiny.yaml](../../../templates/projects/tiny.yaml)\n",
       "- [datasets/abstract/pretokenized_dataset.yaml](../../../templates/datasets/abstract/pretokenized_dataset.yaml)\n",
       "- [datasets/abstract/base_datasets.yaml](../../../templates/datasets/abstract/base_datasets.yaml)\n",
       "- [datasets/tiny/tiny_stories.yaml](../../../templates/datasets/tiny/tiny_stories.yaml)\n",
       "- [datasets/tiny/tiny_stories_abridged.yaml](../../../templates/datasets/tiny/tiny_stories_abridged.yaml)\n",
       "- [models/dynamic_lm.yaml](../../../templates/models/dynamic_lm.yaml)\n",
       "- [models/causal_transformer.yaml](../../../templates/models/causal_transformer.yaml)\n",
       "- [models/gpt2.yaml](../../../templates/models/gpt2.yaml)\n",
       "- [models/llama.yaml](../../../templates/models/llama.yaml)\n",
       "- [models/abstract/causal_lm_from_config.yaml](../../../templates/models/abstract/causal_lm_from_config.yaml)\n",
       "- [models/abstract/base_language_model.yaml](../../../templates/models/abstract/base_language_model.yaml)\n",
       "- [models/abstract/custom_causal_lm.yaml](../../../templates/models/abstract/custom_causal_lm.yaml)\n",
       "- [models/abstract/causal_lm_from_pretrained.yaml](../../../templates/models/abstract/causal_lm_from_pretrained.yaml)\n",
       "- [models/abstract/load_model.yaml](../../../templates/models/abstract/load_model.yaml)\n",
       "- [models/tiny/tiny_causal.yaml](../../../templates/models/tiny/tiny_causal.yaml)\n",
       "- [models/tiny/tiny_gpt2.yaml](../../../templates/models/tiny/tiny_gpt2.yaml)\n",
       "- [models/tiny/tiny_llama.yaml](../../../templates/models/tiny/tiny_llama.yaml)\n",
       "- [models/tiny/tiny_d128_l2.yaml](../../../templates/models/tiny/tiny_d128_l2.yaml)\n",
       "- [prompts/tiny_stories.yaml](../../../templates/prompts/tiny_stories.yaml)\n",
       "- [callbacks/base_callbacks.yaml](../../../templates/callbacks/base_callbacks.yaml)\n",
       "- [callbacks/loggers.yaml](../../../templates/callbacks/loggers.yaml)\n",
       "- [types/meta_template.yaml](../../../templates/types/meta_template.yaml)\n",
       "- [types/type.yaml](../../../templates/types/type.yaml)\n",
       "- [types/tokenizer/tokenizer.yaml](../../../templates/types/tokenizer/tokenizer.yaml)\n",
       "- [types/tokenizer/bpe/bpe.yaml](../../../templates/types/tokenizer/bpe/bpe.yaml)\n",
       "- [types/model/model_type.yaml](../../../templates/types/model/model_type.yaml)\n",
       "- [types/training_script/training_script.yaml](../../../templates/types/training_script/training_script.yaml)\n",
       "- [types/training_script/causal_lm/causal_lm.yaml](../../../templates/types/training_script/causal_lm/causal_lm.yaml)\n",
       "- [paths/example_paths.yaml](../../../templates/paths/example_paths.yaml)\n",
       "- [tokenizers/tiny_2k.yaml](../../../templates/tokenizers/tiny_2k.yaml)\n",
       "- [tokenizers/tiny_8k.yaml](../../../templates/tokenizers/tiny_8k.yaml)\n",
       "## Included Templates\n",
       "- [configs/causal_transformer.yaml](templates/configs/causal_transformer.yaml)\n",
       "    - [models/causal_transformer.yaml](../../../templates/models/causal_transformer.yaml)\n",
       "        - [tokenizers/tiny_8k.yaml](../../../templates/tokenizers/tiny_8k.yaml)\n",
       "        - [models/abstract/custom_causal_lm.yaml](../../../templates/models/abstract/custom_causal_lm.yaml)\n",
       "            - [models/abstract/base_language_model.yaml](../../../templates/models/abstract/base_language_model.yaml)\n",
       "                - [inc/formatting.jinja](../../../templates/inc/formatting.jinja)\n",
       "    - [project.yaml](templates/project.yaml)\n",
       "        - [paths/example_paths.yaml](../../../templates/paths/example_paths.yaml)\n",
       "        - [types/model/model_type.yaml](../../../templates/types/model/model_type.yaml)\n",
       "            - [types/type.yaml](../../../templates/types/type.yaml)\n",
       "### Config Metadata:\n",
       "\n",
       "```python\n",
       "{'config_description': '',\n",
       " 'config_name': 'Default Causal Transformer',\n",
       " 'datasets_dir': '../../../datasets',\n",
       " 'model_src_dir': '../../../model_src',\n",
       " 'models_dir': 'output_models',\n",
       " 'output_dir': 'output_models/causal_transformer',\n",
       " 'project_dir': '.',\n",
       " 'tokenizers_dir': '../../../tokenizers'}\n",
       "\n",
       "```\n",
       "\n",
       "## Modules\n",
       "- [../../../model_src/causal_transformer.py](../../../model_src/causal_transformer.py) : CausalTransformer\n",
       "    - [/home/dinalt/ai_assets/forgather/examples/models/transformers/../../../model_src/causal_transformer.py](../../../model_src/causal_transformer.py) : causal_transformer\n",
       "- [../../../model_src/causal_transformer.py](../../../model_src/causal_transformer.py) : CausalTransformerConfig\n",
       "## Preprocessed Config\n",
       "\n",
       "```yaml\n",
       "#---------------------------------------\n",
       "#       Default Causal Transformer       \n",
       "#---------------------------------------\n",
       "# 2024-08-08T01:30:46\n",
       "# Description: \n",
       "# Project Dir: .\n",
       "# Current Working Dir: \"/home/dinalt/ai_assets/forgather/examples/models/transformers\"\n",
       "# Forgather Config Dir: \"/home/dinalt/.config/forgather\"\n",
       "# Model: causal_transformer\n",
       "\n",
       "############# Config Vars ##############\n",
       "\n",
       "# ns.models_dir: \"output_models\"\n",
       "# ns.tokenizers_dir: \"../../../tokenizers\"\n",
       "# ns.datasets_dir: \"../../../datasets\"\n",
       "# ns.model_src_dir: \"../../../model_src\"\n",
       "# ns.output_dir: \"output_models/causal_transformer\"\n",
       "\n",
       "################ Model #################\n",
       "\n",
       ".define: &model_constructor_args {}\n",
       "\n",
       "# Name: Causal Transformer\n",
       "# Description: A causal transformer model, based upon 'Attention is All You Need'\n",
       "# model_def.cls = \"CausalTransformer\"\n",
       "# model_def.cfg_cls = \"CausalTransformerConfig\"\n",
       "# model_def.config_path = \"../../../model_src/causal_transformer.py\"\n",
       "# model_def.model_path = \"../../../model_src/causal_transformer.py\"\n",
       "\n",
       "# **Tokenizer**\n",
       "\n",
       "# Load custom tokenizer from sub-project definition\n",
       ".define: &tokenizer !singleton:forgather.ml.construct:load_from_config@tokenizer\n",
       "    project_dir: \"../../../examples/tokenizers/tiny_stories_bpe\"\n",
       "    config_template: \"8k.yaml\"\n",
       "\n",
       "# **Model Config**\n",
       "\n",
       "# Model is entirely self-contained; no sub-modules.\n",
       ".define: &model_submodule_searchpath []\n",
       "\n",
       "# Model does not have dynamically generated code\n",
       ".define: &model_code_generator null\n",
       "\n",
       ".define: &model_config !singleton:../../../model_src/causal_transformer.py:CausalTransformerConfig@model_config\n",
       "    submodule_searchpath: *model_submodule_searchpath\n",
       "    # Set auto-map for custom model; this ensures that the source code stays with the model.\n",
       "    auto_map:\n",
       "        AutoConfig: \"causal_transformer.CausalTransformerConfig\"\n",
       "        AutoModel: \"causal_transformer.CausalTransformer\"\n",
       "    # Get the vocab-size from the tokenizer definition.\n",
       "    vocab_size: !singleton:len [ *tokenizer ]\n",
       "    pad_token_id: !singleton:getattr [ *tokenizer, 'pad_token_id' ]\n",
       "    bos_token_id: !singleton:getattr [ *tokenizer, 'bos_token_id' ]\n",
       "    eos_token_id: !singleton:getattr [ *tokenizer, 'eos_token_id' ]\n",
       "    hidden_size: 512\n",
       "    num_attention_heads: 8\n",
       "    num_hidden_layers: 6\n",
       "    max_sequence_length: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - \"model_max_length\"\n",
       "    dim_feedforward: 2048\n",
       "    initializer_range: 0.02\n",
       "    embedding_dropout: 0.10\n",
       "    layer_dropout: 0.10\n",
       "    residual_dropout: 0.0\n",
       "    attention_dropout: 0.0\n",
       "    activation_dropout: 0.0\n",
       "\n",
       "# **Model Constructor**\n",
       "\n",
       ".define: &pretrained_model !singleton:../../../model_src/causal_transformer.py:CausalTransformer@pretrained_model\n",
       "    args:\n",
       "        - *model_config\n",
       "    kwargs:\n",
       "        submodule_searchpath: *model_submodule_searchpath\n",
       "        <<: *model_constructor_args\n",
       "\n",
       ".define: &model !singleton:forgather.ml.construct:dependency_list@model\n",
       "    - *pretrained_model\n",
       "    - !singleton:forgather.ml.construct:copy_package_files\n",
       "        - \"output_models/causal_transformer\"\n",
       "        - *model_config\n",
       "    - !singleton:forgather.ml.construct:copy_package_files\n",
       "        - \"output_models/causal_transformer\"\n",
       "        - *pretrained_model\n",
       "\n",
       "#---------------------------------------\n",
       "#          Configuration Output          \n",
       "#---------------------------------------\n",
       "meta: &meta_output !dict:@meta\n",
       "    config_name: \"Default Causal Transformer\"\n",
       "    config_description: \"\"\n",
       "    project_dir: \".\"\n",
       "    models_dir: \"output_models\"\n",
       "    tokenizers_dir: \"../../../tokenizers\"\n",
       "    datasets_dir: \"../../../datasets\"\n",
       "    output_dir: \"output_models/causal_transformer\"\n",
       "    model_src_dir: \"../../../model_src\"\n",
       "\n",
       "main:\n",
       "    model: *model\n",
       "    tokenizer: *tokenizer\n",
       "    model_config: *model_config\n",
       "    generated_code: *model_code_generator\n",
       "\n",
       "```\n",
       "\n",
       "## Loaded Configuration to YAML\n",
       "\n",
       "```yaml\n",
       ".define: &meta !singleton:named_dict@meta\n",
       "    config_name: 'Default Causal Transformer'\n",
       "    config_description: ''\n",
       "    project_dir: '.'\n",
       "    models_dir: 'output_models'\n",
       "    tokenizers_dir: '../../../tokenizers'\n",
       "    datasets_dir: '../../../datasets'\n",
       "    output_dir: 'output_models/causal_transformer'\n",
       "    model_src_dir: '../../../model_src'\n",
       "\n",
       ".define: &tokenizer !singleton:forgather.ml.construct:load_from_config@tokenizer\n",
       "    project_dir: '../../../examples/tokenizers/tiny_stories_bpe'\n",
       "    config_template: '8k.yaml'\n",
       "\n",
       ".define: &model_config !singleton:../../../model_src/causal_transformer.py:CausalTransformerConfig@model_config\n",
       "    auto_map: \n",
       "        AutoConfig: 'causal_transformer.CausalTransformerConfig'\n",
       "        AutoModel: 'causal_transformer.CausalTransformer'\n",
       "    vocab_size: !singleton:len\n",
       "        - *tokenizer\n",
       "    pad_token_id: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - 'pad_token_id'\n",
       "    bos_token_id: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - 'bos_token_id'\n",
       "    eos_token_id: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - 'eos_token_id'\n",
       "    hidden_size: 512\n",
       "    num_attention_heads: 8\n",
       "    num_hidden_layers: 6\n",
       "    max_sequence_length: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - 'model_max_length'\n",
       "    dim_feedforward: 2048\n",
       "    initializer_range: 0.02\n",
       "    embedding_dropout: 0.1\n",
       "    layer_dropout: 0.1\n",
       "    residual_dropout: 0.0\n",
       "    attention_dropout: 0.0\n",
       "    activation_dropout: 0.0\n",
       "\n",
       ".define: &pretrained_model !singleton:../../../model_src/causal_transformer.py:CausalTransformer@pretrained_model\n",
       "    - *model_config\n",
       "\n",
       ".define: &model !singleton:forgather.ml.construct:dependency_list@model\n",
       "    - *pretrained_model\n",
       "    - !singleton:forgather.ml.construct:copy_package_files\n",
       "        - 'output_models/causal_transformer'\n",
       "        - *model_config\n",
       "    - !singleton:forgather.ml.construct:copy_package_files\n",
       "        - 'output_models/causal_transformer'\n",
       "        - *pretrained_model\n",
       "\n",
       "\n",
       "meta: *meta\n",
       "main: \n",
       "    model: *model\n",
       "    tokenizer: *tokenizer\n",
       "    model_config: *model_config\n",
       "    generated_code: null\n",
       "\n",
       "```\n",
       "\n",
       "### Generated Source Code\n",
       "\n",
       "```python\n",
       "from forgather.ml.construct import dependency_list\n",
       "from forgather.ml.construct import copy_package_files\n",
       "from forgather.ml.construct import load_from_config\n",
       "from importlib.util import spec_from_file_location, module_from_spec\n",
       "import os\n",
       "import sys\n",
       "\n",
       "# Import a dynamic module.\n",
       "def dynimport(module, name, searchpath):\n",
       "    module_path = module\n",
       "    module_name = os.path.basename(module).split(\".\")[0]\n",
       "    module_spec = spec_from_file_location(\n",
       "        module_name,\n",
       "        module_path,\n",
       "        submodule_search_locations=searchpath,\n",
       "    )\n",
       "    mod = module_from_spec(module_spec)\n",
       "    sys.modules[module_name] = mod\n",
       "    module_spec.loader.exec_module(mod)\n",
       "    for symbol in name.split(\".\"):\n",
       "        mod = getattr(mod, symbol)\n",
       "    return mod\n",
       "\n",
       "CausalTransformerConfig = lambda: dynimport(\"../../../model_src/causal_transformer.py\", \"CausalTransformerConfig\", ['/home/dinalt/ai_assets/forgather/examples/models/transformers/../../../model_src'])\n",
       "CausalTransformer = lambda: dynimport(\"../../../model_src/causal_transformer.py\", \"CausalTransformer\", ['/home/dinalt/ai_assets/forgather/examples/models/transformers/../../../model_src'])\n",
       "\n",
       "def construct(\n",
       "):\n",
       "    meta = {\n",
       "        'config_name': 'Default Causal Transformer',\n",
       "        'config_description': '',\n",
       "        'project_dir': '.',\n",
       "        'models_dir': 'output_models',\n",
       "        'tokenizers_dir': '../../../tokenizers',\n",
       "        'datasets_dir': '../../../datasets',\n",
       "        'output_dir': 'output_models/causal_transformer',\n",
       "        'model_src_dir': '../../../model_src',\n",
       "    }\n",
       "\n",
       "    tokenizer = load_from_config(\n",
       "        project_dir='../../../examples/tokenizers/tiny_stories_bpe',\n",
       "        config_template='8k.yaml',\n",
       "    )\n",
       "\n",
       "    model_config = CausalTransformerConfig()(\n",
       "        auto_map={\n",
       "            'AutoConfig': 'causal_transformer.CausalTransformerConfig',\n",
       "            'AutoModel': 'causal_transformer.CausalTransformer',\n",
       "        },\n",
       "        vocab_size=len(\n",
       "            tokenizer,\n",
       "        ),\n",
       "        pad_token_id=tokenizer.pad_token_id,\n",
       "        bos_token_id=tokenizer.bos_token_id,\n",
       "        eos_token_id=tokenizer.eos_token_id,\n",
       "        hidden_size=512,\n",
       "        num_attention_heads=8,\n",
       "        num_hidden_layers=6,\n",
       "        max_sequence_length=tokenizer.model_max_length,\n",
       "        dim_feedforward=2048,\n",
       "        initializer_range=0.02,\n",
       "        embedding_dropout=0.1,\n",
       "        layer_dropout=0.1,\n",
       "        residual_dropout=0.0,\n",
       "        attention_dropout=0.0,\n",
       "        activation_dropout=0.0,\n",
       "    )\n",
       "\n",
       "    pretrained_model = CausalTransformer()(\n",
       "        model_config,\n",
       "    )\n",
       "\n",
       "    model = dependency_list(\n",
       "        pretrained_model,\n",
       "        copy_package_files(\n",
       "            'output_models/causal_transformer',\n",
       "            model_config,\n",
       "        ),\n",
       "        copy_package_files(\n",
       "            'output_models/causal_transformer',\n",
       "            pretrained_model,\n",
       "        ),\n",
       "    )\n",
       "    \n",
       "    return {\n",
       "        'meta': meta,\n",
       "        'main': {\n",
       "            'model': model,\n",
       "            'tokenizer': tokenizer,\n",
       "            'model_config': model_config,\n",
       "            'generated_code': None,\n",
       "        },\n",
       "    }\n",
       "\n",
       "```\n",
       "\n",
       "## Constructed Project\n",
       "\n",
       "```python\n",
       "{'main': {'generated_code': None,\n",
       "          'model': CausalTransformer(\n",
       "  (input_encoder): InputEncoder(\n",
       "    d_model=512, vocab_size=8000, embedding_scale=22.627416997969522\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (embedding): Embedding(8000, 512)\n",
       "    (positional_encoder): SinusoidalPE(d_model=512, max_sequence_length=2048)\n",
       "  )\n",
       "  (output_decoder): Linear(in_features=512, out_features=8000, bias=True)\n",
       "  (layer_stack): CausalLayerStack(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x PostLNLayer(\n",
       "        (feedforward): FeedforwardLayer(\n",
       "          d_model=512, d_feedforward=2048\n",
       "          (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (dropout): Identity()\n",
       "          (activation): ReLU()\n",
       "          (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (attention): CausalMultiheadAttn(\n",
       "          d_model=512, num_heads=8\n",
       "          (query_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (key_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (value_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (dropout): Identity()\n",
       "        )\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (residual_dropout): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "),\n",
       "          'model_config': CausalTransformerConfig {\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"auto_map\": {\n",
       "    \"AutoConfig\": \"causal_transformer.CausalTransformerConfig\",\n",
       "    \"AutoModel\": \"causal_transformer.CausalTransformer\"\n",
       "  },\n",
       "  \"bos_token_id\": 0,\n",
       "  \"dim_feedforward\": 2048,\n",
       "  \"embedding_dropout\": 0.1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_size\": 512,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_dropout\": 0.1,\n",
       "  \"max_sequence_length\": 2048,\n",
       "  \"model_type\": \"forgather-causal-transformer\",\n",
       "  \"num_attention_heads\": 8,\n",
       "  \"num_hidden_layers\": 6,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"residual_dropout\": 0.0,\n",
       "  \"transformers_version\": \"4.41.2\",\n",
       "  \"vocab_size\": 8000\n",
       "}\n",
       ",\n",
       "          'tokenizer': PreTrainedTokenizerFast(name_or_path='../../../tokenizers/tiny_stories_8k', vocab_size=8000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|BOS|>', 'eos_token': '<|EOS|>', 'unk_token': '<|UNK|>', 'pad_token': '<|PAD|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<|BOS|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"<|PAD|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<|EOS|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<|UNK|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}},\n",
       " 'meta': {'config_description': '',\n",
       "          'config_name': 'Default Causal Transformer',\n",
       "          'datasets_dir': '../../../datasets',\n",
       "          'model_src_dir': '../../../model_src',\n",
       "          'models_dir': 'output_models',\n",
       "          'output_dir': 'output_models/causal_transformer',\n",
       "          'project_dir': '.',\n",
       "          'tokenizers_dir': '../../../tokenizers'}}\n",
       "\n",
       "```\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import forgather.ml.notebooks as nb\n",
    "\n",
    "nb.display_project_index(config_template=\"causal_transformer.yaml\", materialize=True, pp_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0a06f-f425-41ef-878b-017a2d2c2718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
