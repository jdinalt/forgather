-- set datasets_ns = namespace()
-- from 'inc/formatting.jinja' import h3
-- filter trim()

-- block datasets_meta_config
-- set datasets_ns.name = "Undefined"
-- set datasets_ns.description = ""
-- set datasets_ns.source = ""
-- set datasets_ns.train_dataset_split = "train"
-- set datasets_ns.eval_dataset_split = "validation"
## The callable used for loading
-- set datasets_ns.train_load_method = "datasets:load_dataset"
-- set datasets_ns.eval_load_method = "datasets:load_dataset"
-- set datasets_ns.train_select_range = "null"
-- set datasets_ns.eval_select_range = "null"
## The following args are required
## -- set datasets_ns.train_dataset_id = "dataset_id_or_path"
-- set datasets_ns.eval_dataset_id = datasets_ns.train_dataset_id
-- endblock datasets_meta_config

## Alias train dataset, if they are the same?
## As long as there are no other references to the eval dataset,
## it will be eliminated when the "dot-keys" are stripped.
-- if datasets_ns.train_dataset_id == datasets_ns.eval_dataset_id
    -- set datasets_ns.eval_source_dataset_name = "train_source_dataset"
-- else
    -- set datasets_ns.eval_source_dataset_name = "eval_source_dataset"
-- endif

-- endfilter
-- block datasets_header
# Name: {{ datasets_ns.name }}
# Define: {{ datasets_ns.description }}
# Source: {{ datasets_ns.source }}
# Train Dataset: "{{ datasets_ns.train_dataset_id }}" : "{{ datasets_ns.train_dataset_split }}"
# Eval Dataset: "{{ datasets_ns.eval_dataset_id }}" : "{{ datasets_ns.eval_dataset_split }}"
<< endblock datasets_header


== h3('Source Datasets')

-- filter trim()
-- block load_train_dataset
train_source_dataset: &train_source_dataset !singleton:{{datasets_ns.train_load_method}}@train_source_dataset
    - "{{ datasets_ns.train_dataset_id }}"
<< endblock load_train_dataset
-- endfilter


-- filter trim()

-- block load_eval_dataset
eval_source_dataset: &eval_source_dataset !singleton:{{datasets_ns.eval_load_method}}@eval_source_dataset
    - "{{ datasets_ns.eval_dataset_id }}"
<< endblock load_eval_dataset
-- endfilter


== h3('Dataset Splits')

-- filter trim()
-- block dataset_splits
train_dataset_split: &train_dataset_split !singleton:operator:getitem
    - *train_source_dataset
    - "{{ datasets_ns.train_dataset_split }}"

eval_dataset_split: &eval_dataset_split !singleton:operator:getitem
    - *{{ datasets_ns.eval_source_dataset_name }}
    - "{{ datasets_ns.eval_dataset_split }}"
<< endblock dataset_splits
-- endfilter


== h3('Preprocess Dataset Args')

-- filter trim()
-- block preprocess_args
## See: https://huggingface.co/docs/transformers/main_classes/tokenizer
preprocess_args: &preprocess_args
    truncation: True
<< endblock preprocess_args

-- endfilter


== h3('Preprocessed Datasets')

-- filter trim()
-- block datasets
    -- filter trim()
    -- block tokenize_train
train_dataset: &train_dataset !singleton:forgather.ml.datasets:preprocess_dataset@train_dataset
    dataset: *train_dataset_split
    tokenizer: *tokenizer
    select_range: {{ datasets_ns.train_select_range }}
    desc: "{{ "Tokenizing " + datasets_ns.train_dataset_split }}"
    fn_kwargs:
        <<: *preprocess_args
    << endblock tokenize_train
    -- endfilter


    -- filter trim()
    -- block tokenize_eval
eval_dataset: &eval_dataset !singleton:forgather.ml.datasets:preprocess_dataset@eval_dataset
    dataset: *eval_dataset_split
    tokenizer: *tokenizer
    select_range: {{ datasets_ns.eval_select_range }}
    desc: "{{ "Tokenizing " + datasets_ns.eval_dataset_split + " split" }}"
    fn_kwargs:
        <<: *preprocess_args
    << endblock tokenize_eval
    -- endfilter
<< endblock datasets
-- endfilter
