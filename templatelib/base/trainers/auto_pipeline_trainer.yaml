-- extends 'trainers/pipeline_trainer.yaml'
## Automatic model splitting via torch.export()

[trainer_meta_config]
    == super()
    ## Set these in your sub-project
    ##-- set ns.pipeline_layers = 16
    ##-- set ns.pipeline_segments = 4
    ##-- set ns.pipeline_microbatches = 4
    ##-- set ns.split_layer_prefix = "causal_lm.layer_stack.layers."
    ## Set to match number of pipeline segments on each node
    ## -- set ns.nproc_per_node = N

[trainer_header]
    == super()
# pipeline_layers: {{ ns.pipeline_layers }}
# pipeline_segments: {{ ns.pipeline_segments }}
# pipeline_microbatches: {{ ns.pipeline_microbatches }}
# split_layer_prefix: "{{ ns.split_layer_prefix }}"

[pp_strategy]
    [split_spec]
.define: &split_spec !dict
    ## Define where to split the model, based upon the total number of layers and the number of segments.
    ## While not optimal, this is probably a good starting point.
-- for i in range(1, ns.pipeline_segments):
    {{ ns.split_layer_prefix }}{{i * (ns.pipeline_layers // ns.pipeline_segments)}}: "beginning"
-- endfor

    [model_splitter]
.define: &model_splitter !call:forgather.ml.trainer.pipeline:create_automatic_splitter
    split_spec: *split_spec

[trainer_args]
    == super()
    n_microbatches: {{ ns.pipeline_microbatches }}

[trainer_constructor]
    == super()
    # **auto PipelineTrainer**
    enable_activation_checkpoint_fn: !partial:forgather.ml.trainer.pipeline:insert_activation_checkpoints
        targets: '^layers\.(\d+)$'
