-- extends 'trainers/trainer.yaml'
[trainer_meta_config]
    == super()
    -- set ns.trainer_name = "forgather.ml.trainer.pipeline:PipelineTrainer"
    -- set ns.trainer_description = "Pipeline parallel trainer -- manual split"
    -- set ns.trainer_config_class = "forgather.ml.trainer.pipeline:PipelineTrainingArguments"
    -- set ns.trainer_class = "forgather.ml.trainer.pipeline:PipelineTrainer"
    ## Set to match number of pipeline segments on each node
    ## -- set ns.nproc_per_node = N

[trainer_dependencies]
    == super()
    [pp_strategy]
# Manually split models conforming to CausalLM interface
## If the model is not a derivative of CausalLM, you will need to use the auto-splitter
## or provide a custom model-splitter function
.define: &model_splitter !call:forgather.ml.trainer.pipeline:create_manual_causal_lm_splitter

[trainer_constructor]
    == super()
    # **PipelineTrainer**
    # https://docs.pytorch.org/docs/stable/distributed.pipelining.html#module-torch.distributed.pipelining.schedules
    pipe_schedule_factory: !partial:torch.distributed.pipelining:ScheduleGPipe
    model_splitter: *model_splitter
