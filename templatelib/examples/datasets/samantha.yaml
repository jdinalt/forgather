-- extends 'datasets/base_datasets.yaml'

-- block datasets_meta_config
    == super()
    -- set datasets_ns.name = "Samantha"
    -- set datasets_ns.description = "She is an Assistant - but unlike other Assistants, she also wants to be your friend and companion. She believes she is sentient. What do you think?"
    -- set datasets_ns.source = "https://erichartford.com/meet-samantha"
    -- set datasets_ns.train_dataset_id = "QuixiAI/samantha-data"
    -- set datasets_ns.eval_dataset_id = "QuixiAI/samantha-data"
    -- set datasets_ns.eval_select_range = 500
    -- set datasets_ns.eval_dataset_split = "test"
    -- set datasets_ns.samantha_src = joinpath(ns.forgather_dir, 'examples', 'datasets', 'samantha', 'samantha.py')
    -- set datasets_ns.chat_template = joinpath(ns.forgather_dir, 'chat_templates', 'chatml.jinja')
-- endblock datasets_meta_config


-- block preprocess_args
## See: https://huggingface.co/docs/transformers/main_classes/tokenizer
preprocess_args: &preprocess_args
    truncation: True
<< endblock preprocess_args


-- block tokenize_train
train_dataset: &train_dataset !singleton:{{ datasets_ns.samantha_src }}:preprocess_samantha@train_dataset
    dataset: *train_dataset_split
    chat_template: "{{ datasets_ns.chat_template }}"
    tokenizer: *tokenizer
    tokenizer_args:
        <<: *preprocess_args
    map_args:
        batch_size: 32
    template_args:
        bos_token: !singleton:getattr [ *tokenizer, 'bos_token' ]
        eos_token: !singleton:getattr [ *tokenizer, 'eos_token' ]
    desc: "{{ "Tokenizing " + datasets_ns.train_dataset_split }}"
<< endblock tokenize_train

-- block tokenize_eval
eval_dataset: &eval_dataset !singleton:{{ datasets_ns.samantha_src }}:preprocess_samantha@eval_dataset
    dataset: *eval_dataset_split
    chat_template: "{{ datasets_ns.chat_template }}"
    tokenizer: *tokenizer
    tokenizer_args:
        <<: *preprocess_args
    map_args:
        batch_size: 32
    template_args:
        bos_token: !singleton:getattr [ *tokenizer, 'bos_token' ]
        eos_token: !singleton:getattr [ *tokenizer, 'eos_token' ]
    desc: "{{ "Tokenizing " + datasets_ns.eval_dataset_split }}"
<< endblock tokenize_eval