[tokenizer]
.define: &tokenizer !call:forgather:from_project

[model_args]
.define: &model_args !call:torchtitan.models.llama3.model.args:TransformerModelArgs
    vocab_size: !call:len [ *tokenizer ]
    eos_id: !call:getattr [ *tokenizer, 'eos_token_id' ]
    max_seq_len: !call:getattr [ *tokenizer, "model_max_length" ]

[model_factory]
.define: &model_factory !partial:torchtitan.models.llama3.model.model:Transformer

[parallelize_fn]
.define: &parallelize_fn !partial:torchtitan.models.llama3.infra.parallelize:parallelize_llama

[pipeline_fn]
.define: &pipeline_fn !partial:torchtitan.models.llama3.infra.pipeline:pipeline_llama

[loss_fn]
.define: &loss_fn !call:forgather.ml.loss:CausalLoss

[state_dict_adapter]
.define: &state_dict_adapter !partial:torchtitan.models.llama3.model.state_dict_adapter:Llama3StateDictAdapter
