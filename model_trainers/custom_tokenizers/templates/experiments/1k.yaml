-- extends 'project.yaml'

-- block experiment_metadata
    == super()
    ## Experiment Metadata
    -- set ns.EXPERIMENT_NAME = "1k tokenizer"
    -- set ns.EXPERIMENT_DESCRIPTION = "tiny_2k_bpe tokenizer definition with 1k tokens."
    -- set ns.LOG_NAME = "1k"
-- endblock experiment_metadata


-- block construct_new_model
    -- include 'experiment.model_config'
-- endblock construct_new_model

-- block trainer_callbacks
    -- include 'experiment.callbacks'
<< endblock trainer_callbacks

#-------------------- experiment.model_config --------------------
-- extends 'project.model_config'

-- block model_meta_config
    == super()
    -- set model_def.description = "Tiny model with 1k tokenizer" 
-- endblock model_meta_config

## Replace default tokenizer with custom tokenizer
-- block model_tokenizer
    -- include "experiment.tokenizer"
<< endblock model_tokenizer

#-------------------- experiment.tokenizer --------------------
-- extends 'project.tokenizer'

-- block tokenizer_meta_config
    == super()
    -- set tok_def.name = "tiny_1k_bpe"
    -- set tok_def.description = "Smaller tiny tokenizer" 
    -- set tok_def.output_dir = path_join(ns.TOKENIZERS_DIR, 'tiny_stories_1k')
-- endblock tokenizer_meta_config

# Reduce vocabulary to 1000 tokens
-- block tokenizer_custom_definition
    == super()
    -- set tok_def.vocab_size = 1000
-- endblock tokenizer_custom_definition

#-------------------- experiment.callbacks --------------------
-- extends 'tiny.callbacks'

-- block text_gen_callback_args
    == super()

    # Override to compensate for less information in each token
    max_new_tokens: 80
<< endblock text_gen_callback_args