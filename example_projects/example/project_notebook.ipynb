{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e422f35-7a08-4a50-a075-51a68b5c3994",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "[forgather/config.py](../../forgather/config.py)  \n",
    "[forgather/latent.py](../../forgather/latent.py)  \n",
    "[forgather/dynamic.py](../../forgather/dynamic.py)  \n",
    "\n",
    "**Experiments Definitions**  \n",
    "[meta_config.yaml](meta_config.yaml)\n",
    "\n",
    "[templates/experiment.yaml](forgather_demo/experiment%201.yaml)  \n",
    "[templates/paths.yaml](templates/paths.yaml)  \n",
    "[templates/whitelist.yaml](templates/whitelist.yaml)  \n",
    "[templates/trainer_config.yaml](templates/trainer_config.yaml)    \n",
    "\n",
    "[templates/common/whitelist.yaml](../../templates/common/whitelist.yaml)  \n",
    "[templates/common/defaults.yaml](../../templates/common/defaults.yaml)  \n",
    "[templates/common/helpers.yaml](../../templates/common/helpers.yaml)  \n",
    "[templates/common/trainer/base_trainer.yaml](../../templates/common/trainer/base_trainer.yaml)  \n",
    "[templates/common/causal_lm/base_train.yaml](../../templates/common/causal_lm/base_train.yaml)  \n",
    "[model_zoo/models/vanilla_transformer/vanilla_transformer.yaml](../../model_zoo/models/vanilla_transformer/vanilla_transformer.yaml)  \n",
    "[model_zoo/models/model_zoo_whitelist.yaml](../../model_zoo/models/model_zoo_whitelist.yaml)  \n",
    "\n",
    "**Model Code**  \n",
    "\n",
    "[model_zoo/models/vanilla_transformer/vanilla_transformer.py](../../model_zoo/models/vanilla_transformer/vanilla_transformer.py)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5a90f-6386-4b8e-89ce-ec19195f7dff",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bffdcc-00ac-4adc-b3fd-974df44d09fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assets_dir: '../..'\n",
      "datasets_dir: '../../datasets'\n",
      "experiment_dir: './templates/experiments/'\n",
      "model_dir: './output_models'\n",
      "model_src_dir: '../../model_zoo'\n",
      "project_dir: '.'\n",
      "project_templates: './templates'\n",
      "scripts_dir: '../../scripts'\n",
      "search_paths:\n",
      "  - '../../templates'\n",
      "  - './templates'\n",
      "templates: '../../templates'\n",
      "tokenizer_dir: '../../tokenizers'\n",
      "train_script_path: '../../scripts/train_script.py'\n",
      "whitelist_path: './templates/whitelist.yaml'\n",
      "****************************************\n",
      "Meta Config: meta_config.yaml\n",
      "Experiment Path: ./templates/experiments/example/experiment.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "modules_path = os.path.join('..', '..')\n",
    "if modules_path not in sys.path: sys.path.insert(0, modules_path)\n",
    "import shutil\n",
    "\n",
    "from pprint import pformat, pp\n",
    "from transformers import set_seed\n",
    "\n",
    "from forgather.config import (\n",
    "    preprocess_config,\n",
    "    load_config,\n",
    "    load_whitelist_as_set,\n",
    "    materialize_config,\n",
    "    enumerate_whitelist_exceptions,\n",
    "    pconfig,\n",
    ")\n",
    "from forgather import Latent\n",
    "from aiws.dotdict import DotDict\n",
    "\n",
    "# Path to your project meta-config\n",
    "meta_config_path = 'meta_config.yaml'\n",
    "experiment_name = 'example'\n",
    "# Path to an experiment config to run.\n",
    "\n",
    "metacfg = DotDict(load_config(meta_config_path).config)\n",
    "pconfig(metacfg)\n",
    "\n",
    "# Get path to selected experiment\n",
    "experiment_path = os.path.join(metacfg.experiment_dir, experiment_name, 'experiment.yaml')\n",
    "\n",
    "print('*' * 40)\n",
    "print(f'Meta Config: {meta_config_path}')\n",
    "print(f'Experiment Path: {experiment_path}')\n",
    "\n",
    "def preprocess():\n",
    "    return preprocess_config(experiment_path, search_path=metacfg.search_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0835a75-8ac2-4e9a-9937-d9c260cdc211",
   "metadata": {},
   "source": [
    "### Preprocess Configuration\n",
    "\n",
    "#### preprocess_config() : Preprocess a configuration file.\n",
    "\n",
    "```python\n",
    "def preprocess_config(\n",
    "    config:  os.PathLike | str, *,\n",
    "    search_path: str | List[str] = '.',\n",
    "    load_method: LoadMethod = DEFAULT_LOAD_METHOD,\n",
    "    **kwargs,\n",
    ") -> str:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9c21cd-877d-4544-a16b-7aeb7606f577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1: ############## Experiment ##############\n",
      "     2: \n",
      "     3: # The latest example\n",
      "     4: # 2024-07-10 04:29:25\n",
      "     5: # Description: It's not supid, it's advanced!\n",
      "     6: # Model: anonymous_model\n",
      "     7: # World Size: 1\n",
      "     8: # Hostname: hal9000\n",
      "     9: # Script Args: N/A\n",
      "    10: \n",
      "    11: ############# Config Vars ##############\n",
      "    12: \n",
      "    13: # ns.TOKENIZERS_DIR: \"../../tokenizers\"\n",
      "    14: # ns.MODELS_DIR: \"./output_models\"\n",
      "    15: # ns.DATASETS_DIR: \"../../datasets\"\n",
      "    16: # ns.SCRIPTS_DIR: \"../../scripts\"\n",
      "    17: # ns.MODEL_SOURCE_DIR: \"../../model_zoo\"\n",
      "    18: # ns.OUTPUT_DIR: \"./output_models/anonymous_model\"\n",
      "    19: # ns.LOGGING_DIR: path = \"./output_models/anonymous_model/runs/The latest example_1720585765000114070\"\n",
      "    20: # ns.CREATE_NEW_MODEL: path = False\n",
      "    21: # ns.SAVE_MODEL: path = True\n",
      "    22: \n",
      "    23: ####### Additional Dependencies ########\n",
      "    24: \n",
      "    25: # Experiment tracking: Tensorboard SummaryWriter\n",
      "    26: .define: &summary_writer !callable:torch.utils.tensorboard:SummaryWriter\n",
      "    27:     - \"./output_models/anonymous_model/runs/The latest example_1720585765000114070\"\n",
      "    28: \n",
      "    29: ################ Model #################\n",
      "    30: # Name: Custom Model Loader\n",
      "    31: # Description: Load a pre-trained custom model.\n",
      "    32: \n",
      "    33: # model_def.model_path = \"./output_models/anonymous_model\"\n",
      "    34: \n",
      "    35: #**** Tokenizer ****\n",
      "    36: \n",
      "    37: .define: &tokenizer !callable:transformers:AutoTokenizer.from_pretrained\n",
      "    38:     - \"./output_models/anonymous_model\"\n",
      "    39: \n",
      "    40: #**** Model ****\n",
      "    41: \n",
      "    42: .define: &model !callable:transformers:AutoModel.from_pretrained\n",
      "    43:     args: [ \"./output_models/anonymous_model\" ]\n",
      "    44:     kwargs: { trust_remote_code: True }\n",
      "    45: \n",
      "    46: ############### Datasets ###############\n",
      "    47: \n",
      "    48: # Name: Tiny Stories 2K\n",
      "    49: # Description: Tiny Stories dataset, pre-tokenized with the tiny_2k tokenizer.\n",
      "    50: \n",
      "    51: # dataset_def.dataset_name_or_path = \"../../datasets/tiny_stories_tokenized\"\n",
      "    52: # dataset_def.dataset_train_split = \"train\"\n",
      "    53: # dataset_def.dataset_validation_split = \"validation\"\n",
      "    54: \n",
      "    55: #**** Load Datasets ****\n",
      "    56: \n",
      "    57: .define: &dataset !callable:datasets:load_from_disk [ \"../../datasets/tiny_stories_tokenized\" ]\n",
      "    58: \n",
      "    59: #**** Get Splits ****\n",
      "    60: \n",
      "    61: .define: &train_dataset !callable:forgather.construct:get_item [ *dataset, \"train\" ]\n",
      "    62: .define: &eval_dataset !callable:forgather.construct:get_item [ *dataset, \"validation\" ]\n",
      "    63: \n",
      "    64: ########## Trainer Callbacks ###########\n",
      "    65: \n",
      "    66: .define: &trainer_callbacks\n",
      "    67:     - !callable:aiws.default_callbacks:JsonLogger []\n",
      "    68:     - !callable:aiws.tb_logger:TBLogger\n",
      "    69:         args: [ *summary_writer ]\n",
      "    70:         kwargs:\n",
      "    71:             date: \"2024-07-10 04:29:25\"\n",
      "    72:             name: \"The latest example\"\n",
      "    73:             description: \"It's not supid, it's advanced!\"\n",
      "    74:             args: N/A\n",
      "    75:             world_size: 1\n",
      "    76:             config: !callable:pp_config\n",
      "    77: \n",
      "    78: ############ Data Collator #############\n",
      "    79: \n",
      "    80: .define: &data_collator !callable:transformers:DataCollatorForLanguageModeling\n",
      "    81:     args:\n",
      "    82:         - *tokenizer\n",
      "    83:     kwargs:\n",
      "    84:         mlm: False\n",
      "    85:         return_tensors: pt\n",
      "    86: \n",
      "    87: ############### Trainer ################\n",
      "    88: \n",
      "    89: # Name: Custom aiws.trainer.Trainer\n",
      "    90: # Description: A lightweight, extensible trainer; does not support multiple GPUs\n",
      "    91: \n",
      "    92: #**** Trainer Args ****\n",
      "    93: \n",
      "    94: .define: &trainer_args\n",
      "    95:     output_dir: \"./output_models/anonymous_model\"\n",
      "    96:     logging_dir: \"./output_models/anonymous_model/runs/The latest example_1720585765000114070\"\n",
      "    97:     overwrite_output_dir: True\n",
      "    98:     per_device_train_batch_size: 16\n",
      "    99:     per_device_eval_batch_size: 16\n",
      "   100:     learning_rate: 1.0e-3\n",
      "   101:     num_train_epochs: 1\n",
      "   102:     eval_steps: 500\n",
      "   103:     logging_steps: 500\n",
      "   104:     seed: 42\n",
      "   105:     eval_strategy: \"steps\"\n",
      "   106:     save_strategy: \"no\"\n",
      "   107:     logging_strategy: \"steps\"\n",
      "   108:     lr_scheduler_type: \"constant\"\n",
      "   109:     max_steps: 2000\n",
      "   110: \n",
      "   111: #**** Trainer Constructor ****\n",
      "   112: \n",
      "   113: .define: &trainer !callable:aiws.trainer:Trainer\n",
      "   114:     model: *model\n",
      "   115:     args: !callable:aiws.trainer_types:TrainingArguments\n",
      "   116:         <<: *trainer_args\n",
      "   117:     data_collator: *data_collator\n",
      "   118:     train_dataset: *train_dataset\n",
      "   119:     eval_dataset: *eval_dataset\n",
      "   120:     tokenizer: *tokenizer\n",
      "   121:     callbacks: *trainer_callbacks\n",
      "   122: \n",
      "   123: ############## Pre Config ##############\n",
      "   124: \n",
      "   125: # Undefined\n",
      "   126: \n",
      "   127: ############ Configuration #############\n",
      "   128: \n",
      "   129: output_dir: \"./output_models/anonymous_model\"\n",
      "   130: logging_dir: \"./output_models/anonymous_model/runs/The latest example_1720585765000114070\"\n",
      "   131: experiment_name: \"The latest example\"\n",
      "   132: experiment_description: \"It's not supid, it's advanced!\"\n",
      "   133: trainer: *trainer\n",
      "   134: do_save: True\n",
      "   135: \n",
      "   136: ############# Post Config ##############\n",
      "   137: \n",
      "   138: # Undefined\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(preprocess().with_line_numbers())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3438afc6-999c-4031-8193-ec230dfcdc9e",
   "metadata": {},
   "source": [
    "Run the cell and click the link to open the preprocessed file in the notebook.  \n",
    "[preprocessed_config.yaml](preprocessed_config.yaml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bd1cab-66a4-4784-96ce-8514890291bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only preprocess the experiment template\n",
    "pp_config = preprocess()\n",
    "\n",
    "with open('preprocessed_config.yaml', 'w') as f:\n",
    "    f.write(pp_config.with_line_numbers(False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f6eba1-e054-4e8d-99e3-57030302a337",
   "metadata": {},
   "source": [
    "### Preprocess and Load the Whitelist\n",
    "```python\n",
    "def load_whitelist_as_set(\n",
    "    config: os.PathLike | str, *,\n",
    "    preprocess: bool = True,\n",
    "    search_path: str | List[str] = '.',\n",
    "    load_method: LoadMethod = DEFAULT_LOAD_METHOD\n",
    ") -> Set[str]:\n",
    "```\n",
    "Load a whitelist configuration from a file or string\n",
    "\n",
    "This is essentially just load_config, but it normalizes the paths in the whitelist and converts the list to a set, to improve search performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb04018a-f7de-400b-91d3-8b07efec0c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config:\n",
      "  - '/home/dinalt/ai_assets/aiworkshop/model_zoo/attention_only/attention_only.py:TransformerConfig'\n",
      "  - '/home/dinalt/ai_assets/aiworkshop/model_zoo/attention_only/attention_only.py:TransformerModel'\n",
      "  - '/home/dinalt/ai_assets/aiworkshop/model_zoo/vanilla_transformer/vanilla_transformer.py:VanillaTransformer'\n",
      "  - '/home/dinalt/ai_assets/aiworkshop/model_zoo/vanilla_transformer/vanilla_transformer.py:VanillaTransformerConfig'\n",
      "  - 'accelerate:DataLoaderConfiguration'\n",
      "  - 'aiws.accel_trainer:AccelTrainer'\n",
      "  - 'aiws.accel_trainer:AccelTrainingArguments'\n",
      "  - 'aiws.construct:register_for_auto_class'\n",
      "  - 'aiws.default_callbacks:InfoCallback'\n",
      "  - 'aiws.default_callbacks:JsonLogger'\n",
      "  - 'aiws.default_callbacks:ProgressCallback'\n",
      "  - 'aiws.tb_logger:TBLogger'\n",
      "  - 'aiws.trainer:Trainer'\n",
      "  - 'aiws.trainer_types:TrainingArguments'\n",
      "  - 'datasets:load_dataset'\n",
      "  - 'datasets:load_from_disk'\n",
      "  - 'forgather.construct:flatten'\n",
      "  - 'forgather.construct:get_attr'\n",
      "  - 'forgather.construct:get_item'\n",
      "  - 'torch.utils.tensorboard:SummaryWriter'\n",
      "  - 'transformers:AutoModel.from_pretrained'\n",
      "  - 'transformers:AutoTokenizer.from_pretrained'\n",
      "  - 'transformers:DataCollatorForLanguageModeling'\n",
      "  - 'transformers:Trainer'\n",
      "  - 'transformers:TrainingArguments'\n",
      "pp_config:\n",
      "       1: # Dynamic Loader Whitelist\n",
      "       2: # Only constructors listed here are allowed in the configuration file.\n",
      "       3: # This is intended to prevent the arbitrary execution of any Python code by\n",
      "       4: # a configuration script. Be very careful what you add when running\n",
      "       5: # a confiuration from an untrusted source!\n",
      "       6: \n",
      "       7: # Transformers\n",
      "       8: - transformers:AutoTokenizer.from_pretrained\n",
      "       9: # TODO: AutoModel.from_pretrained has a 'trust_remote_code' flag; deal with this.\n",
      "      10: - transformers:AutoModel.from_pretrained\n",
      "      11: - transformers:DataCollatorForLanguageModeling\n",
      "      12: - transformers:Trainer\n",
      "      13: - transformers:TrainingArguments\n",
      "      14: \n",
      "      15: # Accelerate\n",
      "      16: - accelerate:DataLoaderConfiguration\n",
      "      17: \n",
      "      18: # Datasets\n",
      "      19: - datasets:load_from_disk\n",
      "      20: # TODO: load_dataset has a 'trust_remote_code' flag; deal with this.\n",
      "      21: - datasets:load_dataset\n",
      "      22: \n",
      "      23: # Torch\n",
      "      24: - torch.utils.tensorboard:SummaryWriter\n",
      "      25: \n",
      "      26: # AIWS\n",
      "      27: - aiws.trainer:Trainer\n",
      "      28: - aiws.trainer_types:TrainingArguments\n",
      "      29: - aiws.accel_trainer:AccelTrainer\n",
      "      30: - aiws.accel_trainer:AccelTrainingArguments\n",
      "      31: - aiws.default_callbacks:InfoCallback\n",
      "      32: - aiws.default_callbacks:ProgressCallback\n",
      "      33: - aiws.default_callbacks:JsonLogger\n",
      "      34: - aiws.tb_logger:TBLogger\n",
      "      35: - aiws.construct:register_for_auto_class\n",
      "      36: \n",
      "      37: # forgather\n",
      "      38: - forgather.construct:get_item\n",
      "      39: - forgather.construct:flatten\n",
      "      40: - forgather.construct:get_attr\n",
      "      41: - ../../model_zoo/attention_only/attention_only.py:TransformerConfig\n",
      "      42: - ../../model_zoo/attention_only/attention_only.py:TransformerModel\n",
      "      43: - ../../model_zoo/vanilla_transformer/vanilla_transformer.py:VanillaTransformerConfig\n",
      "      44: - ../../model_zoo/vanilla_transformer/vanilla_transformer.py:VanillaTransformer\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "whitelist_out = load_whitelist_as_set(metacfg.whitelist_path, search_path=metacfg.search_paths)\n",
    "pconfig(whitelist_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6f72ba-670d-46fb-87c3-f9ce5f2c58b4",
   "metadata": {},
   "source": [
    "#### Check Whitelist Requirements\n",
    "\n",
    "If you would like to see which import-specs are used in a configuraiton (or which are missing), you can use enumerate_whitelist_exceptions().\n",
    "```python\n",
    "def enumerate_whitelist_exceptions(config: Any, whitelist: Container = set())\n",
    "```\n",
    "Print all import-specs not matching the whitelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630c7929-da58-40db-b430-a8687e0a0541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "whitelist = whitelist_out.config\n",
    "#whitelist = set()\n",
    "enumerate_whitelist_exceptions(load_config(experiment_path, search_path=metacfg.search_paths).config, whitelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4848270-6d49-412f-a3a2-b72222461140",
   "metadata": {},
   "source": [
    "### Materialize the Configuration\n",
    "\n",
    "#### materialize_config() : Materialize the Latent objects in the configuration\n",
    "```python\n",
    "def materialize_config(\n",
    "    config: Any,\n",
    "    whitelist: Container | os.PathLike | str = None,\n",
    "    preprocess: bool = True,\n",
    "    search_path: str | List[str] = '.',\n",
    "    load_method: LoadMethod=DEFAULT_LOAD_METHOD,\n",
    "    pp_kwargs: Dict[str, Any] = {},\n",
    "    kwargs: Dict[str, Callable] = {},\n",
    ") -> MaterializedOutput:\n",
    "```\n",
    "- config: An instantiated, but Latent, configuration; a preprocessed configuration string; or a path to a configuraiton file.  \n",
    "- whitelist: A Container type, which means any object which supports 'str is in container'  \n",
    "- preprocess: Preprocess the string or file. Only applies if input is a path or string.  \n",
    "- load_method: One of \"from_file\", \"from_string\", \"from_file_search\"  \n",
    "- search_path: A str or List\\[str\\] paths to search for templates; also applies to \"from_file_search\" load method.  \n",
    "- pp_kwargs: Arguments to pass to the template, if preprocessing is to be performed.  \n",
    "- kwargs: A mapping str -> Callable to substitute when materializing the final config. This allows passing already instantiated objects into the config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce4a60c-ce9b-4738-9eb1-4deb39d559ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do_save: True\n",
      "experiment_description: 'It's not supid, it's advanced!'\n",
      "experiment_name: 'The latest example'\n",
      "logging_dir: './output_models/anonymous_model/runs/The latest example_1720586293852204866'\n",
      "output_dir: './output_models/anonymous_model'\n",
      "trainer:\n",
      "  Trainer(model=VanillaTransformer(\n",
      "    (embedding): Embedding(2000, 256)\n",
      "    (positional_encoder): PositionalEncoder()\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerLayer(\n",
      "        (attention): MultiheadAttention(\n",
      "          (query_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (key_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "          (value_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        )\n",
      "        (feedforward): FeedforwardLayer(\n",
      "          (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "          (activation): ReLU()\n",
      "          (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=256, out_features=2000, bias=True)\n",
      "  ),args=TrainingArguments(per_device_train_batch_size=16, output_dir='./output_models/anonymous_model', overwrite_output_dir=True, per_device_eval_batch_size=16, max_steps=2000, logging_steps=500, eval_steps=500, save_steps=500, learning_rate=0.001, num_train_epochs=1, seed=42, lr_scheduler_type='constant', warmup_steps=0, device=None, logging_dir='./output_models/anonymous_model/runs/The latest example_1720586293852204866', eval_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_strategy=<IntervalStrategy.STEPS: 'steps'>, save_strategy=<IntervalStrategy.NO: 'no'>, logging_first_step=False, eval_delay=0, save_total_limit=2),data_collator=DataCollatorForLanguageModeling(tokenizer=PreTrainedTokenizerFast(name_or_path='../../tokenizers/tiny_stories_2k', vocab_size=2000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|BOS|>', 'eos_token': '<|EOS|>', 'unk_token': '<|UNK|>', 'pad_token': '<|PAD|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "  \t0: AddedToken(\"<|BOS|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "  \t1: AddedToken(\"<|PAD|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "  \t2: AddedToken(\"<|EOS|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "  \t3: AddedToken(\"<|UNK|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "  }, mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt'),train_dataset=Dataset({\n",
      "      features: ['input_ids'],\n",
      "      num_rows: 2119719\n",
      "  }),eval_dataset=Dataset({\n",
      "      features: ['input_ids'],\n",
      "      num_rows: 2199\n",
      "  }),tokenizer=PreTrainedTokenizerFast(name_or_path='../../tokenizers/tiny_stories_2k', vocab_size=2000, model_max_length=2048, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|BOS|>', 'eos_token': '<|EOS|>', 'unk_token': '<|UNK|>', 'pad_token': '<|PAD|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "  \t0: AddedToken(\"<|BOS|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "  \t1: AddedToken(\"<|PAD|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "  \t2: AddedToken(\"<|EOS|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "  \t3: AddedToken(\"<|UNK|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "  },model_init=None,callbacks=[<aiws.default_callbacks.ProgressCallback object at 0x7f0402444310>, <aiws.default_callbacks.InfoCallback object at 0x7f04024443d0>, <aiws.default_callbacks.JsonLogger object at 0x7f0402445540>, <aiws.tb_logger.TBLogger object at 0x7f04024441c0>],)\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)\n",
    "\n",
    "config_output = materialize_config(experiment_path, whitelist=metacfg.whitelist_path, search_path=metacfg.search_paths)\n",
    "config = DotDict(config_output.config)\n",
    "pconfig(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec21d135-1575-4684-a639-ce1c38162063",
   "metadata": {},
   "source": [
    "### Run Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ccce36-feda-4ba1-8fb9-31a5b3d7871c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d498667de54f482abcbb59796803b231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_examples: 2,119,712\n",
      "total_train_samples: 2,119,712\n",
      "per_device_train_batch_size: 16\n",
      "actual_per_device_batch_size: 16\n",
      "total_train_batch_size: 16\n",
      "max_steps: 2,000\n",
      "total_parameters: 1.9M\n",
      "trainable_parameters: 1.9M\n",
      "model:\n",
      "VanillaTransformer(\n",
      "  (embedding): Embedding(2000, 256)\n",
      "  (positional_encoder): PositionalEncoder()\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x TransformerLayer(\n",
      "      (attention): MultiheadAttention(\n",
      "        (query_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (key_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (value_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (feedforward): FeedforwardLayer(\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (output_projection): Linear(in_features=256, out_features=2000, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "2024-07-09 23:01:06          500  0.0   train-loss: 3.83067   learning-rate: 1.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96272829bdab4c90b4968fc9a2304d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-09 23:01:06          500  0.0   eval-loss:  3.24676   \n",
      "2024-07-09 23:01:10        1,000  0.01  train-loss: 2.97355   learning-rate: 1.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae99609af244c159f7f009644acb21f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-09 23:01:11        1,000  0.01  eval-loss:  2.84039   \n",
      "2024-07-09 23:01:15        1,500  0.01  train-loss: 2.68934   learning-rate: 1.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c424facf329481aaacb5f3aaf77fe74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-09 23:01:15        1,500  0.01  eval-loss:  2.63415   \n",
      "2024-07-09 23:01:19        2,000  0.02  train-loss: 2.51999   learning-rate: 1.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d27ab483a2904af6a78a1bffaed99692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-09 23:01:20        2,000  0.02  eval-loss:  2.52777   \n",
      "train_runtime: 18.08\n",
      "train_samples: 32,000\n",
      "step: 2,000\n",
      "train_samples_per_second: 1.77e+03\n",
      "train_steps_per_second: 110.6\n",
      "train_loss: 2.997\n",
      "epoch: 0.0151\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=2.519994020462036, metrics={'train_runtime': 18.078115224838257, 'train_samples': 32000, 'step': 2000, 'train_samples_per_second': 1770.096, 'train_steps_per_second': 110.631, 'train_loss': 2.997377872467041, 'epoch': 0.015096390453042677})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(42)\n",
    "config.trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a29692-aab9-44d6-b089-bf97e6f81d90",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2565208e-5df9-41f6-afc0-dd9d18d22d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import notebook_launcher\n",
    "\n",
    "# This is the entry-point for the spawned procceses.\n",
    "def training_loop(meta_config, experiment_name):\n",
    "    set_seed(42)\n",
    "    metacfg = DotDict(load_config(meta_config).config)\n",
    "\n",
    "    # Get Torch Distributed parameters from environ.\n",
    "    world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
    "    rank = int(os.environ.get('RANK', 0))\n",
    "    local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
    "    \n",
    "    config_output = materialize_config(\n",
    "        experiment_name,\n",
    "        metacfg.whitelist_path,\n",
    "        search_path=metacfg.search_paths,\n",
    "        pp_kwargs = dict(\n",
    "            world_size=world_size,\n",
    "            rank=rank,\n",
    "            local_rank=local_rank,\n",
    "        )\n",
    "    )\n",
    "    config = DotDict(config_output.config)\n",
    "    is_main_process = config.trainer.accelerator if hasattr(config.trainer, \"accelerator\") else True\n",
    "    # If you don't want all processes to print to the console...\n",
    "    if is_main_process:\n",
    "        print(\"**** Training Started *****\")\n",
    "        print(f\"experiment_name: {config.experiment_name}\")\n",
    "        print(f\"experiment_description: {config.experiment_description}\")\n",
    "        print(f\"output_dir: {config.output_dir}\")\n",
    "        print(f\"logging_dir: {config.logging_dir}\")\n",
    "\n",
    "    # This is where the actual 'loop' is.\n",
    "    metrics = config.trainer.train().metrics\n",
    "    \n",
    "    if is_main_process:\n",
    "        print(\"**** Training Completed *****\")\n",
    "        print(metrics)\n",
    "\n",
    "    metrics = config.trainer.evaluate()\n",
    "\n",
    "    if is_main_process:\n",
    "        print(\"**** Evaluation Completed *****\")\n",
    "        print(metrics)\n",
    "    \n",
    "    if config.do_save:\n",
    "        config.trainer.save_model()\n",
    "        if is_main_process:\n",
    "            print(f\"Model saved to: {config.trainer.args.output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5709fd93-5a27-487a-8aeb-166b8cd2274e",
   "metadata": {},
   "source": [
    "#### Run Training Loop Directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdbf0acd-89c0-423c-bb6f-f2b98b6d82e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training Started *****\n",
      "experiment_name: The latest example\n",
      "experiment_description: It's not supid, it's advanced!\n",
      "output_dir: ./output_models/anonymous_model\n",
      "logging_dir: ./output_models/anonymous_model/runs/The latest example_1720586319070237488\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c155d6ad1b9140d4833f29597a21ad82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_examples: 2,119,712\n",
      "total_train_samples: 2,119,712\n",
      "per_device_train_batch_size: 16\n",
      "actual_per_device_batch_size: 16\n",
      "total_train_batch_size: 16\n",
      "max_steps: 2,000\n",
      "total_parameters: 1.9M\n",
      "trainable_parameters: 1.9M\n",
      "model:\n",
      "VanillaTransformer(\n",
      "  (embedding): Embedding(2000, 256)\n",
      "  (positional_encoder): PositionalEncoder()\n",
      "  (layers): ModuleList(\n",
      "    (0-1): 2 x TransformerLayer(\n",
      "      (attention): MultiheadAttention(\n",
      "        (query_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (key_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "        (value_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "      )\n",
      "      (feedforward): FeedforwardLayer(\n",
      "        (linear1): Linear(in_features=256, out_features=512, bias=True)\n",
      "        (activation): ReLU()\n",
      "        (linear2): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (output_projection): Linear(in_features=256, out_features=2000, bias=True)\n",
      ")\n",
      "\n",
      "\n",
      "2024-07-10 04:38:43          500  0.0   train-loss: 3.83067   learning-rate: 1.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5bff7261b7a40dca6474e42ea1b659a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 04:38:43          500  0.0   eval-loss:  3.24676   \n",
      "2024-07-10 04:38:47        1,000  0.01  train-loss: 2.97355   learning-rate: 1.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08be6291febc4810b6cd67097258bd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 04:38:48        1,000  0.01  eval-loss:  2.84039   \n",
      "2024-07-10 04:38:51        1,500  0.01  train-loss: 2.68934   learning-rate: 1.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a137fe57dd3b47e9aa1e1a5b8c940a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 04:38:52        1,500  0.01  eval-loss:  2.63415   \n",
      "2024-07-10 04:38:56        2,000  0.02  train-loss: 2.51999   learning-rate: 1.00e-03\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0471611cfce74943ab3ffd1803f14428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 04:38:56        2,000  0.02  eval-loss:  2.52777   \n",
      "train_runtime: 17.29\n",
      "train_samples: 32,000\n",
      "step: 2,000\n",
      "train_samples_per_second: 1.851e+03\n",
      "train_steps_per_second: 115.7\n",
      "train_loss: 2.997\n",
      "epoch: 0.0151\n",
      "\n",
      "**** Training Completed *****\n",
      "{'train_runtime': 17.29047727584839, 'train_samples': 32000, 'step': 2000, 'train_samples_per_second': 1850.73, 'train_steps_per_second': 115.671, 'train_loss': 2.997377872467041, 'epoch': 0.015096390453042677}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f38b720fa14ba3a0aea42516df4b7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-07-10 04:38:56        2,000  0.02  eval-loss:  2.52777   \n",
      "**** Evaluation Completed *****\n",
      "{'eval_loss': 2.527772903442383}\n",
      "[2024-07-10 04:38:57,086] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "Model saved to: ./output_models/anonymous_model\n"
     ]
    }
   ],
   "source": [
    "training_loop(meta_config_path, experiment_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa3351-96d7-4769-8b45-99d103e1b941",
   "metadata": {},
   "source": [
    "#### Launch with Notebook Launcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd87183a-dbec-420e-ad2f-796384eb9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_launcher(\n",
    "    training_loop,\n",
    "    args=(meta_config_path, experiment_path,),\n",
    "    num_processes=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece555d-aa15-4b5e-a80e-20cb9fa9db52",
   "metadata": {},
   "source": [
    "### Train from a Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a399e7a-6220-426f-affa-f9bfba4b9a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_templates: 'templates'\n",
      "templates: '../../templates'\n",
      "tokenizer_dir: '../../tokenizers'\n",
      "datasets_dir: '../../datasets'\n",
      "assets_dir: '../..'\n",
      "search_paths:\n",
      "  - 'templates'\n",
      "  - '../../templates'\n",
      "  - '../../model_zoo'\n",
      "whitelist_path: 'templates/whitelist.yaml'\n",
      "model_src_dir: '../../model_zoo'\n",
      "script_dir: '../../scripts'\n",
      "train_script_path: '../../scripts/train_script.py'\n",
      "models_dir: 'output_models'\n",
      "dataset_id: 'roneneldan/TinyStories'\n",
      "tokenizer_def: '../../templates/common/tokenizers/tiny_2k_bpe.yaml'\n",
      "tokenizer_path: '../../tokenizers/tiny_stories_2k'\n",
      "tokenizers_whitelist: '../../templates/common/tokenizers/whitelist.yaml'\n"
     ]
    }
   ],
   "source": [
    "# Output train-script command line as a string\n",
    "def train_cmdline(metacfg, nproc='gpu'):\n",
    "    includes = ''.join(f\"-I '{inc}' \" for inc in metacfg.search_paths)\n",
    "    return f\"torchrun --standalone --nproc-per-node {nproc} '{metacfg.train_script_path}' -w '{metacfg.whitelist_path}' {includes} -s '{metacfg.assets_dir}'\"\n",
    "\n",
    "# Output train-script as command line as a bash-script\n",
    "# ./train.sh [<other-sli-args] <experiment-config-file>\n",
    "def make_bash_script(metacfg, script_path='train.sh', nproc='gpu'):\n",
    "    with open(script_path, 'w') as f:\n",
    "        f.write('#!/bin/bash\\n' + train_cmdline(metacfg) + ' \"${@}\"\\n')\n",
    "        os.chmod(f.fileno(), stat.S_IREAD|stat.S_IRUSR|stat.S_IWUSR|stat.S_IXUSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ae89f3-11cb-45d9-b4ec-6ac2ae35a5be",
   "metadata": {},
   "source": [
    "#### Generate Bash Script\n",
    "\n",
    "This will output a shell-script which will invoke the training script with the arguments for this project.\n",
    "\n",
    "```bash\n",
    "# Optional: Restrict the GPUs to use to a sub-set of those avialable.\n",
    "export CUDA_VISIBLE_DEVICES=\"0,1\"\n",
    "\n",
    "./train path_to_experiment.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61e3cdc6-925d-4b28-ae59-778c011dcd5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "torchrun --standalone --nproc-per-node gpu '../scripts/train_script.py' -w 'forgather_demo/whitelist.yaml' -I 'forgather_demo' -I '../templates' -I '../model_zoo'  -s '..' \"${@}\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "make_bash_script(metacfg)\n",
    "\n",
    "# Read back to verify\n",
    "with open('train.sh', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a3131-a09e-46de-8f60-6699f758630c",
   "metadata": {},
   "source": [
    "#### Run Training Script from Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108a0cf4-1c93-47cf-8888-ffb806df684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, this will run on all available GPUs. To restrict it to a sub-set, you can use this envrionment variable.\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "!{train_cmdline(metacfg)} 'forgather_demo/hf_trainer_experiment.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e49f3-d22c-4130-934b-460c0cf2e080",
   "metadata": {},
   "source": [
    "### View in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fafbb8c8-8f81-4eb2-a574-cd7999ec77ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "TensorBoard 2.16.2 at http://hal9000:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --bind_all --logdir output_models/test_model/runs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b3c45a-d962-4316-8146-afd0a1024614",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "Delete all of the output models produced by the demo and start over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "073be4ea-bebc-4f64-8248-3818d8717863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 'forgather_demo/output_models'\n"
     ]
    }
   ],
   "source": [
    "print(f\"Removing '{metacfg.models_dir}'\")\n",
    "shutil.rmtree(metacfg.models_dir, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed775b-a63b-4dd0-adbe-1c3d78de8898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
