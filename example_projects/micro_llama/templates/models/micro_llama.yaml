-- extends "models/base_language_model.yaml"

-- block model_meta_config
    == super()
    -- set model_def.name = "Micro Llama"
    -- set model_def.description = "A very small llama with a TinyStories 2K vocabulary."
<< endblock model_meta_config


-- block model_tokenizer
.define: &tokenizer !callable:transformers:AutoTokenizer.from_pretrained
    - "{{ path_join(ns.TOKENIZERS_DIR, 'tiny_stories_2k') }}"
<< endblock model_tokenizer


-- block model_config
.define: &model_config !callable:transformers:LlamaConfig
    vocab_size: !callable:forgather.construct:length [ *tokenizer ]
    hidden_size: 256
    num_attention_heads: 4
    num_hidden_layers: 4
    intermediate_size: 1024
<< endblock model_config


-- block model_constructor
.define: &model !callable:transformers:AutoModelForCausalLM.from_config
    args:
        - *model_config
    kwargs:
        <<: *model_constructor_args
<< endblock model_constructor