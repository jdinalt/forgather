-- extends 'project.yaml'

-- block experiment_metadata
    == super()
    ## Experiment Metadata
    -- set ns.EXPERIMENT_NAME = "Byte Tokenizer"
    -- set ns.EXPERIMENT_DESCRIPTION = "tiny_2k_bpe, reduced to the base 256 byte tokens + special tokens."
    -- set ns.LOG_NAME = "bytes"
-- endblock experiment_metadata


-- block construct_new_model
    -- include 'experiment.model_config'
-- endblock construct_new_model


-- block trainer_callbacks
    -- include 'experiment.callbacks'
<< endblock trainer_callbacks

#-------------------- experiment.model_config --------------------
-- extends 'project.model_config'

-- block model_meta_config
    == super()
    -- set model_def.description = "Tiny model with byte tokenizer" 
-- endblock model_meta_config

## Replace default tokenizer with custom tokenizer
-- block model_tokenizer
    -- include "experiment.tokenizer"
<< endblock model_tokenizer

#-------------------- experiment.tokenizer --------------------
-- extends 'project.tokenizer'

-- block tokenizer_meta_config
    == super()
    -- set tok_def.name = "Tiny Bytes"
    -- set tok_def.description = "Byte-level BPE tokenizer" 
    -- set tok_def.output_dir = path_join(ns.TOKENIZERS_DIR, 'tiny_bytes')
-- endblock tokenizer_meta_config

# Reduce vocabulary to 1000 tokens
-- block tokenizer_custom_definition
    == super()
    -- set tok_def.vocab_size = 256
-- endblock tokenizer_custom_definition

#-------------------- experiment.callbacks --------------------
-- extends 'tiny.callbacks'

-- block text_gen_callback_args
    == super()

    # Override to compensate for less information in each token
    max_new_tokens: 300
<< endblock text_gen_callback_args