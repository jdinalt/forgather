-- extends 'project.yaml'

-- block experiment_metadata
    == super()
    ## Experiment Metadata
    -- set ns.EXPERIMENT_NAME = "1k tokenizer"
    -- set ns.EXPERIMENT_DESCRIPTION = "tiny_2k_bpe tokenizer definition with 1k tokens."
-- endblock experiment_metadata


-- block construct_new_model
    -- include 'experiment.model_config'
-- endblock construct_new_model

#-------------------- experiment.model_config --------------------
-- extends 'project.model_config'

-- block model_meta_config
    == super()
    -- set model_def.name = "Tiny-d128-2L-1k"
    -- set model_def.description = "Tiny-d128-2L with a 1k tokenizer" 
-- endblock model_meta_config

## Replace default tokenizer with custom tokenizer
-- block model_tokenizer
    -- include "experiment.tokenizer"
<< endblock model_tokenizer

#-------------------- experiment.tokenizer --------------------
-- extends 'project.tokenizer'

-- block tokenizer_meta_config
    == super()
    -- set tok_def.name = "tiny_1k_bpe"
    -- set tok_def.description = "Smaller tiny tokenizer" 
    -- set tok_def.template_path = path_join(ns.EXPERIMENT_DIR, '1k.yaml')
    -- set tok_def.output_dir = path_join(ns.TOKENIZERS_DIR, 'tiny_stories_1k')
-- endblock tokenizer_meta_config

# Reduce vocabulary to 1000 tokens
-- block tokenizer_custom_definition
    == super()
    -- set tok_def.vocab_size = 1000
-- endblock tokenizer_custom_definition