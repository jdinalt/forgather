{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e422f35-7a08-4a50-a075-51a68b5c3994",
   "metadata": {},
   "source": [
    "# Model Notebook\n",
    "Useful for debugging configurations and viewing project configuration details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5a90f-6386-4b8e-89ce-ec19195f7dff",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Configure defaults and select a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bffdcc-00ac-4adc-b3fd-974df44d09fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set defaults\n",
    "default_models_directory = '../example_projects'\n",
    "default_model = \"\"\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "fc = FileChooser(\n",
    "    os.path.join(default_models_directory, default_model), show_only_dirs=True,\n",
    "    title=\"Select a Model Directory\", select_default=True)\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4681a4d-fc01-43f7-a28f-308d6f4869b8",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966a8a33-55a2-4ff0-b364-bd0ddbad4675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "modules_path = os.path.join('..', 'src')\n",
    "if modules_path not in sys.path: sys.path.insert(0, modules_path)\n",
    "from pprint import pformat, pp\n",
    "from IPython import display as ds\n",
    "\n",
    "from tutorial.inference import show_predictions\n",
    "import forgather.ml.notebooks as nb\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "assert os.path.exists(fc.selected_path), \"Model directory does not exist.\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(fc.selected_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    fc.selected_path,\n",
    "    local_files_only=True,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "print(model)\n",
    "print(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef93cee-f35e-4a89-98aa-df1076b163f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"\"\"One day, a little girl named Lily found a needle in her room. She knew it was difficult to play with it because it was sharp. Lily wanted to share the needle with her mom, so she could sew a button on her shirt.\n",
    "\n",
    "Lily went to her mom and said, \"Mom, I found this needle. Can you share it with me and sew my shirt?\" Her mom smiled and said, \"Yes, Lily, we can share the needle and fix your shirt.\"\n",
    "\n",
    "Together, they shared the needle and sewed the button on Lily's shirt.\n",
    "\"\"\"\n",
    "\n",
    "show_predictions(model, tokenizer, device=\"cpu\", text=[sample_text])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db6ded-ea4d-4f29-9832-9b357bd3da39",
   "metadata": {},
   "source": [
    "### Simple Text Gen\n",
    "This is a very simple text generator implementation.\n",
    "\n",
    "[tutorial_code.textgen](../tutorial_code/textgen.py)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e791db3-b315-46f9-900a-3cc770b3717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tutorial.textgen import TextGenerator\n",
    "\n",
    "# Test text generation.\n",
    "# Don't expect too much from this model, as the only input to each prediction is the previous word. \n",
    "text_gen = TextGenerator(model, tokenizer, \"cpu\", do_sample=True, seed=42)\n",
    "text = text_gen.prompt(\"One day, a little girl\", max_new_tokens=200)\n",
    "print(repr(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a06d9-e20a-42aa-9651-823363d0db06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18187c-bf39-47e9-bb8e-16ef547b4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/v4.34.1/en/generation_strategies\n",
    "\n",
    "class TextGen():\n",
    "    def __init__(self, model, tokenizer, device):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "\n",
    "    def generate(self, prompt, do_sample=True, top_k=50, top_p=0.9, max_new_tokens=500):\n",
    "        self.model.to(self.device)\n",
    "        input_ids = self.tokenizer(prompt, return_tensors='pt')['input_ids'].to(self.device)\n",
    "        outputs = model.generate(input_ids, do_sample=do_sample, top_k=top_k, top_p=top_p, max_new_tokens=max_new_tokens)\n",
    "        return tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb1513c-c98f-442b-b57f-217e76b668e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = TextGen(model, tokenizer, device=\"cpu\")\n",
    "print(gen.generate(\"One day, a little girl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f669f2e-266a-4fb9-bcd7-585957ffd6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
