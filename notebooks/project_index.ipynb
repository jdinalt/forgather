{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e422f35-7a08-4a50-a075-51a68b5c3994",
   "metadata": {},
   "source": [
    "# Project Index\n",
    "Useful for debugging configurations and viewing project configuration details.\n",
    "\n",
    "Debug configuration here: [Configuration Notebook](project_config.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26bffdcc-00ac-4adc-b3fd-974df44d09fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b02c4496c8c34e74a866ec5790bb2876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models', filename='', title='Seleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set defaults\n",
    "#default_projects_directory = '/home/dinalt/ai_assets/projects/experiments'\n",
    "default_projects_directory = '../examples/trainers'\n",
    "default_project = \"dynamic_models\"\n",
    "config_template = \"\"\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "fc = FileChooser(\n",
    "    os.path.join(default_projects_directory, default_project), show_only_dirs=True,\n",
    "    title=\"Select a Project Directory\", select_default=True)\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4681a4d-fc01-43f7-a28f-308d6f4869b8",
   "metadata": {},
   "source": [
    "## Project Info\n",
    "\n",
    "Note: This will fully construct the configuration, as this is required for resolving dynamic imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "966a8a33-55a2-4ff0-b364-bd0ddbad4675",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Dynamic Models\n",
       "\n",
       "This is a demonstraction of how to perform model archetecture experiments by using the configuration system to dynamically change module types.\n",
       "\n",
       "As most of the examples, we use \"Tiny Causal\" as a baseline, then make various changes for comparison.\n",
       "\n",
       "### Common Configuration\n",
       "- Tokenizer: tokenizers/tiny_2k_bpe.yaml\n",
       "    - Vocabulary Size: 2000\n",
       "    - Maximum Model Sequence: 2048\n",
       "- Dataset: datasets/tiny/tiny_stories_abridged.yaml\n",
       "    - Dataset ID: roneneldan/TinyStories\n",
       "    - Reference: https://arxiv.org/abs/2305.07759\n",
       "    - Train Select Range: 10% \n",
       "- Model:\n",
       "    - Model Dimension: 256\n",
       "    - MLP Dimension: 1024\n",
       "    - Layers: 4\n",
       "    - Heads: 2\n",
       "    - All Dropout Probabilities: 0.0\n",
       "- Trainer:\n",
       "    - Class: aiws.trainer.Trainer\n",
       "    - Epochs: 1\n",
       "    - Initial Learning Rate: 1.0e-3\n",
       "    - Train Batch Size: 32\n",
       "    - LR Sheduler: Cosine"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Meta Config\n",
       "Project Directory: /home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models\n",
       "\n",
       "Meta Config: [/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/meta.yaml](../examples/trainers/dynamic_models/meta.yaml)\n",
       "\n",
       "Template Search Paths:\n",
       "- [/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/templates](../examples/trainers/dynamic_models/templates)\n",
       "- [/home/dinalt/ai_assets/forgather/templates](../templates)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Available Configurations\n",
       "- [pre_ln.yaml](../examples/trainers/dynamic_models/templates/experiments/pre_ln.yaml)\n",
       "- [walsh_pe.yaml](../examples/trainers/dynamic_models/templates/experiments/walsh_pe.yaml)\n",
       "- [relu-glu.yaml](../examples/trainers/dynamic_models/templates/experiments/relu-glu.yaml)\n",
       "- [swish.yaml](../examples/trainers/dynamic_models/templates/experiments/swish.yaml)\n",
       "- [swi-glu.yaml](../examples/trainers/dynamic_models/templates/experiments/swi-glu.yaml)\n",
       "- [control.yaml](../examples/trainers/dynamic_models/templates/experiments/control.yaml)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Default Configuration: control.yaml\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Templates\n",
       "- [project.yaml](../examples/trainers/dynamic_models/templates/project.yaml)\n",
       "- [experiments/pre_ln.yaml](../examples/trainers/dynamic_models/templates/experiments/pre_ln.yaml)\n",
       "- [experiments/walsh_pe.yaml](../examples/trainers/dynamic_models/templates/experiments/walsh_pe.yaml)\n",
       "- [experiments/relu-glu.yaml](../examples/trainers/dynamic_models/templates/experiments/relu-glu.yaml)\n",
       "- [experiments/swish.yaml](../examples/trainers/dynamic_models/templates/experiments/swish.yaml)\n",
       "- [experiments/swi-glu.yaml](../examples/trainers/dynamic_models/templates/experiments/swi-glu.yaml)\n",
       "- [experiments/control.yaml](../examples/trainers/dynamic_models/templates/experiments/control.yaml)\n",
       "- [trainers/accel_trainer.yaml](../templates/trainers/accel_trainer.yaml)\n",
       "- [trainers/trainer.yaml](../templates/trainers/trainer.yaml)\n",
       "- [trainers/hf_trainer.yaml](../templates/trainers/hf_trainer.yaml)\n",
       "- [trainers/base_trainer.yaml](../templates/trainers/base_trainer.yaml)\n",
       "- [model_ctor/args.yaml](../templates/model_ctor/args.yaml)\n",
       "- [projects/tiny.yaml](../templates/projects/tiny.yaml)\n",
       "- [datasets/abstract/pretokenized_dataset.yaml](../templates/datasets/abstract/pretokenized_dataset.yaml)\n",
       "- [datasets/abstract/base_datasets.yaml](../templates/datasets/abstract/base_datasets.yaml)\n",
       "- [datasets/tiny/tiny_stories.yaml](../templates/datasets/tiny/tiny_stories.yaml)\n",
       "- [datasets/tiny/tiny_stories_abridged.yaml](../templates/datasets/tiny/tiny_stories_abridged.yaml)\n",
       "- [models/dynamic_lm.yaml](../templates/models/dynamic_lm.yaml)\n",
       "- [models/causal_transformer.yaml](../templates/models/causal_transformer.yaml)\n",
       "- [models/gpt2.yaml](../templates/models/gpt2.yaml)\n",
       "- [models/llama.yaml](../templates/models/llama.yaml)\n",
       "- [models/abstract/causal_lm_from_config.yaml](../templates/models/abstract/causal_lm_from_config.yaml)\n",
       "- [models/abstract/base_language_model.yaml](../templates/models/abstract/base_language_model.yaml)\n",
       "- [models/abstract/custom_causal_lm.yaml](../templates/models/abstract/custom_causal_lm.yaml)\n",
       "- [models/abstract/causal_lm_from_pretrained.yaml](../templates/models/abstract/causal_lm_from_pretrained.yaml)\n",
       "- [models/abstract/load_model.yaml](../templates/models/abstract/load_model.yaml)\n",
       "- [models/tiny/tiny_causal.yaml](../templates/models/tiny/tiny_causal.yaml)\n",
       "- [models/tiny/tiny_gpt2.yaml](../templates/models/tiny/tiny_gpt2.yaml)\n",
       "- [models/tiny/tiny_llama.yaml](../templates/models/tiny/tiny_llama.yaml)\n",
       "- [models/tiny/tiny_d128_l2.yaml](../templates/models/tiny/tiny_d128_l2.yaml)\n",
       "- [prompts/tiny_stories.yaml](../templates/prompts/tiny_stories.yaml)\n",
       "- [callbacks/base_callbacks.yaml](../templates/callbacks/base_callbacks.yaml)\n",
       "- [callbacks/loggers.yaml](../templates/callbacks/loggers.yaml)\n",
       "- [types/meta_template.yaml](../templates/types/meta_template.yaml)\n",
       "- [types/type.yaml](../templates/types/type.yaml)\n",
       "- [types/tokenizer/tokenizer.yaml](../templates/types/tokenizer/tokenizer.yaml)\n",
       "- [types/tokenizer/bpe/bpe.yaml](../templates/types/tokenizer/bpe/bpe.yaml)\n",
       "- [types/model/model_type.yaml](../templates/types/model/model_type.yaml)\n",
       "- [types/training_script/training_script.yaml](../templates/types/training_script/training_script.yaml)\n",
       "- [types/training_script/causal_lm/causal_lm.yaml](../templates/types/training_script/causal_lm/causal_lm.yaml)\n",
       "- [paths/example_paths.yaml](../templates/paths/example_paths.yaml)\n",
       "- [tokenizers/tiny_2k.yaml](../templates/tokenizers/tiny_2k.yaml)\n",
       "- [tokenizers/tiny_8k.yaml](../templates/tokenizers/tiny_8k.yaml)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Included Templates\n",
       "- [experiments/control.yaml](../examples/trainers/dynamic_models/templates/experiments/control.yaml)\n",
       "    - [project.yaml](../examples/trainers/dynamic_models/templates/project.yaml)\n",
       "        - [projects/tiny.yaml](../templates/projects/tiny.yaml)\n",
       "            - [types/training_script/causal_lm/causal_lm.yaml](../templates/types/training_script/causal_lm/causal_lm.yaml)\n",
       "                - [types/training_script/training_script.yaml](../templates/types/training_script/training_script.yaml)\n",
       "                    - [types/type.yaml](../templates/types/type.yaml)\n",
       "                        - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "                    - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "                - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "                - [models/abstract/load_model.yaml](../templates/models/abstract/load_model.yaml)\n",
       "                    - [models/abstract/causal_lm_from_pretrained.yaml](../templates/models/abstract/causal_lm_from_pretrained.yaml)\n",
       "                        - [models/abstract/base_language_model.yaml](../templates/models/abstract/base_language_model.yaml)\n",
       "                            - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "                - [callbacks/loggers.yaml](../templates/callbacks/loggers.yaml)\n",
       "                    - [callbacks/base_callbacks.yaml](../templates/callbacks/base_callbacks.yaml)\n",
       "                        - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "                - [trainers/trainer.yaml](../templates/trainers/trainer.yaml)\n",
       "                    - [trainers/base_trainer.yaml](../templates/trainers/base_trainer.yaml)\n",
       "                        - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "            - [paths/example_paths.yaml](../templates/paths/example_paths.yaml)\n",
       "            - [prompts/tiny_stories.yaml](../templates/prompts/tiny_stories.yaml)\n",
       "            - [datasets/tiny/tiny_stories_abridged.yaml](../templates/datasets/tiny/tiny_stories_abridged.yaml)\n",
       "                - [datasets/tiny/tiny_stories.yaml](../templates/datasets/tiny/tiny_stories.yaml)\n",
       "                    - [datasets/abstract/base_datasets.yaml](../templates/datasets/abstract/base_datasets.yaml)\n",
       "                        - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "            - [tiny.trainer_config](../templates/projects/tiny.yaml)\n",
       "            - [tiny.model_config](../templates/projects/tiny.yaml)\n",
       "                - [models/tiny/tiny_causal.yaml](../templates/models/tiny/tiny_causal.yaml)\n",
       "                    - [models/dynamic_lm.yaml](../templates/models/dynamic_lm.yaml)\n",
       "                        - [models/abstract/custom_causal_lm.yaml](../templates/models/abstract/custom_causal_lm.yaml)\n",
       "                            - [models/abstract/base_language_model.yaml](../templates/models/abstract/base_language_model.yaml)\n",
       "                                - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "                        - [tokenizers/tiny_8k.yaml](../templates/tokenizers/tiny_8k.yaml)\n",
       "                    - [tokenizers/tiny_2k.yaml](../templates/tokenizers/tiny_2k.yaml)\n",
       "            - [tiny.callbacks](../templates/projects/tiny.yaml)\n",
       "                - [callbacks/loggers.yaml](../templates/callbacks/loggers.yaml)\n",
       "                    - [callbacks/base_callbacks.yaml](../templates/callbacks/base_callbacks.yaml)\n",
       "                        - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "        - [project.trainer_config](../examples/trainers/dynamic_models/templates/project.yaml)\n",
       "            - [tiny.trainer_config](../templates/projects/tiny.yaml)\n",
       "        - [project.model_config](../examples/trainers/dynamic_models/templates/project.yaml)\n",
       "            - [models/tiny/tiny_causal.yaml](../templates/models/tiny/tiny_causal.yaml)\n",
       "                - [models/dynamic_lm.yaml](../templates/models/dynamic_lm.yaml)\n",
       "                    - [models/abstract/custom_causal_lm.yaml](../templates/models/abstract/custom_causal_lm.yaml)\n",
       "                        - [models/abstract/base_language_model.yaml](../templates/models/abstract/base_language_model.yaml)\n",
       "                            - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "                    - [tokenizers/tiny_8k.yaml](../templates/tokenizers/tiny_8k.yaml)\n",
       "                - [tokenizers/tiny_2k.yaml](../templates/tokenizers/tiny_2k.yaml)\n",
       "    - [experiment.model_config](../examples/trainers/dynamic_models/templates/experiments/control.yaml)\n",
       "        - [project.model_config](../examples/trainers/dynamic_models/templates/project.yaml)\n",
       "            - [models/tiny/tiny_causal.yaml](../templates/models/tiny/tiny_causal.yaml)\n",
       "                - [models/dynamic_lm.yaml](../templates/models/dynamic_lm.yaml)\n",
       "                    - [models/abstract/custom_causal_lm.yaml](../templates/models/abstract/custom_causal_lm.yaml)\n",
       "                        - [models/abstract/base_language_model.yaml](../templates/models/abstract/base_language_model.yaml)\n",
       "                            - [inc/formatting.jinja](../templates/inc/formatting.jinja)\n",
       "                    - [tokenizers/tiny_8k.yaml](../templates/tokenizers/tiny_8k.yaml)\n",
       "                - [tokenizers/tiny_2k.yaml](../templates/tokenizers/tiny_2k.yaml)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Sub-Modules\n",
       "- [/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py](../model_src/dynamic_causal_lm.py) : DynamicCasualLM\n",
       "    - [/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py](../model_src/dynamic_causal_lm.py) : dynamic_causal_lm\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/causal_loss.py](../model_src/bits/causal_loss.py) : dynamic_causal_lm.causal_loss\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/feedforward_layer.py](../model_src/bits/feedforward_layer.py) : dynamic_causal_lm.feedforward_layer\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/causal_multihead_attn.py](../model_src/bits/causal_multihead_attn.py) : dynamic_causal_lm.causal_multihead_attn\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/init_weights.py](../model_src/bits/init_weights.py) : dynamic_causal_lm.init_weights\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/causal_lm.py](../model_src/bits/causal_lm.py) : dynamic_causal_lm.causal_lm\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/causal_layer_stack.py](../model_src/bits/causal_layer_stack.py) : dynamic_causal_lm.causal_layer_stack\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/input_encoder.py](../model_src/bits/input_encoder.py) : dynamic_causal_lm.input_encoder\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/post_ln_layer.py](../model_src/bits/post_ln_layer.py) : dynamic_causal_lm.post_ln_layer\n",
       "        - [/home/dinalt/ai_assets/forgather/model_src/bits/sinusoidal_pe.py](../model_src/bits/sinusoidal_pe.py) : dynamic_causal_lm.sinusoidal_pe\n",
       "        - [/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/model_factory.py](../examples/trainers/dynamic_models/output_models/tiny_causal/model_factory.py) : dynamic_causal_lm.model_factory\n",
       "- [/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py](../model_src/dynamic_causal_lm.py) : DynamicCausalLMConfig\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Preprocessed Configuration\n",
       "```yaml\n",
       "#---------------------------------------\n",
       "#                 Control                \n",
       "#---------------------------------------\n",
       "# 2024-08-05T23:39:31\n",
       "# Description: Tiny Causal; the baseline control\n",
       "# Project Dir: /home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models\n",
       "# Current Working Dir: \"/home/dinalt/ai_assets/forgather/notebooks\"\n",
       "# Forgather Config Dir: \"/home/dinalt/.config/forgather\"\n",
       "# Model: tiny_causal\n",
       "# Hostname: hal9000\n",
       "# Versions:\n",
       "#     python: 3.10.13\n",
       "#     torch: 2.3.1\n",
       "#     transformers: 4.41.2\n",
       "#     accelerate: 0.31.0\n",
       "\n",
       "############# Config Vars ##############\n",
       "\n",
       "# ns.models_dir: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models\"\n",
       "# ns.tokenizers_dir: \"/home/dinalt/ai_assets/forgather/tokenizers\"\n",
       "# ns.datasets_dir: \"/home/dinalt/ai_assets/forgather/datasets\"\n",
       "# ns.model_src_dir: \"/home/dinalt/ai_assets/forgather/model_src\"\n",
       "# ns.output_dir: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal\"\n",
       "# ns.logging_dir: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-31\"\n",
       "# ns.create_new_model: True\n",
       "# ns.save_model: False\n",
       "# ns.train: True\n",
       "# ns.eval: False\n",
       "# ns.trust_remote_code: True\n",
       "\n",
       "####### Distributed Environment ########\n",
       "\n",
       ".define: &distributed_env !singleton:aiws.distributed:DistributedEnvironment@distributed_env\n",
       "\n",
       "############# Dependencies #############\n",
       "\n",
       "# The model will be given the following prompts for text-gen at regular intervals.\n",
       ".define: &testprompts !list:@testprompts\n",
       "    # Test prompts from \"https://arxiv.org/abs/2305.07759\"\n",
       "    - \"Alice was so tired when she got back home so she went\"\n",
       "    - \"Jack and Lily liked to watch the moon at night. They noticed that the moon changed its shape every night. Sometimes the moon was big and round, and sometimes it was\"\n",
       "    - \"Jack and Lily saw a rainbow after a rainy day.They were amazed by the colors. Jack said, \\\"Look, Lily. A rainbow has\"\n",
       "    - \"Jack wanted to read a book, so he went to\"\n",
       "    - \"\\\"Can cows fly?\\\" Alice asked her mother.\"\n",
       "    - \"\\\"What do birds like to eat?\\\" Tom asked his mother.\"\n",
       "    - \"\\\"What language do they speak in France?\\\" Tom asked his mother.\"\n",
       "    - \"If I throw a ball up in the air, eventually it will\"\n",
       "    - \"It was winter and cold outside so his mother told him, \\\"You should\"\n",
       "    - \"Lily likes cats and dogs. She asked her mom for a dog and her mom said no, so instead she asked\"\n",
       "    - \"Jack told Mary, \\\"If you give me your banana, I'll give you my apple.\\\" Mary gave Jack her Banana, so\"\n",
       "    - \"On weekends Jack went to visit his grandmother whereas on weekdays he would go to school. Last weekend, when Jack was on his way to\"\n",
       "    - \"Lily and Ben were having an argument. Ben said that cake is much better than ice cream and Lily said that\"\n",
       "    - \"Lily and Ben are having an argument. They are trying to decide between the park and the swimming pool. Ben says, \\\"I want to go to the park\\\". Lily says\"\n",
       "    - \"Jack's mother was not home, and his father was at home. When Jack came home, he said hello to\"\n",
       "    - \"Lily doesn't like swimming. When her father wants to take her to the swimming pool, she says\"\n",
       "    - \"Both Ben and Lily wanted cake. Father said that there was only one piece of cake left. They\"\n",
       "    - \"Ben went to visit Lily in her house, but she was not at home. Ben knocked on the door,\"\n",
       "\n",
       "# Conservative text-generation parameters.\n",
       ".define: &generation_config !dict:@generation_config\n",
       "    identity: generation_config\n",
       "    do_sample: True\n",
       "    top_k: 20\n",
       "    top_p: 0.9\n",
       "    temperature: 0.7\n",
       "    repitition_penalty: 1.15\n",
       "\n",
       "################ Model #################\n",
       "\n",
       "# https://huggingface.co/docs/transformers/en/model_doc/auto\n",
       ".define: &model_constructor_args {}\n",
       "\n",
       "# Name: Tiny Causal\n",
       "# Description: A scaled-down version of the base Causal Transformer\n",
       "# model_def.cls = \"DynamicCasualLM\"\n",
       "# model_def.cfg_cls = \"DynamicCausalLMConfig\"\n",
       "# model_def.config_path = \"/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py\"\n",
       "# model_def.model_path = \"/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py\"\n",
       "\n",
       "# **Tokenizer**\n",
       "\n",
       "# Load custom tokenizer from sub-project definition\n",
       ".define: &tokenizer !singleton:aiws.construct:load_from_config@tokenizer\n",
       "    project_dir: \"/home/dinalt/ai_assets/forgather/examples/tokenizers/tiny_stories_bpe\"\n",
       "    config_template: \"2k.yaml\"\n",
       "\n",
       "# **Model Config**\n",
       "\n",
       "# Add 'bits' to model's module.\n",
       ".define: &model_submodule_searchpath\n",
       "    - \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal\"\n",
       "    - \"/home/dinalt/ai_assets/forgather/model_src/bits\"\n",
       ".define: &loss_fn_factory !factory:.causal_loss:CausalLoss@loss_fn_factory []\n",
       "\n",
       ".define: &layer_norm_factory !factory:torch.nn:LayerNorm@layer_norm_factory\n",
       "    normalized_shape: !var \"hidden_size\"\n",
       "\n",
       ".define: &feedforward_factory !factory:.feedforward_layer:FeedforwardLayer@feedforward_factory\n",
       "    d_model: !var \"hidden_size\"\n",
       "    d_feedforward: !var \"dim_feedforward\"\n",
       "    dropout: !var \"activation_dropout\"\n",
       "\n",
       ".define: &attention_factory !factory:.causal_multihead_attn:CausalMultiheadAttn@attention_factory\n",
       "    d_model: !var \"hidden_size\"\n",
       "    num_heads: !var \"num_attention_heads\"\n",
       "    dropout: !var \"attention_dropout\"\n",
       "\n",
       ".define: &layer_factory !lambda:.post_ln_layer:PostLNLayer@layer_factory\n",
       "    feedforward: *feedforward_factory\n",
       "    attention: *attention_factory\n",
       "    norm1: *layer_norm_factory\n",
       "    norm2: *layer_norm_factory\n",
       "    dropout: !var \"layer_dropout\"\n",
       "    residual_dropout: !var \"residual_dropout\"\n",
       "\n",
       ".define: &layer_stack_factory !factory:.causal_layer_stack:CausalLayerStack@layer_stack_factory\n",
       "    layer_factory: *layer_factory\n",
       "    num_hidden_layers: !var \"num_hidden_layers\"\n",
       "\n",
       ".define: &output_decoder_factory !factory:torch.nn:Linear@output_decoder_factory\n",
       "    - !var \"hidden_size\"\n",
       "    - !var \"vocab_size\"\n",
       "\n",
       ".define: &positional_encoder_factory !factory:.sinusoidal_pe:SinusoidalPE@positional_encoder_factory\n",
       "    d_model: !var \"hidden_size\"\n",
       "    max_sequence_length: !var \"max_sequence_length\"\n",
       "\n",
       ".define: &input_encoder_factory !factory:.input_encoder:InputEncoder@input_encoder_factory\n",
       "    d_model: !var \"hidden_size\"\n",
       "    vocab_size: !var \"vocab_size\"\n",
       "    dropout: !var \"embedding_dropout\"\n",
       "    positional_encoder: *positional_encoder_factory\n",
       "\n",
       ".define: &init_weights_factory !factory:.init_weights:InitWeights@init_weights_factory\n",
       "    std: !var \"initializer_range\"\n",
       "\n",
       ".define: &model_factory !singleton:.causal_lm:CasualLM@model_factory\n",
       "    loss_fn: *loss_fn_factory\n",
       "    input_encoder: *input_encoder_factory\n",
       "    output_decoder: *output_decoder_factory\n",
       "    layer_stack: *layer_stack_factory\n",
       "    init_weights: *init_weights_factory\n",
       "\n",
       ".define: &model_code_writer !singleton:aiws.construct:write_file@model_code_writer\n",
       "    data: &model_code_generator !meta:forgather.codegen:generate_code@model_code_generator\n",
       "        obj: *model_factory\n",
       "        factory_name: \"construct_model\"\n",
       "        relaxed_kwargs: True\n",
       "    output_file: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/model_factory.py\"\n",
       "    return_value: \"Model constructor generated by Forgather 1.0\"\n",
       "\n",
       ".define: &model_config !singleton:/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py:DynamicCausalLMConfig@model_config\n",
       "    submodule_searchpath: *model_submodule_searchpath\n",
       "    # Set auto-map for custom model; this ensures that the source code stays with the model.\n",
       "    auto_map:\n",
       "        AutoConfig: \"dynamic_causal_lm.DynamicCausalLMConfig\"\n",
       "        AutoModel: \"dynamic_causal_lm.DynamicCasualLM\"\n",
       "    # Get the vocab-size from the tokenizer definition.\n",
       "    vocab_size: !singleton:len [ *tokenizer ]\n",
       "    pad_token_id: !singleton:getattr [ *tokenizer, 'pad_token_id' ]\n",
       "    bos_token_id: !singleton:getattr [ *tokenizer, 'bos_token_id' ]\n",
       "    eos_token_id: !singleton:getattr [ *tokenizer, 'eos_token_id' ]\n",
       "    code_generator: *model_code_writer\n",
       "    # Convert model definition to a JSON compatible encoding for the configuration to store.\n",
       "    hidden_size: 512\n",
       "    num_attention_heads: 8\n",
       "    num_hidden_layers: 6\n",
       "    max_sequence_length: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - \"model_max_length\"\n",
       "    dim_feedforward: 2048\n",
       "    initializer_range: 0.02\n",
       "    embedding_dropout: 0.10\n",
       "    layer_dropout: 0.10\n",
       "    residual_dropout: 0.0\n",
       "    attention_dropout: 0.0\n",
       "    activation_dropout: 0.0\n",
       "    \n",
       "    # Tiny Causal overrides\n",
       "    hidden_size: 256\n",
       "    dim_feedforward: 1024\n",
       "    num_attention_heads: 2\n",
       "    num_hidden_layers: 4\n",
       "    embedding_dropout: 0.0\n",
       "    layer_dropout: 0.0\n",
       "\n",
       "# **Model Constructor**\n",
       "\n",
       ".define: &pretrained_model !singleton:/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py:DynamicCasualLM@pretrained_model\n",
       "    args:\n",
       "        - *model_config\n",
       "    kwargs:\n",
       "        submodule_searchpath: *model_submodule_searchpath\n",
       "        <<: *model_constructor_args\n",
       "\n",
       ".define: &model !singleton:aiws.construct:dependency_list@model\n",
       "    - *pretrained_model\n",
       "    - !singleton:aiws.construct:copy_package_files\n",
       "        - \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal\"\n",
       "        - *model_config\n",
       "    - !singleton:aiws.construct:copy_package_files\n",
       "        - \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal\"\n",
       "        - *pretrained_model\n",
       "\n",
       "############### Datasets ###############\n",
       "\n",
       "# Name: TinyStories Abridged\n",
       "# Define: Abridged to 10% of original size; Dataset containing synthetically generated (by GPT-3.5 and GPT-4) short stories that only use a small vocabulary.\n",
       "# Source: https://arxiv.org/abs/2305.07759\n",
       "# Train Dataset: \"roneneldan/TinyStories\" : \"train\"\n",
       "# Eval Dataset: \"roneneldan/TinyStories\" : \"validation\"\n",
       "\n",
       "# **Source Datasets**\n",
       "\n",
       ".define: &train_source_dataset !singleton:datasets:load_dataset@train_source_dataset\n",
       "    - \"roneneldan/TinyStories\"\n",
       "\n",
       ".define: &eval_source_dataset !singleton:datasets:load_dataset@eval_source_dataset\n",
       "    - \"roneneldan/TinyStories\"\n",
       "\n",
       "# **Dataset Splits**\n",
       "\n",
       ".define: &train_dataset_split !singleton:operator:getitem\n",
       "    - *train_source_dataset\n",
       "    - \"train\"\n",
       "\n",
       ".define: &eval_dataset_split !singleton:operator:getitem\n",
       "    - *train_source_dataset\n",
       "    - \"validation\"\n",
       "\n",
       "# **Tokenize Args**\n",
       "\n",
       ".define: &tokenize_args\n",
       "    truncation: True\n",
       "\n",
       "# **Tokenized Datasets**\n",
       "\n",
       ".define: &train_dataset !singleton:aiws.datasets:tokenize_dataset@train_dataset\n",
       "    dataset: *train_dataset_split\n",
       "    tokenizer: *tokenizer\n",
       "    select_range: 0.1\n",
       "    desc: \"Tokenizing train\"\n",
       "    fn_kwargs:\n",
       "        <<: *tokenize_args\n",
       "\n",
       ".define: &eval_dataset !singleton:aiws.datasets:tokenize_dataset@eval_dataset\n",
       "    dataset: *eval_dataset_split\n",
       "    tokenizer: *tokenizer\n",
       "    select_range: 500\n",
       "    desc: \"Tokenizing validation split\"\n",
       "    fn_kwargs:\n",
       "        <<: *tokenize_args\n",
       "\n",
       "############ Data Collator #############\n",
       "\n",
       "# Data collator for causal model\n",
       "# Batches are dynamically padded to longest sequence\n",
       "# labels are set to input_ids, with pad tokens set to -100\n",
       "# https://huggingface.co/docs/transformers/en/main_classes/data_collator#transformers.DataCollatorForLanguageModeling\n",
       ".define: &data_collator !singleton:transformers:DataCollatorForLanguageModeling@data_collator\n",
       "    args:\n",
       "        - *tokenizer\n",
       "    kwargs:\n",
       "        mlm: False\n",
       "        return_tensors: pt\n",
       "\n",
       "########## Trainer Callbacks ###########\n",
       "\n",
       "# **Dependencies**\n",
       "\n",
       "# Experiment tracking: Tensorboard SummaryWriter\n",
       ".define: &summary_writer !singleton:torch.utils.tensorboard:SummaryWriter\n",
       "    - \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-31\"\n",
       "\n",
       "# Additional data to record to experiment loggers\n",
       ".define: &experiment_info !dict:@experiment_info\n",
       "    date: \"2024-08-05T23:39:31\"\n",
       "    name: \"Control\"\n",
       "    description: \"Tiny Causal; the baseline control\"\n",
       "    config: !var \"pp_config\"\n",
       "    versions: {'python': '3.10.13', 'torch': '2.3.1', 'transformers': '4.41.2', 'accelerate': '0.31.0'}\n",
       "\n",
       ".define: &text_gen_callback_args\n",
       "    summary_writer: *summary_writer\n",
       "    prompts: *testprompts\n",
       "    generation_config: *generation_config\n",
       "    max_new_tokens: 40\n",
       "    generation_steps: 2000\n",
       "\n",
       "# **Callback List**\n",
       "\n",
       ".define: &trainer_callbacks !list:@trainer_callbacks\n",
       "    # Log all training output to JSON\n",
       "    - !singleton:aiws.json_logger:JsonLogger\n",
       "        <<: *experiment_info\n",
       "    # Log configuration and metrics to Tensorboard file\n",
       "    - !singleton:aiws.tb_logger:TBLogger\n",
       "        args: [ *summary_writer ]\n",
       "        kwargs:\n",
       "            <<: *experiment_info\n",
       "    - !singleton:aiws.textgen_callback:TextgenCallback\n",
       "        <<: *text_gen_callback_args\n",
       "\n",
       "############### Trainer ################\n",
       "\n",
       "# Name: Custom aiws.trainer.Trainer\n",
       "# Description: A lightweight, extensible trainer; does not support multiple GPUs\n",
       "\n",
       "# **Trainer Args**\n",
       "\n",
       ".define: &trainer_args\n",
       "    # Base Trainer Defaults\n",
       "    # https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments\n",
       "    output_dir: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal\"\n",
       "    logging_dir: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-31\"\n",
       "    overwrite_output_dir: True\n",
       "    per_device_train_batch_size: 16\n",
       "    per_device_eval_batch_size: 16\n",
       "    learning_rate: 1.0e-3\n",
       "    num_train_epochs: 1\n",
       "    eval_steps: 100\n",
       "    logging_steps: 500\n",
       "    eval_strategy: \"steps\"\n",
       "    save_strategy: \"no\"\n",
       "    logging_strategy: \"steps\"\n",
       "    lr_scheduler_type: \"constant\"\n",
       "\n",
       "    # Tiny Project Overrides\n",
       "    per_device_train_batch_size: 32\n",
       "    per_device_eval_batch_size: 64\n",
       "    logging_steps: 100\n",
       "    eval_steps: 500\n",
       "    learning_rate: 1.0e-3\n",
       "    num_train_epochs: 1\n",
       "    lr_scheduler_type: \"cosine\"\n",
       "\n",
       "    # max_steps: 500\n",
       "\n",
       "# **Trainer Constructor**\n",
       "\n",
       ".define: &trainer !singleton:aiws.trainer:Trainer@trainer\n",
       "    model: *model\n",
       "    args: !singleton:aiws.trainer_types:TrainingArguments@trainer_args\n",
       "        <<: *trainer_args\n",
       "    data_collator: *data_collator\n",
       "    train_dataset: *train_dataset\n",
       "    eval_dataset: *eval_dataset\n",
       "    tokenizer: *tokenizer\n",
       "    callbacks: *trainer_callbacks\n",
       "\n",
       "#---------------------------------------\n",
       "#          Configuration Output          \n",
       "#---------------------------------------\n",
       "meta: &meta_output !dict:@meta\n",
       "    config_name: \"Control\"\n",
       "    config_description: \"Tiny Causal; the baseline control\"\n",
       "    project_dir: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models\"\n",
       "    models_dir: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models\"\n",
       "    tokenizers_dir: \"/home/dinalt/ai_assets/forgather/tokenizers\"\n",
       "    datasets_dir: \"/home/dinalt/ai_assets/forgather/datasets\"\n",
       "    output_dir: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal\"\n",
       "    model_src_dir: \"/home/dinalt/ai_assets/forgather/model_src\"\n",
       "    logging_dir: \"/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-31\"\n",
       "    create_new_model: \"True\"\n",
       "    save_model: \"False\"\n",
       "    train: \"True\"\n",
       "    eval: \"False\"\n",
       "\n",
       "main: !singleton:aiws.training_script:TrainingScript@training_script\n",
       "    meta: *meta_output\n",
       "    do_save: False\n",
       "    do_train: True\n",
       "    do_eval: False\n",
       "    # Init distributed envrionment before initializing anyting which depends on it.\n",
       "    distributed_env: *distributed_env\n",
       "    trainer: *trainer\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Loaded Configuration to YAML\n",
       "```yaml\n",
       ".define: &meta !singleton:dict@meta\n",
       "    config_name: 'Control'\n",
       "    config_description: 'Tiny Causal; the baseline control'\n",
       "    project_dir: '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models'\n",
       "    models_dir: '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models'\n",
       "    tokenizers_dir: '/home/dinalt/ai_assets/forgather/tokenizers'\n",
       "    datasets_dir: '/home/dinalt/ai_assets/forgather/datasets'\n",
       "    output_dir: '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal'\n",
       "    model_src_dir: '/home/dinalt/ai_assets/forgather/model_src'\n",
       "    logging_dir: '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-30'\n",
       "    create_new_model: 'True'\n",
       "    save_model: 'False'\n",
       "    train: 'True'\n",
       "    eval: 'False'\n",
       "\n",
       ".define: &distributed_env !singleton:aiws.distributed:DistributedEnvironment@distributed_env []\n",
       "\n",
       ".define: &tokenizer !singleton:aiws.construct:load_from_config@tokenizer\n",
       "    project_dir: '/home/dinalt/ai_assets/forgather/examples/tokenizers/tiny_stories_bpe'\n",
       "    config_template: '2k.yaml'\n",
       "\n",
       ".define: &loss_fn_factory !factory:.causal_loss:CausalLoss@loss_fn_factory []\n",
       "\n",
       ".define: &positional_encoder_factory !factory:.sinusoidal_pe:SinusoidalPE@positional_encoder_factory\n",
       "    d_model: !var hidden_size\n",
       "    max_sequence_length: !var max_sequence_length\n",
       "\n",
       ".define: &input_encoder_factory !factory:.input_encoder:InputEncoder@input_encoder_factory\n",
       "    d_model: !var hidden_size\n",
       "    vocab_size: !var vocab_size\n",
       "    dropout: !var embedding_dropout\n",
       "    positional_encoder: *positional_encoder_factory\n",
       "\n",
       ".define: &output_decoder_factory !factory:torch.nn:Linear@output_decoder_factory\n",
       "    - !var hidden_size\n",
       "    - !var vocab_size\n",
       "\n",
       ".define: &feedforward_factory !factory:.feedforward_layer:FeedforwardLayer@feedforward_factory\n",
       "    d_model: !var hidden_size\n",
       "    d_feedforward: !var dim_feedforward\n",
       "    dropout: !var activation_dropout\n",
       "\n",
       ".define: &attention_factory !factory:.causal_multihead_attn:CausalMultiheadAttn@attention_factory\n",
       "    d_model: !var hidden_size\n",
       "    num_heads: !var num_attention_heads\n",
       "    dropout: !var attention_dropout\n",
       "\n",
       ".define: &layer_norm_factory !factory:torch.nn:LayerNorm@layer_norm_factory\n",
       "    normalized_shape: !var hidden_size\n",
       "\n",
       ".define: &layer_factory !lambda:.post_ln_layer:PostLNLayer@layer_factory\n",
       "    feedforward: *feedforward_factory\n",
       "    attention: *attention_factory\n",
       "    norm1: *layer_norm_factory\n",
       "    norm2: *layer_norm_factory\n",
       "    dropout: !var layer_dropout\n",
       "    residual_dropout: !var residual_dropout\n",
       "\n",
       ".define: &layer_stack_factory !factory:.causal_layer_stack:CausalLayerStack@layer_stack_factory\n",
       "    layer_factory: *layer_factory\n",
       "    num_hidden_layers: !var num_hidden_layers\n",
       "\n",
       ".define: &init_weights_factory !factory:.init_weights:InitWeights@init_weights_factory\n",
       "    std: !var initializer_range\n",
       "\n",
       ".define: &model_factory !singleton:.causal_lm:CasualLM@model_factory\n",
       "    loss_fn: *loss_fn_factory\n",
       "    input_encoder: *input_encoder_factory\n",
       "    output_decoder: *output_decoder_factory\n",
       "    layer_stack: *layer_stack_factory\n",
       "    init_weights: *init_weights_factory\n",
       "\n",
       ".define: &model_code_generator !meta:forgather.codegen:generate_code@model_code_generator\n",
       "    obj: *model_factory\n",
       "    factory_name: 'construct_model'\n",
       "    relaxed_kwargs: True\n",
       "\n",
       ".define: &model_code_writer !singleton:aiws.construct:write_file@model_code_writer\n",
       "    data: *model_code_generator\n",
       "    output_file: '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/model_factory.py'\n",
       "    return_value: 'Model constructor generated by Forgather 1.0'\n",
       "\n",
       ".define: &model_config !singleton:/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py:DynamicCausalLMConfig@model_config\n",
       "    auto_map: \n",
       "        AutoConfig: 'dynamic_causal_lm.DynamicCausalLMConfig'\n",
       "        AutoModel: 'dynamic_causal_lm.DynamicCasualLM'\n",
       "    vocab_size: !singleton:len\n",
       "        - *tokenizer\n",
       "    pad_token_id: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - 'pad_token_id'\n",
       "    bos_token_id: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - 'bos_token_id'\n",
       "    eos_token_id: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - 'eos_token_id'\n",
       "    code_generator: *model_code_writer\n",
       "    hidden_size: 256\n",
       "    num_attention_heads: 2\n",
       "    num_hidden_layers: 4\n",
       "    max_sequence_length: !singleton:getattr\n",
       "        - *tokenizer\n",
       "        - 'model_max_length'\n",
       "    dim_feedforward: 1024\n",
       "    initializer_range: 0.02\n",
       "    embedding_dropout: 0.0\n",
       "    layer_dropout: 0.0\n",
       "    residual_dropout: 0.0\n",
       "    attention_dropout: 0.0\n",
       "    activation_dropout: 0.0\n",
       "\n",
       ".define: &pretrained_model !singleton:/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py:DynamicCasualLM@pretrained_model\n",
       "    - *model_config\n",
       "\n",
       ".define: &model !singleton:aiws.construct:dependency_list@model\n",
       "    - *pretrained_model\n",
       "    - !singleton:aiws.construct:copy_package_files\n",
       "        - '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal'\n",
       "        - *model_config\n",
       "    - !singleton:aiws.construct:copy_package_files\n",
       "        - '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal'\n",
       "        - *pretrained_model\n",
       "\n",
       ".define: &trainer_args !singleton:aiws.trainer_types:TrainingArguments@trainer_args\n",
       "    output_dir: '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal'\n",
       "    logging_dir: '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-30'\n",
       "    overwrite_output_dir: True\n",
       "    per_device_train_batch_size: 32\n",
       "    per_device_eval_batch_size: 64\n",
       "    learning_rate: 0.001\n",
       "    num_train_epochs: 1\n",
       "    eval_steps: 500\n",
       "    logging_steps: 100\n",
       "    eval_strategy: 'steps'\n",
       "    save_strategy: 'no'\n",
       "    logging_strategy: 'steps'\n",
       "    lr_scheduler_type: 'cosine'\n",
       "\n",
       ".define: &data_collator !singleton:transformers:DataCollatorForLanguageModeling@data_collator\n",
       "    args:\n",
       "        - *tokenizer\n",
       "    kwargs:\n",
       "        mlm: False\n",
       "        return_tensors: 'pt'\n",
       "\n",
       ".define: &train_source_dataset !singleton:datasets:load_dataset@train_source_dataset\n",
       "    - 'roneneldan/TinyStories'\n",
       "\n",
       ".define: &train_dataset !singleton:aiws.datasets:tokenize_dataset@train_dataset\n",
       "    dataset: !singleton:operator:getitem\n",
       "        - *train_source_dataset\n",
       "        - 'train'\n",
       "    tokenizer: *tokenizer\n",
       "    select_range: 0.1\n",
       "    desc: 'Tokenizing train'\n",
       "    fn_kwargs: \n",
       "        truncation: True\n",
       "\n",
       ".define: &eval_dataset !singleton:aiws.datasets:tokenize_dataset@eval_dataset\n",
       "    dataset: !singleton:operator:getitem\n",
       "        - *train_source_dataset\n",
       "        - 'validation'\n",
       "    tokenizer: *tokenizer\n",
       "    select_range: 500\n",
       "    desc: 'Tokenizing validation split'\n",
       "    fn_kwargs: \n",
       "        truncation: True\n",
       "\n",
       ".define: &testprompts !singleton:list@testprompts\n",
       "    - \n",
       "        - 'Alice was so tired when she got back home so she went'\n",
       "        - 'Jack and Lily liked to watch the moon at night. They noticed that the moon changed its shape every night. Sometimes the moon was big and round, and sometimes it was'\n",
       "        - 'Jack and Lily saw a rainbow after a rainy day.They were amazed by the colors. Jack said, \"Look, Lily. A rainbow has'\n",
       "        - 'Jack wanted to read a book, so he went to'\n",
       "        - '\"Can cows fly?\" Alice asked her mother.'\n",
       "        - '\"What do birds like to eat?\" Tom asked his mother.'\n",
       "        - '\"What language do they speak in France?\" Tom asked his mother.'\n",
       "        - 'If I throw a ball up in the air, eventually it will'\n",
       "        - 'It was winter and cold outside so his mother told him, \"You should'\n",
       "        - 'Lily likes cats and dogs. She asked her mom for a dog and her mom said no, so instead she asked'\n",
       "        - 'Jack told Mary, \"If you give me your banana, I\\'ll give you my apple.\" Mary gave Jack her Banana, so'\n",
       "        - 'On weekends Jack went to visit his grandmother whereas on weekdays he would go to school. Last weekend, when Jack was on his way to'\n",
       "        - 'Lily and Ben were having an argument. Ben said that cake is much better than ice cream and Lily said that'\n",
       "        - 'Lily and Ben are having an argument. They are trying to decide between the park and the swimming pool. Ben says, \"I want to go to the park\". Lily says'\n",
       "        - \"Jack's mother was not home, and his father was at home. When Jack came home, he said hello to\"\n",
       "        - \"Lily doesn't like swimming. When her father wants to take her to the swimming pool, she says\"\n",
       "        - 'Both Ben and Lily wanted cake. Father said that there was only one piece of cake left. They'\n",
       "        - 'Ben went to visit Lily in her house, but she was not at home. Ben knocked on the door,'\n",
       "\n",
       ".define: &generation_config !singleton:dict@generation_config\n",
       "    identity: 'generation_config'\n",
       "    do_sample: True\n",
       "    top_k: 20\n",
       "    top_p: 0.9\n",
       "    temperature: 0.7\n",
       "    repitition_penalty: 1.15\n",
       "\n",
       ".define: &trainer_callbacks !singleton:list@trainer_callbacks\n",
       "    - \n",
       "        - !singleton:aiws.json_logger:JsonLogger\n",
       "            date: '2024-08-05T23:39:30'\n",
       "            name: 'Control'\n",
       "            description: 'Tiny Causal; the baseline control'\n",
       "            config: !var pp_config\n",
       "            versions: \n",
       "                python: '3.10.13'\n",
       "                torch: '2.3.1'\n",
       "                transformers: '4.41.2'\n",
       "                accelerate: '0.31.0'\n",
       "        - !singleton:aiws.tb_logger:TBLogger\n",
       "            args:\n",
       "                - !singleton:torch.utils.tensorboard:SummaryWriter\n",
       "                    - '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-30'\n",
       "            kwargs:\n",
       "                date: '2024-08-05T23:39:30'\n",
       "                name: 'Control'\n",
       "                description: 'Tiny Causal; the baseline control'\n",
       "                config: !var pp_config\n",
       "                versions: \n",
       "                    python: '3.10.13'\n",
       "                    torch: '2.3.1'\n",
       "                    transformers: '4.41.2'\n",
       "                    accelerate: '0.31.0'\n",
       "        - !singleton:aiws.textgen_callback:TextgenCallback\n",
       "            summary_writer: !singleton:torch.utils.tensorboard:SummaryWriter\n",
       "                - '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-30'\n",
       "            prompts: *testprompts\n",
       "            generation_config: *generation_config\n",
       "            max_new_tokens: 40\n",
       "            generation_steps: 2000\n",
       "\n",
       ".define: &trainer !singleton:aiws.trainer:Trainer@trainer\n",
       "    model: *model\n",
       "    args: *trainer_args\n",
       "    data_collator: *data_collator\n",
       "    train_dataset: *train_dataset\n",
       "    eval_dataset: *eval_dataset\n",
       "    tokenizer: *tokenizer\n",
       "    callbacks: *trainer_callbacks\n",
       "\n",
       ".define: &training_script !singleton:aiws.training_script:TrainingScript@training_script\n",
       "    meta: *meta\n",
       "    do_save: False\n",
       "    do_train: True\n",
       "    do_eval: False\n",
       "    distributed_env: *distributed_env\n",
       "    trainer: *trainer\n",
       "\n",
       "\n",
       "meta: *meta\n",
       "main: *training_script\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Generated Source Code\n",
       "```python\n",
       "from aiws.tb_logger import TBLogger\n",
       "from aiws.distributed import DistributedEnvironment\n",
       "from aiws.construct import load_from_config\n",
       "from datasets import load_dataset\n",
       "from aiws.json_logger import JsonLogger\n",
       "from torch.utils.tensorboard import SummaryWriter\n",
       "from aiws.construct import dependency_list\n",
       "from aiws.textgen_callback import TextgenCallback\n",
       "from aiws.datasets import tokenize_dataset\n",
       "from transformers import DataCollatorForLanguageModeling\n",
       "from aiws.training_script import TrainingScript\n",
       "from aiws.construct import copy_package_files\n",
       "from aiws.trainer import Trainer\n",
       "from aiws.trainer_types import TrainingArguments\n",
       "from aiws.construct import write_file\n",
       "from importlib.util import spec_from_file_location, module_from_spec\n",
       "import os\n",
       "import sys\n",
       "\n",
       "# Import a dynamic module.\n",
       "def dynimport(module, name, searchpath):\n",
       "    module_path = module\n",
       "    module_name = os.path.basename(module).split(\".\")[0]\n",
       "    module_spec = spec_from_file_location(\n",
       "        module_name,\n",
       "        module_path,\n",
       "        submodule_search_locations=searchpath,\n",
       "    )\n",
       "    mod = module_from_spec(module_spec)\n",
       "    sys.modules[module_name] = mod\n",
       "    module_spec.loader.exec_module(mod)\n",
       "    for symbol in name.split(\".\"):\n",
       "        mod = getattr(mod, symbol)\n",
       "    return mod\n",
       "\n",
       "DynamicCausalLMConfig = lambda: dynimport(\"/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py\", \"DynamicCausalLMConfig\", ['/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal', '/home/dinalt/ai_assets/forgather/model_src/bits'])\n",
       "DynamicCasualLM = lambda: dynimport(\"/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py\", \"DynamicCasualLM\", ['/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal', '/home/dinalt/ai_assets/forgather/model_src/bits'])\n",
       "\n",
       "def construct(\n",
       "    pp_config,\n",
       "):\n",
       "    meta = {\n",
       "        'config_name': 'Control',\n",
       "        'config_description': 'Tiny Causal; the baseline control',\n",
       "        'project_dir': '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models',\n",
       "        'models_dir': '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models',\n",
       "        'tokenizers_dir': '/home/dinalt/ai_assets/forgather/tokenizers',\n",
       "        'datasets_dir': '/home/dinalt/ai_assets/forgather/datasets',\n",
       "        'output_dir': '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal',\n",
       "        'model_src_dir': '/home/dinalt/ai_assets/forgather/model_src',\n",
       "        'logging_dir': '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-30',\n",
       "        'create_new_model': 'True',\n",
       "        'save_model': 'False',\n",
       "        'train': 'True',\n",
       "        'eval': 'False',\n",
       "    }\n",
       "\n",
       "    distributed_env = DistributedEnvironment()\n",
       "\n",
       "    tokenizer = load_from_config(\n",
       "        project_dir='/home/dinalt/ai_assets/forgather/examples/tokenizers/tiny_stories_bpe',\n",
       "        config_template='2k.yaml',\n",
       "    )\n",
       "\n",
       "    model_code_writer = write_file(\n",
       "        data=(\n",
       "            'from .causal_loss import CausalLoss\\n'\n",
       "            'from .feedforward_layer import FeedforwardLayer\\n'\n",
       "            'from .causal_multihead_attn import CausalMultiheadAttn\\n'\n",
       "            'from .init_weights import InitWeights\\n'\n",
       "            'from .causal_lm import CasualLM\\n'\n",
       "            'from .causal_layer_stack import CausalLayerStack\\n'\n",
       "            'from torch.nn import Linear\\n'\n",
       "            'from .input_encoder import InputEncoder\\n'\n",
       "            'from .post_ln_layer import PostLNLayer\\n'\n",
       "            'from torch.nn import LayerNorm\\n'\n",
       "            'from .sinusoidal_pe import SinusoidalPE\\n'\n",
       "            '\\n'\n",
       "            'def construct_model(\\n'\n",
       "            '    activation_dropout,\\n'\n",
       "            '    embedding_dropout,\\n'\n",
       "            '    max_sequence_length,\\n'\n",
       "            '    num_attention_heads,\\n'\n",
       "            '    layer_dropout,\\n'\n",
       "            '    vocab_size,\\n'\n",
       "            '    initializer_range,\\n'\n",
       "            '    num_hidden_layers,\\n'\n",
       "            '    dim_feedforward,\\n'\n",
       "            '    attention_dropout,\\n'\n",
       "            '    residual_dropout,\\n'\n",
       "            '    hidden_size,\\n'\n",
       "            '    **kwargs\\n'\n",
       "            '):\\n'\n",
       "            '    loss_fn_factory = lambda: CausalLoss()\\n'\n",
       "            '\\n'\n",
       "            '    positional_encoder_factory = lambda: SinusoidalPE(\\n'\n",
       "            '        d_model=hidden_size,\\n'\n",
       "            '        max_sequence_length=max_sequence_length,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    input_encoder_factory = lambda: InputEncoder(\\n'\n",
       "            '        d_model=hidden_size,\\n'\n",
       "            '        vocab_size=vocab_size,\\n'\n",
       "            '        dropout=embedding_dropout,\\n'\n",
       "            '        positional_encoder=positional_encoder_factory(),\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    output_decoder_factory = lambda: Linear(\\n'\n",
       "            '        hidden_size,\\n'\n",
       "            '        vocab_size,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    feedforward_factory = lambda: FeedforwardLayer(\\n'\n",
       "            '        d_model=hidden_size,\\n'\n",
       "            '        d_feedforward=dim_feedforward,\\n'\n",
       "            '        dropout=activation_dropout,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    attention_factory = lambda: CausalMultiheadAttn(\\n'\n",
       "            '        d_model=hidden_size,\\n'\n",
       "            '        num_heads=num_attention_heads,\\n'\n",
       "            '        dropout=attention_dropout,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    layer_norm_factory = lambda: LayerNorm(\\n'\n",
       "            '        normalized_shape=hidden_size,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    layer_factory = lambda: PostLNLayer(\\n'\n",
       "            '        feedforward=feedforward_factory(),\\n'\n",
       "            '        attention=attention_factory(),\\n'\n",
       "            '        norm1=layer_norm_factory(),\\n'\n",
       "            '        norm2=layer_norm_factory(),\\n'\n",
       "            '        dropout=layer_dropout,\\n'\n",
       "            '        residual_dropout=residual_dropout,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    layer_stack_factory = lambda: CausalLayerStack(\\n'\n",
       "            '        layer_factory=layer_factory,\\n'\n",
       "            '        num_hidden_layers=num_hidden_layers,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    init_weights_factory = lambda: InitWeights(\\n'\n",
       "            '        std=initializer_range,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    model_factory = CasualLM(\\n'\n",
       "            '        loss_fn=loss_fn_factory(),\\n'\n",
       "            '        input_encoder=input_encoder_factory(),\\n'\n",
       "            '        output_decoder=output_decoder_factory(),\\n'\n",
       "            '        layer_stack=layer_stack_factory(),\\n'\n",
       "            '        init_weights=init_weights_factory(),\\n'\n",
       "            '    )\\n'\n",
       "            '    \\n'\n",
       "            '    return model_factory'\n",
       "        ),\n",
       "        output_file='/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/model_factory.py',\n",
       "        return_value='Model constructor generated by Forgather 1.0',\n",
       "    )\n",
       "\n",
       "    model_config = DynamicCausalLMConfig(\n",
       "        auto_map={\n",
       "            'AutoConfig': 'dynamic_causal_lm.DynamicCausalLMConfig',\n",
       "            'AutoModel': 'dynamic_causal_lm.DynamicCasualLM',\n",
       "        },\n",
       "        vocab_size=len(\n",
       "            tokenizer,\n",
       "        ),\n",
       "        pad_token_id=tokenizer.pad_token_id,\n",
       "        bos_token_id=tokenizer.bos_token_id,\n",
       "        eos_token_id=tokenizer.eos_token_id,\n",
       "        code_generator=model_code_writer,\n",
       "        hidden_size=256,\n",
       "        num_attention_heads=2,\n",
       "        num_hidden_layers=4,\n",
       "        max_sequence_length=tokenizer.model_max_length,\n",
       "        dim_feedforward=1024,\n",
       "        initializer_range=0.02,\n",
       "        embedding_dropout=0.0,\n",
       "        layer_dropout=0.0,\n",
       "        residual_dropout=0.0,\n",
       "        attention_dropout=0.0,\n",
       "        activation_dropout=0.0,\n",
       "    )\n",
       "\n",
       "    pretrained_model = DynamicCasualLM(\n",
       "        model_config,\n",
       "    )\n",
       "\n",
       "    model = dependency_list(\n",
       "        pretrained_model,\n",
       "        copy_package_files(\n",
       "            '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal',\n",
       "            model_config,\n",
       "        ),\n",
       "        copy_package_files(\n",
       "            '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal',\n",
       "            pretrained_model,\n",
       "        ),\n",
       "    )\n",
       "\n",
       "    trainer_args = TrainingArguments(\n",
       "        output_dir='/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal',\n",
       "        logging_dir='/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-30',\n",
       "        overwrite_output_dir=True,\n",
       "        per_device_train_batch_size=32,\n",
       "        per_device_eval_batch_size=64,\n",
       "        learning_rate=0.001,\n",
       "        num_train_epochs=1,\n",
       "        eval_steps=500,\n",
       "        logging_steps=100,\n",
       "        eval_strategy='steps',\n",
       "        save_strategy='no',\n",
       "        logging_strategy='steps',\n",
       "        lr_scheduler_type='cosine',\n",
       "    )\n",
       "\n",
       "    data_collator = DataCollatorForLanguageModeling(\n",
       "        tokenizer,\n",
       "        mlm=False,\n",
       "        return_tensors='pt',\n",
       "    )\n",
       "\n",
       "    train_source_dataset = load_dataset(\n",
       "        'roneneldan/TinyStories',\n",
       "    )\n",
       "\n",
       "    train_dataset = tokenize_dataset(\n",
       "        dataset=train_source_dataset['train'],\n",
       "        tokenizer=tokenizer,\n",
       "        select_range=0.1,\n",
       "        desc='Tokenizing train',\n",
       "        fn_kwargs={\n",
       "            'truncation': True,\n",
       "        },\n",
       "    )\n",
       "\n",
       "    eval_dataset = tokenize_dataset(\n",
       "        dataset=train_source_dataset['validation'],\n",
       "        tokenizer=tokenizer,\n",
       "        select_range=500,\n",
       "        desc='Tokenizing validation split',\n",
       "        fn_kwargs={\n",
       "            'truncation': True,\n",
       "        },\n",
       "    )\n",
       "\n",
       "    testprompts = [\n",
       "        [\n",
       "            'Alice was so tired when she got back home so she went',\n",
       "            'Jack and Lily liked to watch the moon at night. They noticed that the moon changed its shape every night. Sometimes the moon was big and round, and sometimes it was',\n",
       "            'Jack and Lily saw a rainbow after a rainy day.They were amazed by the colors. Jack said, \"Look, Lily. A rainbow has',\n",
       "            'Jack wanted to read a book, so he went to',\n",
       "            '\"Can cows fly?\" Alice asked her mother.',\n",
       "            '\"What do birds like to eat?\" Tom asked his mother.',\n",
       "            '\"What language do they speak in France?\" Tom asked his mother.',\n",
       "            'If I throw a ball up in the air, eventually it will',\n",
       "            'It was winter and cold outside so his mother told him, \"You should',\n",
       "            'Lily likes cats and dogs. She asked her mom for a dog and her mom said no, so instead she asked',\n",
       "            'Jack told Mary, \"If you give me your banana, I\\'ll give you my apple.\" Mary gave Jack her Banana, so',\n",
       "            'On weekends Jack went to visit his grandmother whereas on weekdays he would go to school. Last weekend, when Jack was on his way to',\n",
       "            'Lily and Ben were having an argument. Ben said that cake is much better than ice cream and Lily said that',\n",
       "            'Lily and Ben are having an argument. They are trying to decide between the park and the swimming pool. Ben says, \"I want to go to the park\". Lily says',\n",
       "            \"Jack's mother was not home, and his father was at home. When Jack came home, he said hello to\",\n",
       "            \"Lily doesn't like swimming. When her father wants to take her to the swimming pool, she says\",\n",
       "            'Both Ben and Lily wanted cake. Father said that there was only one piece of cake left. They',\n",
       "            'Ben went to visit Lily in her house, but she was not at home. Ben knocked on the door,',\n",
       "        ],\n",
       "    ]\n",
       "\n",
       "    generation_config = {\n",
       "        'identity': 'generation_config',\n",
       "        'do_sample': True,\n",
       "        'top_k': 20,\n",
       "        'top_p': 0.9,\n",
       "        'temperature': 0.7,\n",
       "        'repitition_penalty': 1.15,\n",
       "    }\n",
       "\n",
       "    trainer_callbacks = [\n",
       "        [\n",
       "            JsonLogger(\n",
       "                date='2024-08-05T23:39:30',\n",
       "                name='Control',\n",
       "                description='Tiny Causal; the baseline control',\n",
       "                config=pp_config,\n",
       "                versions={\n",
       "                    'python': '3.10.13',\n",
       "                    'torch': '2.3.1',\n",
       "                    'transformers': '4.41.2',\n",
       "                    'accelerate': '0.31.0',\n",
       "                },\n",
       "            ),\n",
       "            TBLogger(\n",
       "                SummaryWriter(\n",
       "                    '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-30',\n",
       "                ),\n",
       "                date='2024-08-05T23:39:30',\n",
       "                name='Control',\n",
       "                description='Tiny Causal; the baseline control',\n",
       "                config=pp_config,\n",
       "                versions={\n",
       "                    'python': '3.10.13',\n",
       "                    'torch': '2.3.1',\n",
       "                    'transformers': '4.41.2',\n",
       "                    'accelerate': '0.31.0',\n",
       "                },\n",
       "            ),\n",
       "            TextgenCallback(\n",
       "                summary_writer=SummaryWriter(\n",
       "                    '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-39-30',\n",
       "                ),\n",
       "                prompts=testprompts,\n",
       "                generation_config=generation_config,\n",
       "                max_new_tokens=40,\n",
       "                generation_steps=2000,\n",
       "            ),\n",
       "        ],\n",
       "    ]\n",
       "\n",
       "    trainer = Trainer(\n",
       "        model=model,\n",
       "        args=trainer_args,\n",
       "        data_collator=data_collator,\n",
       "        train_dataset=train_dataset,\n",
       "        eval_dataset=eval_dataset,\n",
       "        tokenizer=tokenizer,\n",
       "        callbacks=trainer_callbacks,\n",
       "    )\n",
       "\n",
       "    training_script = TrainingScript(\n",
       "        meta=meta,\n",
       "        do_save=False,\n",
       "        do_train=True,\n",
       "        do_eval=False,\n",
       "        distributed_env=distributed_env,\n",
       "        trainer=trainer,\n",
       "    )\n",
       "    \n",
       "    return {\n",
       "        'meta': meta,\n",
       "        'main': training_script,\n",
       "    }\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "modules_path = os.path.join('..', 'src')\n",
    "if modules_path not in sys.path: sys.path.insert(0, modules_path)\n",
    "from pprint import pformat, pp\n",
    "from IPython import display as ds\n",
    "from forgather.config import (\n",
    "    ConfigEnvironment,\n",
    "    pconfig\n",
    ")\n",
    "from aiws.config import preprocessor_globals, MetaConfig\n",
    "import aiws.notebooks as nb\n",
    "from forgather.latent import Latent\n",
    "from forgather.codegen import generate_code\n",
    "\n",
    "meta = MetaConfig(fc.selected_path)\n",
    "default_config = meta.default_config()\n",
    "config_template_path = meta.config_path(config_template)\n",
    "environment = ConfigEnvironment(\n",
    "    searchpath=meta.searchpath,\n",
    "    global_vars = preprocessor_globals(fc.selected_path),\n",
    ")\n",
    "config, pp_config = environment.load(config_template_path).get()\n",
    "main_output = config.main(pp_config=pp_config)\n",
    "\n",
    "assert os.path.exists(fc.selected_path), \"Project directory does not exist.\"\n",
    "nb.show_project_readme(fc.selected_path)\n",
    "nb.display_meta(meta, \"### Meta Config\\n\")\n",
    "nb.list_templates(meta.find_templates(meta.config_prefix), \"### Available Configurations\\n\")\n",
    "\n",
    "print('-' * 60)\n",
    "print(f\"Default Configuration: {default_config}\")\n",
    "def list_templates(prefix):\n",
    "    nb.list_templates(meta.find_templates(prefix), \"### Templates\\n\")\n",
    "list_templates('')\n",
    "\n",
    "nb.display_referenced_templates_tree(environment, config_template_path, \"### Included Templates\\n\")\n",
    "nb.display_referenced_source_list(config, title=\"### Sub-Modules\\n\", deep=True)\n",
    "nb.display_preprocessed_template(environment, config_template_path, title=\"### Preprocessed Configuration\\n\")\n",
    "display(ds.Markdown(f\"### Loaded Configuration to YAML\\n```yaml\\n{Latent.to_yaml(config)}\\n```\"))\n",
    "generated_code = generate_code(config)\n",
    "display(ds.Markdown(f\"### Generated Source Code\\n```python\\n{generated_code}\\n```\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f0a06f-f425-41ef-878b-017a2d2c2718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
