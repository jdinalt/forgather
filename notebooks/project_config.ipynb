{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e422f35-7a08-4a50-a075-51a68b5c3994",
   "metadata": {},
   "source": [
    "# Configuration Notebook\n",
    "Useful for debugging configurations and viewing project configuration details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c5a90f-6386-4b8e-89ce-ec19195f7dff",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Configure defaults and select a project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26bffdcc-00ac-4adc-b3fd-974df44d09fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e105ba149254f049c4556a53bb27527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models', filename='', title='Seleâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set defaults\n",
    "#default_projects_directory = '/home/dinalt/ai_assets/projects/experiments'\n",
    "default_projects_directory = '../examples/trainers'\n",
    "default_project = \"dynamic_models\"\n",
    "config_template = \"\"\n",
    "\n",
    "from ipyfilechooser import FileChooser\n",
    "import os\n",
    "fc = FileChooser(\n",
    "    os.path.join(default_projects_directory, default_project), show_only_dirs=True,\n",
    "    title=\"Select a Project Directory\", select_default=True)\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4681a4d-fc01-43f7-a28f-308d6f4869b8",
   "metadata": {},
   "source": [
    "## Project Info\n",
    "\n",
    "This cell loads the import dependencies and the project meta-data from the selected project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "966a8a33-55a2-4ff0-b364-bd0ddbad4675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Dynamic Models\n",
       "\n",
       "This is a demonstraction of how to perform model archetecture experiments by using the configuration system to dynamically change module types.\n",
       "\n",
       "As most of the examples, we use \"Tiny Causal\" as a baseline, then make various changes for comparison.\n",
       "\n",
       "### Common Configuration\n",
       "- Tokenizer: tokenizers/tiny_2k_bpe.yaml\n",
       "    - Vocabulary Size: 2000\n",
       "    - Maximum Model Sequence: 2048\n",
       "- Dataset: datasets/tiny/tiny_stories_abridged.yaml\n",
       "    - Dataset ID: roneneldan/TinyStories\n",
       "    - Reference: https://arxiv.org/abs/2305.07759\n",
       "    - Train Select Range: 10% \n",
       "- Model:\n",
       "    - Model Dimension: 256\n",
       "    - MLP Dimension: 1024\n",
       "    - Layers: 4\n",
       "    - Heads: 2\n",
       "    - All Dropout Probabilities: 0.0\n",
       "- Trainer:\n",
       "    - Class: aiws.trainer.Trainer\n",
       "    - Epochs: 1\n",
       "    - Initial Learning Rate: 1.0e-3\n",
       "    - Train Batch Size: 32\n",
       "    - LR Sheduler: Cosine"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Meta Config\n",
       "Project Directory: /home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models\n",
       "\n",
       "Meta Config: [/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/meta.yaml](../examples/trainers/dynamic_models/meta.yaml)\n",
       "\n",
       "Template Search Paths:\n",
       "- [/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/templates](../examples/trainers/dynamic_models/templates)\n",
       "- [/home/dinalt/ai_assets/forgather/templates](../templates)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Available Configurations\n",
       "- [pre_ln.yaml](../examples/trainers/dynamic_models/templates/experiments/pre_ln.yaml)\n",
       "- [walsh_pe.yaml](../examples/trainers/dynamic_models/templates/experiments/walsh_pe.yaml)\n",
       "- [relu-glu.yaml](../examples/trainers/dynamic_models/templates/experiments/relu-glu.yaml)\n",
       "- [swish.yaml](../examples/trainers/dynamic_models/templates/experiments/swish.yaml)\n",
       "- [swi-glu.yaml](../examples/trainers/dynamic_models/templates/experiments/swi-glu.yaml)\n",
       "- [control.yaml](../examples/trainers/dynamic_models/templates/experiments/control.yaml)\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Default Configuration: control.yaml\n",
      "Selected Template Name: experiments/control.yaml\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "modules_path = os.path.join('..', 'src')\n",
    "if modules_path not in sys.path: sys.path.insert(0, modules_path)\n",
    "from pprint import pformat, pp\n",
    "from IPython import display as ds\n",
    "from forgather import Latent\n",
    "from forgather.config import ConfigEnvironment\n",
    "from forgather.codegen import generate_code\n",
    "from aiws.config import preprocessor_globals, MetaConfig\n",
    "import aiws.notebooks as nb\n",
    "\n",
    "assert os.path.exists(fc.selected_path), \"Project directory does not exist.\"\n",
    "nb.show_project_readme(fc.selected_path)\n",
    "\n",
    "# Get meta-config for project\n",
    "meta = MetaConfig(fc.selected_path)\n",
    "\n",
    "nb.display_meta(meta, \"### Meta Config\\n\")\n",
    "nb.list_templates(meta.find_templates(meta.config_prefix), \"### Available Configurations\\n\")\n",
    "\n",
    "# Get default config for project\n",
    "default_config = meta.default_config()\n",
    "print('-' * 60)\n",
    "print(f\"Default Configuration: {default_config}\")\n",
    "\n",
    "# Get the full name of the selected config template in the template name-space.\n",
    "# If empty, meta.config_path() will return the default template path.\n",
    "config_template_path = meta.config_path(config_template)\n",
    "print(f\"Selected Template Name: {config_template_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442e6d6-dab8-4e3d-8fff-b6ee71ccfe33",
   "metadata": {},
   "source": [
    "## List Available Templates\n",
    "This will list all templates within the searchpath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7753ff3-d9fe-4812-899d-60c38ac5c179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_templates(prefix):\n",
    "    nb.list_templates(meta.find_templates(prefix), \"### Templates\\n\")\n",
    "list_templates('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72a55f2-cf33-4eab-8c86-3f69212d2bc7",
   "metadata": {},
   "source": [
    "### Show Referenced Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8295f7-de68-4c86-bc5d-662ebae902f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.display_referenced_templates_tree(environment, config_template_path, \"### Included Templates\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fc8010-1a0b-4b88-8d5b-0020d40ccf1d",
   "metadata": {},
   "source": [
    "## Init Config Envrionment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04301bba-b40e-4f36-b0ad-2e07b6cfe79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration envrionment\n",
    "environment = ConfigEnvironment(\n",
    "    searchpath=meta.searchpath,\n",
    "    global_vars=preprocessor_globals(fc.selected_path),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a029b39-51c2-4eb2-96b0-55f7d9c8176b",
   "metadata": {},
   "source": [
    "## Preprocess Configiguration\n",
    "Not required, but can be useful for diagnostics prior to YAML parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25284dc-c3fc-4b0a-8d3d-3554d7ad20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_config = environment.preprocess(config_template_path)\n",
    "display(ds.Markdown(f\"#### Preprocessed Config\\n\" f\"```yaml\\n{pp_config}\\n```\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db7eba-83e6-4c0d-86fb-4228d61b5a98",
   "metadata": {},
   "source": [
    "## Load Configuration\n",
    "\n",
    "This will both preprocess and parse (YAML) the template in a single step, returning both the node-graph and the pre-processed config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d14e8c87-10f7-4f27-a007-4525621a1ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config, pp_config = environment.load(config_template_path).get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c38b86-86f2-4e0a-b717-1af806a01023",
   "metadata": {},
   "source": [
    "### Show Referenced Source Files\n",
    "\n",
    "Show referenced sub-modules within the same package.  \n",
    "For accurate results, the configuration must be instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434174da-3de0-4567-84b9-0c8a18eb5661",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.display_referenced_source_list(config, \"### Included Sources\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4c79d6-c79c-45f3-9c64-e558192a7d17",
   "metadata": {},
   "source": [
    "### Render Configuration as YAML\n",
    "\n",
    "Note: The configuration graph is language independent. This merely translates the graph to YAML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bdf697-8745-47f7-9ab1-d3ffdbdfa910",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ds.Markdown(f\"### Loaded Configuration\\n```yaml\\n{Latent.to_yaml(config)}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8090ae8-226b-4fd2-8b3c-16987b76a3fc",
   "metadata": {},
   "source": [
    "### Render Configuration as Python\n",
    "\n",
    "This will display the configuraiton graph as Python code. This even works correctly for recursively generated code.\n",
    "\n",
    "While the render tries to faithfully generate code which is identical to what Latent.materialize(config) would do, it's an interpretation and may not always produce identical results.\n",
    "\n",
    "One known issue is that LambdaNodes, which take arguments, are not rendered correctly. They work fine with 'materialize(),' but the lambdas in the generated code don't accept arguments from their caller. While fixable, doing so is fairly complicated, and the author lacks an infinite supply of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6f6dd9-8bf8-44fb-8c33-9f3e9efe1556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Generated Source Code\n",
       "```python\n",
       "from aiws.datasets import tokenize_dataset\n",
       "from aiws.json_logger import JsonLogger\n",
       "from aiws.tb_logger import TBLogger\n",
       "from torch.utils.tensorboard import SummaryWriter\n",
       "from aiws.distributed import DistributedEnvironment\n",
       "from aiws.trainer import Trainer\n",
       "from aiws.training_script import TrainingScript\n",
       "from aiws.construct import write_file\n",
       "from aiws.textgen_callback import TextgenCallback\n",
       "from aiws.trainer_types import TrainingArguments\n",
       "from datasets import load_dataset\n",
       "from aiws.construct import dependency_list\n",
       "from aiws.construct import copy_package_files\n",
       "from transformers import DataCollatorForLanguageModeling\n",
       "from aiws.construct import load_from_config\n",
       "from importlib.util import spec_from_file_location, module_from_spec\n",
       "import os\n",
       "import sys\n",
       "\n",
       "# Import a dynamic module.\n",
       "def dynimport(module, name, searchpath):\n",
       "    module_path = module\n",
       "    module_name = os.path.basename(module).split(\".\")[0]\n",
       "    module_spec = spec_from_file_location(\n",
       "        module_name,\n",
       "        module_path,\n",
       "        submodule_search_locations=searchpath,\n",
       "    )\n",
       "    mod = module_from_spec(module_spec)\n",
       "    sys.modules[module_name] = mod\n",
       "    module_spec.loader.exec_module(mod)\n",
       "    for symbol in name.split(\".\"):\n",
       "        mod = getattr(mod, symbol)\n",
       "    return mod\n",
       "\n",
       "DynamicCasualLM = lambda: dynimport(\"/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py\", \"DynamicCasualLM\", ['/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal', '/home/dinalt/ai_assets/forgather/model_src/bits'])\n",
       "DynamicCausalLMConfig = lambda: dynimport(\"/home/dinalt/ai_assets/forgather/model_src/dynamic_causal_lm.py\", \"DynamicCausalLMConfig\", ['/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal', '/home/dinalt/ai_assets/forgather/model_src/bits'])\n",
       "\n",
       "def construct(\n",
       "    pp_config,\n",
       "):\n",
       "    meta = {\n",
       "        'config_name': 'Control',\n",
       "        'config_description': 'Tiny Causal; the baseline control',\n",
       "        'project_dir': '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models',\n",
       "        'models_dir': '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models',\n",
       "        'tokenizers_dir': '/home/dinalt/ai_assets/forgather/tokenizers',\n",
       "        'datasets_dir': '/home/dinalt/ai_assets/forgather/datasets',\n",
       "        'output_dir': '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal',\n",
       "        'model_src_dir': '/home/dinalt/ai_assets/forgather/model_src',\n",
       "        'logging_dir': '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-38-38',\n",
       "        'create_new_model': 'True',\n",
       "        'save_model': 'False',\n",
       "        'train': 'True',\n",
       "        'eval': 'False',\n",
       "    }\n",
       "\n",
       "    distributed_env = DistributedEnvironment()\n",
       "\n",
       "    tokenizer = load_from_config(\n",
       "        project_dir='/home/dinalt/ai_assets/forgather/examples/tokenizers/tiny_stories_bpe',\n",
       "        config_template='2k.yaml',\n",
       "    )\n",
       "\n",
       "    model_code_writer = write_file(\n",
       "        data=(\n",
       "            'from torch.nn import Linear\\n'\n",
       "            'from torch.nn import LayerNorm\\n'\n",
       "            'from .init_weights import InitWeights\\n'\n",
       "            'from .causal_layer_stack import CausalLayerStack\\n'\n",
       "            'from .causal_lm import CasualLM\\n'\n",
       "            'from .sinusoidal_pe import SinusoidalPE\\n'\n",
       "            'from .input_encoder import InputEncoder\\n'\n",
       "            'from .causal_multihead_attn import CausalMultiheadAttn\\n'\n",
       "            'from .causal_loss import CausalLoss\\n'\n",
       "            'from .post_ln_layer import PostLNLayer\\n'\n",
       "            'from .feedforward_layer import FeedforwardLayer\\n'\n",
       "            '\\n'\n",
       "            'def construct_model(\\n'\n",
       "            '    num_hidden_layers,\\n'\n",
       "            '    initializer_range,\\n'\n",
       "            '    dim_feedforward,\\n'\n",
       "            '    num_attention_heads,\\n'\n",
       "            '    embedding_dropout,\\n'\n",
       "            '    hidden_size,\\n'\n",
       "            '    vocab_size,\\n'\n",
       "            '    layer_dropout,\\n'\n",
       "            '    activation_dropout,\\n'\n",
       "            '    attention_dropout,\\n'\n",
       "            '    max_sequence_length,\\n'\n",
       "            '    residual_dropout,\\n'\n",
       "            '    **kwargs\\n'\n",
       "            '):\\n'\n",
       "            '    loss_fn_factory = lambda: CausalLoss()\\n'\n",
       "            '\\n'\n",
       "            '    positional_encoder_factory = lambda: SinusoidalPE(\\n'\n",
       "            '        d_model=hidden_size,\\n'\n",
       "            '        max_sequence_length=max_sequence_length,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    input_encoder_factory = lambda: InputEncoder(\\n'\n",
       "            '        d_model=hidden_size,\\n'\n",
       "            '        vocab_size=vocab_size,\\n'\n",
       "            '        dropout=embedding_dropout,\\n'\n",
       "            '        positional_encoder=positional_encoder_factory(),\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    output_decoder_factory = lambda: Linear(\\n'\n",
       "            '        hidden_size,\\n'\n",
       "            '        vocab_size,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    feedforward_factory = lambda: FeedforwardLayer(\\n'\n",
       "            '        d_model=hidden_size,\\n'\n",
       "            '        d_feedforward=dim_feedforward,\\n'\n",
       "            '        dropout=activation_dropout,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    attention_factory = lambda: CausalMultiheadAttn(\\n'\n",
       "            '        d_model=hidden_size,\\n'\n",
       "            '        num_heads=num_attention_heads,\\n'\n",
       "            '        dropout=attention_dropout,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    layer_norm_factory = lambda: LayerNorm(\\n'\n",
       "            '        normalized_shape=hidden_size,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    layer_factory = lambda: PostLNLayer(\\n'\n",
       "            '        feedforward=feedforward_factory(),\\n'\n",
       "            '        attention=attention_factory(),\\n'\n",
       "            '        norm1=layer_norm_factory(),\\n'\n",
       "            '        norm2=layer_norm_factory(),\\n'\n",
       "            '        dropout=layer_dropout,\\n'\n",
       "            '        residual_dropout=residual_dropout,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    layer_stack_factory = lambda: CausalLayerStack(\\n'\n",
       "            '        layer_factory=layer_factory,\\n'\n",
       "            '        num_hidden_layers=num_hidden_layers,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    init_weights_factory = lambda: InitWeights(\\n'\n",
       "            '        std=initializer_range,\\n'\n",
       "            '    )\\n'\n",
       "            '\\n'\n",
       "            '    model_factory = CasualLM(\\n'\n",
       "            '        loss_fn=loss_fn_factory(),\\n'\n",
       "            '        input_encoder=input_encoder_factory(),\\n'\n",
       "            '        output_decoder=output_decoder_factory(),\\n'\n",
       "            '        layer_stack=layer_stack_factory(),\\n'\n",
       "            '        init_weights=init_weights_factory(),\\n'\n",
       "            '    )\\n'\n",
       "            '    \\n'\n",
       "            '    return model_factory'\n",
       "        ),\n",
       "        output_file='/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/model_factory.py',\n",
       "        return_value='Model constructor generated by Forgather 1.0',\n",
       "    )\n",
       "\n",
       "    model_config = DynamicCausalLMConfig()(\n",
       "        auto_map={\n",
       "            'AutoConfig': 'dynamic_causal_lm.DynamicCausalLMConfig',\n",
       "            'AutoModel': 'dynamic_causal_lm.DynamicCasualLM',\n",
       "        },\n",
       "        vocab_size=len(\n",
       "            tokenizer,\n",
       "        ),\n",
       "        pad_token_id=tokenizer.pad_token_id,\n",
       "        bos_token_id=tokenizer.bos_token_id,\n",
       "        eos_token_id=tokenizer.eos_token_id,\n",
       "        code_generator=model_code_writer,\n",
       "        hidden_size=256,\n",
       "        num_attention_heads=2,\n",
       "        num_hidden_layers=4,\n",
       "        max_sequence_length=tokenizer.model_max_length,\n",
       "        dim_feedforward=1024,\n",
       "        initializer_range=0.02,\n",
       "        embedding_dropout=0.0,\n",
       "        layer_dropout=0.0,\n",
       "        residual_dropout=0.0,\n",
       "        attention_dropout=0.0,\n",
       "        activation_dropout=0.0,\n",
       "    )\n",
       "\n",
       "    pretrained_model = DynamicCasualLM()(\n",
       "        model_config,\n",
       "    )\n",
       "\n",
       "    model = dependency_list(\n",
       "        pretrained_model,\n",
       "        copy_package_files(\n",
       "            '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal',\n",
       "            model_config,\n",
       "        ),\n",
       "        copy_package_files(\n",
       "            '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal',\n",
       "            pretrained_model,\n",
       "        ),\n",
       "    )\n",
       "\n",
       "    trainer_args = TrainingArguments(\n",
       "        output_dir='/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal',\n",
       "        logging_dir='/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-38-38',\n",
       "        overwrite_output_dir=True,\n",
       "        per_device_train_batch_size=32,\n",
       "        per_device_eval_batch_size=64,\n",
       "        learning_rate=0.001,\n",
       "        num_train_epochs=1,\n",
       "        eval_steps=500,\n",
       "        logging_steps=100,\n",
       "        eval_strategy='steps',\n",
       "        save_strategy='no',\n",
       "        logging_strategy='steps',\n",
       "        lr_scheduler_type='cosine',\n",
       "    )\n",
       "\n",
       "    data_collator = DataCollatorForLanguageModeling(\n",
       "        tokenizer,\n",
       "        mlm=False,\n",
       "        return_tensors='pt',\n",
       "    )\n",
       "\n",
       "    train_source_dataset = load_dataset(\n",
       "        'roneneldan/TinyStories',\n",
       "    )\n",
       "\n",
       "    train_dataset = tokenize_dataset(\n",
       "        dataset=train_source_dataset['train'],\n",
       "        tokenizer=tokenizer,\n",
       "        select_range=0.1,\n",
       "        desc='Tokenizing train',\n",
       "        fn_kwargs={\n",
       "            'truncation': True,\n",
       "        },\n",
       "    )\n",
       "\n",
       "    eval_dataset = tokenize_dataset(\n",
       "        dataset=train_source_dataset['validation'],\n",
       "        tokenizer=tokenizer,\n",
       "        select_range=500,\n",
       "        desc='Tokenizing validation split',\n",
       "        fn_kwargs={\n",
       "            'truncation': True,\n",
       "        },\n",
       "    )\n",
       "\n",
       "    testprompts = [\n",
       "        'Alice was so tired when she got back home so she went',\n",
       "        'Jack and Lily liked to watch the moon at night. They noticed that the moon changed its shape every night. Sometimes the moon was big and round, and sometimes it was',\n",
       "        'Jack and Lily saw a rainbow after a rainy day.They were amazed by the colors. Jack said, \"Look, Lily. A rainbow has',\n",
       "        'Jack wanted to read a book, so he went to',\n",
       "        '\"Can cows fly?\" Alice asked her mother.',\n",
       "        '\"What do birds like to eat?\" Tom asked his mother.',\n",
       "        '\"What language do they speak in France?\" Tom asked his mother.',\n",
       "        'If I throw a ball up in the air, eventually it will',\n",
       "        'It was winter and cold outside so his mother told him, \"You should',\n",
       "        'Lily likes cats and dogs. She asked her mom for a dog and her mom said no, so instead she asked',\n",
       "        'Jack told Mary, \"If you give me your banana, I\\'ll give you my apple.\" Mary gave Jack her Banana, so',\n",
       "        'On weekends Jack went to visit his grandmother whereas on weekdays he would go to school. Last weekend, when Jack was on his way to',\n",
       "        'Lily and Ben were having an argument. Ben said that cake is much better than ice cream and Lily said that',\n",
       "        'Lily and Ben are having an argument. They are trying to decide between the park and the swimming pool. Ben says, \"I want to go to the park\". Lily says',\n",
       "        \"Jack's mother was not home, and his father was at home. When Jack came home, he said hello to\",\n",
       "        \"Lily doesn't like swimming. When her father wants to take her to the swimming pool, she says\",\n",
       "        'Both Ben and Lily wanted cake. Father said that there was only one piece of cake left. They',\n",
       "        'Ben went to visit Lily in her house, but she was not at home. Ben knocked on the door,',\n",
       "    ]\n",
       "\n",
       "    generation_config = {\n",
       "        'identity': 'generation_config',\n",
       "        'do_sample': True,\n",
       "        'top_k': 20,\n",
       "        'top_p': 0.9,\n",
       "        'temperature': 0.7,\n",
       "        'repitition_penalty': 1.15,\n",
       "    }\n",
       "\n",
       "    trainer_callbacks = [\n",
       "        JsonLogger(\n",
       "            date='2024-08-05T23:38:38',\n",
       "            name='Control',\n",
       "            description='Tiny Causal; the baseline control',\n",
       "            config=pp_config,\n",
       "            versions={\n",
       "                'python': '3.10.13',\n",
       "                'torch': '2.3.1',\n",
       "                'transformers': '4.41.2',\n",
       "                'accelerate': '0.31.0',\n",
       "            },\n",
       "        ),\n",
       "        TBLogger(\n",
       "            SummaryWriter(\n",
       "                '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-38-38',\n",
       "            ),\n",
       "            date='2024-08-05T23:38:38',\n",
       "            name='Control',\n",
       "            description='Tiny Causal; the baseline control',\n",
       "            config=pp_config,\n",
       "            versions={\n",
       "                'python': '3.10.13',\n",
       "                'torch': '2.3.1',\n",
       "                'transformers': '4.41.2',\n",
       "                'accelerate': '0.31.0',\n",
       "            },\n",
       "        ),\n",
       "        TextgenCallback(\n",
       "            summary_writer=SummaryWriter(\n",
       "                '/home/dinalt/ai_assets/forgather/examples/trainers/dynamic_models/output_models/tiny_causal/runs/control_2024-08-05T23-38-38',\n",
       "            ),\n",
       "            prompts=testprompts,\n",
       "            generation_config=generation_config,\n",
       "            max_new_tokens=40,\n",
       "            generation_steps=2000,\n",
       "        ),\n",
       "    ]\n",
       "\n",
       "    trainer = Trainer(\n",
       "        model=model,\n",
       "        args=trainer_args,\n",
       "        data_collator=data_collator,\n",
       "        train_dataset=train_dataset,\n",
       "        eval_dataset=eval_dataset,\n",
       "        tokenizer=tokenizer,\n",
       "        callbacks=trainer_callbacks,\n",
       "    )\n",
       "\n",
       "    training_script = TrainingScript(\n",
       "        meta=meta,\n",
       "        do_save=False,\n",
       "        do_train=True,\n",
       "        do_eval=False,\n",
       "        distributed_env=distributed_env,\n",
       "        trainer=trainer,\n",
       "    )\n",
       "    \n",
       "    return {\n",
       "        'meta': meta,\n",
       "        'main': training_script,\n",
       "    }\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generated_code = generate_code(config)\n",
    "display(ds.Markdown(f\"### Generated Source Code\\n```python\\n{generated_code}\\n```\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4848270-6d49-412f-a3a2-b72222461140",
   "metadata": {},
   "source": [
    "## Materialized Configuration\n",
    "\n",
    "Instantiate the configuration from the definition.\n",
    "This loads all of the referenced modules and instantiates the main output. Some configurations will run preprocessing when loaded, so this can take a moment.\n",
    "\n",
    "And don't run this if you don't trust the source of the configuration!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4a60c-ce9b-4738-9eb1-4deb39d559ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from loguru import logger\n",
    "#logger.enable(\"forgather.latent\")\n",
    "\n",
    "config, pp_config = environment.load(meta.config_path(config_template)).get()\n",
    "\n",
    "# Note: We inject the pre-processed config as an argument, which can then be used to log this information.\n",
    "main_output = Latent.materialize(config, pp_config=pp_config)['main']\n",
    "pp(main_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0aabd1-41c4-4540-80fe-9a2057455cd9",
   "metadata": {},
   "source": [
    "## Execute Generate Code\n",
    "\n",
    "This executes the generated code and calls 'construct()', the default factory function, to instantiate the configuration.\n",
    "\n",
    "In theory, the output should be identitical to calling Latent.materialize(config), but there are know differences (see section on code generation for details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ed4aa-be0f-45f5-ba3f-e206818e4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(generated_code)\n",
    "main_output = construct(pp_config=pp_config)['main']\n",
    "pp(main_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec21d135-1575-4684-a639-ce1c38162063",
   "metadata": {},
   "source": [
    "### Run Configuration\n",
    "\n",
    "Assuming that this the output object has a 'run' method (training scripts do), the following will run it.\n",
    "\n",
    "For a more robust approach, see: [train.ipynb](train.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ccce36-feda-4ba1-8fb9-31a5b3d7871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_output.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8337a-08a2-411f-8173-4946347bcc4b",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Note: These will show the target directory and ask for confirmation before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f81bf-d882-42fe-915c-f52336a4e774",
   "metadata": {},
   "source": [
    "#### Delete All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96252b4b-1b5e-4538-85e3-c4616a7c32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.delete_dir(config.meta['models_dir'], \"Delete all models in project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7e0b2-b8c3-4d77-88d7-fe17f80541b4",
   "metadata": {},
   "source": [
    "#### Delete Configuration Output Directory\n",
    "This will delete the model and logs for the current configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980be21d-b95d-4ef5-baf4-2378e5971a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.delete_dir(config.meta['output_dir'], \"Delete output directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8000891f-950d-4ce5-b298-c8601d1fb9a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
