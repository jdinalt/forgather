{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5862a8b9-ea0b-4fec-b150-8cbb3218e8bb",
   "metadata": {},
   "source": [
    "# Training Notebook\n",
    "Configuration details: [Configuration Notebook](project_config.ipynb)\n",
    "\n",
    "Run project training configurations and generate training scripts from project meta-data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c580dde-ff81-449e-b719-914a6501d7ce",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7715292a-61c8-4be5-9cfd-72530c25e72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "projects_directory = \"/home/dinalt/ai_assets/forgather/tutorials/project_delta\"\n",
    "config_template = \"\"\n",
    "\n",
    "# Path to training script to use.\n",
    "train_script_path = os.path.join('..', 'scripts', 'train_script.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef2f76-28e2-4c76-b540-ae211b00fe87",
   "metadata": {},
   "source": [
    "## Project Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5f19b24-2954-438d-a79c-e8a86e5cbb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Tiny Generative Language Model\n",
       "\n",
       "This project demonstrates how to use the templates library to construct a tiny causal transformer.\n",
       "\n",
       "Most of the remaining examples make use of the Tiny Stories dataset, as it allows one to quickly train a relatively small transformer model (< 10M parameters), which can generate relatively coherent speech.\n",
       "\n",
       "- Dataset: datasets/tiny/tiny_stories_abridged.yaml\n",
       "    - Dataset ID: roneneldan/TinyStories\n",
       "    - Reference: https://arxiv.org/abs/2305.07759\n",
       "\n",
       "Unlike the previous examples, the project meta-config now makes use of the templates library, thus many more templates are now available to the project.\n",
       "\n",
       "The project configuration itself is now even derived from a common \"Tiny Experiments\" project template, which defines defaults for a number of projects with similar setups. See \"projects/tiny.yaml.\"\n",
       "\n",
       "---\n",
       "\n",
       "### Meta Config\n",
       "Meta Config: [/home/dinalt/ai_assets/forgather/tutorials/project_delta/meta.yaml](../tutorials/project_delta/meta.yaml)\n",
       "\n",
       "- [meta.yaml](../tutorials/project_delta/meta.yaml)\n",
       "\n",
       "Template Search Paths:\n",
       "- [/home/dinalt/ai_assets/forgather/tutorials/project_delta/templates](../tutorials/project_delta/templates)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/tiny_experiments](../templates/tiny_experiments)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/modellib](../templates/modellib)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/base](../templates/base)\n",
       "\n",
       "### Available Configurations\n",
       "- [tiny_causal.yaml](../tutorials/project_delta/templates/configs/tiny_causal.yaml)\n",
       "\n",
       "### Tiny Causal:\n",
       "\n",
       "```python\n",
       "{'config_description': 'A tiny causal transformer.',\n",
       " 'config_name': 'Tiny Causal',\n",
       " 'create_new_model': 'True',\n",
       " 'datasets_dir': '/home/dinalt/ai_assets/forgather/datasets',\n",
       " 'eval': 'False',\n",
       " 'logging_dir': '/home/dinalt/ai_assets/forgather/tutorials/project_delta/output_models/tiny_causal/runs/log_2024-08-12T07-03-35',\n",
       " 'model_src_dir': '/home/dinalt/ai_assets/forgather/model_src',\n",
       " 'models_dir': '/home/dinalt/ai_assets/forgather/tutorials/project_delta/output_models',\n",
       " 'output_dir': '/home/dinalt/ai_assets/forgather/tutorials/project_delta/output_models/tiny_causal',\n",
       " 'project_dir': '/home/dinalt/ai_assets/forgather/tutorials/project_delta',\n",
       " 'save_model': 'False',\n",
       " 'tokenizers_dir': '/home/dinalt/ai_assets/forgather/tokenizers',\n",
       " 'train': 'True'}\n",
       "\n",
       "```\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "modules_path = os.path.join('..', 'src')\n",
    "if modules_path not in sys.path: sys.path.insert(0, modules_path)\n",
    "\n",
    "from pprint import pp, pformat\n",
    "from IPython import display as ds\n",
    "from forgather import Project\n",
    "import forgather.nb.notebooks as nb\n",
    "\n",
    "# Load the project\n",
    "proj = Project(projects_directory, config_template)\n",
    "\n",
    "# Show project info\n",
    "md = \"\"\n",
    "md += nb.render_project_readme(proj.project_dir)\n",
    "md += nb.render_meta(proj.meta, \"### Meta Config\\n\")\n",
    "md += nb.render_template_list(proj.meta.find_templates(proj.meta.config_prefix), \"### Available Configurations\\n\")\n",
    "\n",
    "# Only construct the meta object\n",
    "config_meta = proj.config.meta()\n",
    "md += f\"### {config_meta['config_name']}:\\n\\n\"\n",
    "md += nb.render_codeblock(\"python\", pformat(config_meta))\n",
    "display(ds.Markdown(md))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da62d15b-9479-4ee0-a5d0-e148e45572e9",
   "metadata": {},
   "source": [
    "### Launch Notebook Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff957464-78cc-48c0-a6e3-7a68cc9df5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching training on one GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Training Script Started *****\n",
      "config_name: Tiny Causal\n",
      "config_description: A tiny causal transformer.\n",
      "output_dir: /home/dinalt/ai_assets/forgather/tutorials/project_delta/output_models/tiny_causal\n",
      "logging_dir: /home/dinalt/ai_assets/forgather/tutorials/project_delta/output_models/tiny_causal/runs/log_2024-08-12T07-03-55\n",
      "not compiling model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac752257a2c40c4a4c5d5dbf7ad9ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_examples: 212,000\n",
      "total_train_samples: 212,000\n",
      "per_device_train_batch_size: 32\n",
      "actual_per_device_batch_size: 32\n",
      "total_train_batch_size: 32\n",
      "max_steps: 6,625\n",
      "total_parameters: 4.2M\n",
      "trainable_parameters: 4.2M\n",
      "model:\n",
      "DynamicCasualLM(\n",
      "  (causal_lm): CasualLM(\n",
      "    loss_fn=CausalLoss(), init_weights=InitWeights(std=0.02)\n",
      "    (input_encoder): InputEncoder(\n",
      "      d_model=256, vocab_size=2000, embedding_scale=16.0\n",
      "      (dropout): Identity()\n",
      "      (embedding): Embedding(2000, 256)\n",
      "      (positional_encoder): SinusoidalPE(d_model=256, max_sequence_length=2048)\n",
      "    )\n",
      "    (output_decoder): Linear(in_features=256, out_features=2000, bias=True)\n",
      "    (layer_stack): LayerStack(\n",
      "      (layers): ModuleList(\n",
      "        (0-3): 4 x PostLNLayer(\n",
      "          (feedforward): FeedforwardLayer(\n",
      "            d_model=256, d_feedforward=1024\n",
      "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
      "            (dropout): Identity()\n",
      "            (activation): ReLU()\n",
      "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
      "          )\n",
      "          (attention): CausalMultiheadAttn(\n",
      "            d_model=256, num_heads=2\n",
      "            (query_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (key_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (value_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (output_linear): Linear(in_features=256, out_features=256, bias=True)\n",
      "            (dropout): Identity()\n",
      "          )\n",
      "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout): Identity()\n",
      "          (residual_dropout): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "2024-08-12 07:04:04          100  0.02  train-loss: 4.87245   learning-rate: 9.99e-04\n",
      "2024-08-12 07:04:06          200  0.03  train-loss: 3.76461   learning-rate: 9.98e-04\n",
      "2024-08-12 07:04:08          300  0.05  train-loss: 3.4008    learning-rate: 9.95e-04\n",
      "2024-08-12 07:04:11          400  0.06  train-loss: 3.24113   learning-rate: 9.91e-04\n",
      "2024-08-12 07:04:14          500  0.08  train-loss: 3.0373    learning-rate: 9.86e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a99af76eba243bb81b7cbff213e667d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-12 07:04:14          500  0.08  eval-loss:  3.0656    \n",
      "2024-08-12 07:04:18          600  0.09  train-loss: 2.91868   learning-rate: 9.80e-04\n",
      "2024-08-12 07:04:20          700  0.11  train-loss: 2.78024   learning-rate: 9.73e-04\n",
      "2024-08-12 07:04:23          800  0.12  train-loss: 2.72547   learning-rate: 9.64e-04\n",
      "2024-08-12 07:04:25          900  0.14  train-loss: 2.5799    learning-rate: 9.55e-04\n",
      "2024-08-12 07:04:28        1,000  0.15  train-loss: 2.43488   learning-rate: 9.45e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10f3aca27eb4bed9b9ba9dc5b4bfbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-12 07:04:28        1,000  0.15  eval-loss:  2.47814   \n",
      "2024-08-12 07:04:31        1,100  0.17  train-loss: 2.44562   learning-rate: 9.34e-04\n",
      "2024-08-12 07:04:33        1,200  0.18  train-loss: 2.40362   learning-rate: 9.21e-04\n",
      "2024-08-12 07:04:35        1,300  0.2   train-loss: 2.37533   learning-rate: 9.08e-04\n",
      "2024-08-12 07:04:37        1,400  0.21  train-loss: 2.35209   learning-rate: 8.94e-04\n",
      "2024-08-12 07:04:40        1,500  0.23  train-loss: 2.32055   learning-rate: 8.79e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9508e88660504dc38922c9c517548f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-12 07:04:40        1,500  0.23  eval-loss:  2.20528   \n",
      "2024-08-12 07:04:42        1,600  0.24  train-loss: 2.28048   learning-rate: 8.63e-04\n",
      "2024-08-12 07:04:45        1,700  0.26  train-loss: 2.2436    learning-rate: 8.46e-04\n",
      "2024-08-12 07:04:47        1,800  0.27  train-loss: 2.1873    learning-rate: 8.29e-04\n",
      "2024-08-12 07:04:50        1,900  0.29  train-loss: 2.17336   learning-rate: 8.10e-04\n",
      "2024-08-12 07:04:52        2,000  0.3   train-loss: 2.22112   learning-rate: 7.91e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ed8d6f1a964bd88c65b436afcf3a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-12 07:04:52        2,000  0.3   eval-loss:  2.1152    \n",
      "2024-08-12 07:04:57        2,100  0.32  train-loss: 2.16833   learning-rate: 7.72e-04\n",
      "2024-08-12 07:04:59        2,200  0.33  train-loss: 2.11852   learning-rate: 7.52e-04\n",
      "2024-08-12 07:05:01        2,300  0.35  train-loss: 2.07779   learning-rate: 7.31e-04\n",
      "2024-08-12 07:05:03        2,400  0.36  train-loss: 2.1432    learning-rate: 7.10e-04\n",
      "2024-08-12 07:05:05        2,500  0.38  train-loss: 2.10482   learning-rate: 6.88e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8204533bade74bc78586ef1a5ecc4480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-12 07:05:05        2,500  0.38  eval-loss:  2.00863   \n",
      "2024-08-12 07:05:08        2,600  0.39  train-loss: 2.11472   learning-rate: 6.66e-04\n",
      "2024-08-12 07:05:10        2,700  0.41  train-loss: 2.04447   learning-rate: 6.43e-04\n",
      "2024-08-12 07:05:12        2,800  0.42  train-loss: 2.09566   learning-rate: 6.20e-04\n",
      "2024-08-12 07:05:14        2,900  0.44  train-loss: 2.00747   learning-rate: 5.97e-04\n",
      "2024-08-12 07:05:17        3,000  0.45  train-loss: 1.89774   learning-rate: 5.74e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950b6785f4b249e0a3f5816d8206f66e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                                         â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-08-12 07:05:17        3,000  0.45  eval-loss:  1.89916   \n",
      "2024-08-12 07:05:20        3,100  0.47  train-loss: 1.99214   learning-rate: 5.50e-04\n",
      "2024-08-12 07:05:21        3,200  0.48  train-loss: 2.07619   learning-rate: 5.27e-04\n",
      "2024-08-12 07:05:24        3,300  0.5   train-loss: 1.96536   learning-rate: 5.03e-04\n"
     ]
    }
   ],
   "source": [
    "from accelerate import notebook_launcher\n",
    "from forgather.ml.training_script import training_loop\n",
    "\n",
    "notebook_launcher(\n",
    "    training_loop,\n",
    "    args=(proj.project_dir, proj.config_name),\n",
    "    num_processes=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1b276e-ec55-4180-ba5b-df7e4b231bf9",
   "metadata": {},
   "source": [
    "### Run All Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4924c5-e45b-4d26-9370-1745774a2c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import notebook_launcher\n",
    "from forgather.ml.training_script import training_loop\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = str(3)\n",
    "def run_all_configurations():\n",
    "    for proj.config_name, _ in proj.meta.find_templates(proj.meta.config_prefix):\n",
    "        print(f\"{ ' Starting ' + proj.config_name + ' ':-^60}\")\n",
    "        notebook_launcher(\n",
    "            training_loop,\n",
    "            args=(proj.project_dir, proj.config_name,),\n",
    "            num_processes=1\n",
    "        )\n",
    "\n",
    "run_all_configurations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba86cc3-734d-46b4-8813-d8494cbc41b1",
   "metadata": {},
   "source": [
    "### Generate Training Script\n",
    "\n",
    "```python\n",
    "def make_train_script(\n",
    "    project_directory,\n",
    "    config_template=None,\n",
    "    script_name='train.sh',\n",
    "    nproc='gpu',\n",
    "    cuda_devices=None\n",
    "):\n",
    "```\n",
    "Generate a bash training script from a project meta-config\n",
    "\n",
    "The generated script will be written to 'project_directory' and all paths will be\n",
    "relative to this location.\n",
    "\n",
    "- project_directory: The project directory. Assumes meta-config is 'meta_config.yaml'\n",
    "- script_name: The name of the output script. If none, the script can be specified on the command-line.\n",
    "- nproc: Number of processes; 'gpu' is number of available GPUs\n",
    "- cuda_devices: List of CUDA devices to limit training to.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec75bc-20e7-49d5-a7c2-8a3af0c8f4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_script(cuda_devices=None):\n",
    "    script_name = os.path.splitext(os.path.basename(proj.config_name))[0] + \".sh\"\n",
    "    nb.make_train_script(\n",
    "        train_script_path=os.path.abspath(train_script_path),\n",
    "        project_directory=proj.project_dir,\n",
    "        config_template=proj.config_name,\n",
    "        script_name=script_name,\n",
    "        cuda_devices=cuda_devices)\n",
    "\n",
    "    # Read back to verify\n",
    "    script_path = os.path.join(proj.project_dir, script_name)\n",
    "    with open(script_path, 'r') as f:\n",
    "        md = (\n",
    "            f\"#### Generated Shell Script\\n\"\n",
    "            f\"[{script_name}]({os.path.relpath(script_path)})\\n\"\n",
    "            f\"```bash\\n{f.read()}\\n```\"\n",
    "        )\n",
    "        display(ds.Markdown(md))\n",
    "generate_script(\"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27958aa1-fc70-4401-9f2a-55e2ef14f469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign sequential GPUs to each configuration\n",
    "def sequential_devices(i=0):\n",
    "    while True:\n",
    "        yield str(i)\n",
    "        i += 1\n",
    "\n",
    "# Assign the same fixed set of GPUs to each config\n",
    "def same_devices(devices=\"0,1\"):\n",
    "    while True:\n",
    "        yield devices\n",
    "\n",
    "# Assign all GPUs to all configs\n",
    "def all_devices():\n",
    "    while True:\n",
    "        yield None\n",
    "\n",
    "def generate_all_scripts(device_iter=all_devices()):\n",
    "    for devices, (proj.config_name, _) in zip(device_iter, proj.meta.find_templates(proj.meta.config_prefix)):\n",
    "        script_name = os.path.splitext(proj.config_name)[0] + \".sh\"\n",
    "        nb.make_train_script(\n",
    "            train_script_path=os.path.abspath(train_script_path),\n",
    "            project_directory=proj.project_dir,\n",
    "            config_template=proj.config_name,\n",
    "            script_name=script_name,\n",
    "            cuda_devices=devices)\n",
    "        script_path = os.path.join(proj.project_dir, script_name)\n",
    "        with open(script_path, 'r') as f:\n",
    "            \n",
    "            md = (\n",
    "                f\"[{script_name}]({os.path.relpath(script_path)})\\n\"\n",
    "                f\"```bash\\n{f.read()}\\n```\"\n",
    "            )\n",
    "            display(ds.Markdown(md))\n",
    "\n",
    "generate_all_scripts(sequential_devices(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94085b9-a00a-4bda-914c-9de37c7c92a4",
   "metadata": {},
   "source": [
    "### Run Script from Notebook\n",
    "Lauch the training script from the notebook.\n",
    "\n",
    "Note: The terminal emulation of the notebook is lacking, thus rendering of progress bars may be broken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba880a-18c2-4e5e-b845-985d29d95972",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{nb.get_train_cmdline(train_script_path, proj.meta, cuda_devices='0')} '{proj.config_name}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c0e8f-aa96-4547-8239-bb4404556b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{nb.get_train_cmdline(train_script_path, proj.meta, cuda_devices=\"0\")} '{proj.config_name}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855f14c-92d4-4adc-804a-f3ff17eedeb8",
   "metadata": {},
   "source": [
    "### View in Tensorboard\n",
    "Note: If the notebook is running on the same machine as the trainer, remove \"--bind_all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363765bf-dcf7-4f07-8dc5-38a1ac0121d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All models\n",
    "!tensorboard --bind_all --logdir \"{config_meta['models_dir']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba51dd-1914-4f24-a785-ff31e56f07af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current model only\n",
    "!tensorboard --bind_all --logdir \"{config_meta['output_dir']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8337a-08a2-411f-8173-4946347bcc4b",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "Note: These will show the target directory and ask for confirmation before proceeding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f81bf-d882-42fe-915c-f52336a4e774",
   "metadata": {},
   "source": [
    "#### Delete All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96252b4b-1b5e-4538-85e3-c4616a7c32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.delete_dir(config_meta['models_dir'], \"Delete all models in project\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee7e0b2-b8c3-4d77-88d7-fe17f80541b4",
   "metadata": {},
   "source": [
    "#### Delete Configuration Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980be21d-b95d-4ef5-baf4-2378e5971a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.delete_dir(config_meta['output_dir'], \"Delete output directory\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
