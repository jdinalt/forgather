{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e422f35-7a08-4a50-a075-51a68b5c3994",
   "metadata": {},
   "source": [
    "# Project Index\n",
    "\n",
    "[Custom Model Notebook](../../notebooks/custom_model.ipynb)  \n",
    "[Training Notebook](../../notebooks/train.ipynb)  \n",
    "[Project Config Notebook](../../notebooks/project_config.ipynb)  \n",
    "[Forgather Notebook](../../notebooks/forgather.ipynb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26bffdcc-00ac-4adc-b3fd-974df44d09fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Traning an Eye for Fashion\n",
       "\n",
       "This project reproduces the configuration from a PyTorch tutorial, where a simple ML model is created and trained to recognize categories of clothing from the FashionMNIST dataset.\n",
       "\n",
       "https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
       "\n",
       "This was chosen as it is a relatively simple project which can be relativley self contained. Still, it is far more complex than the previous examples.\n",
       "\n",
       "See also: https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
       "\n",
       "## Custom Code\n",
       "\n",
       "While Forgather is good at assembling objects, the language is not practical for defining logic. For this, we have defined a custom \"trainer\" class in the project's 'src' directory and we will use Forgather to dynamically import this code, injecting all the required dependencies.\n",
       "\n",
       "Unlike the previous projects, you will note that the \"Modules\" section not empty and has a link to the model definition.\n",
       "\n",
       "## Project Structure\n",
       "\n",
       "Like the previous example, this project makes use of template inheritance, where there is a common 'project.yaml' file from which all of the configuratioins are derived.\n",
       "\n",
       "Unlike the previous project, the we make use of the templates library to help automate things. This project was actually more complex to setup than most, as there is not a pre-existing template for Torch-vision projects, so the project template had to fill in the details.\n",
       "\n",
       "\n",
       "---\n",
       "\n",
       "\n",
       "\n",
       "#### Project Directory: \"/home/dinalt/ai_assets/forgather/tutorials/project_gamma\"\n",
       "\n",
       "## Meta Config\n",
       "Meta Config: [/home/dinalt/ai_assets/forgather/tutorials/project_gamma/meta.yaml](meta.yaml)\n",
       "\n",
       "- [meta.yaml](meta.yaml)\n",
       "    - [meta_defaults.yaml](../../forgather_workspace/meta_defaults.yaml)\n",
       "        - [base_directories.yaml](../../forgather_workspace/base_directories.yaml)\n",
       "\n",
       "Template Search Paths:\n",
       "- [/home/dinalt/ai_assets/forgather/tutorials/project_gamma/templates](templates)\n",
       "- [/home/dinalt/ai_assets/forgather/forgather_workspace](../../forgather_workspace)\n",
       "- [/home/dinalt/ai_assets/forgather/templates/base](../../templates/base)\n",
       "\n",
       "## Available Configurations\n",
       "- [adam.yaml](templates/experiments/adam.yaml)\n",
       "- [baseline.yaml](templates/experiments/baseline.yaml)\n",
       "\n",
       "Default Configuration: baseline.yaml\n",
       "\n",
       "Active Configuration: baseline.yaml\n",
       "\n",
       "## Available Templates\n",
       "- [base_directories.yaml](../../forgather_workspace/base_directories.yaml)\n",
       "- [callbacks/base_callbacks.yaml](../../templates/base/callbacks/base_callbacks.yaml)\n",
       "- [callbacks/loggers.yaml](../../templates/base/callbacks/loggers.yaml)\n",
       "- [datasets/abstract/base_datasets.yaml](../../templates/base/datasets/abstract/base_datasets.yaml)\n",
       "- [datasets/abstract/pretokenized_dataset.yaml](../../templates/base/datasets/abstract/pretokenized_dataset.yaml)\n",
       "- [experiments/adam.yaml](templates/experiments/adam.yaml)\n",
       "- [experiments/baseline.yaml](templates/experiments/baseline.yaml)\n",
       "- [meta_defaults.yaml](../../forgather_workspace/meta_defaults.yaml)\n",
       "- [model_test/base.yaml](../../templates/base/model_test/base.yaml)\n",
       "- [model_test/sub_project.yaml](../../templates/base/model_test/sub_project.yaml)\n",
       "- [models/abstract/base_language_model.yaml](../../templates/base/models/abstract/base_language_model.yaml)\n",
       "- [models/abstract/causal_lm_from_config.yaml](../../templates/base/models/abstract/causal_lm_from_config.yaml)\n",
       "- [models/abstract/causal_lm_from_pretrained.yaml](../../templates/base/models/abstract/causal_lm_from_pretrained.yaml)\n",
       "- [models/abstract/custom_causal_lm.yaml](../../templates/base/models/abstract/custom_causal_lm.yaml)\n",
       "- [models/abstract/dynamic_causal_lm.yaml](../../templates/base/models/abstract/dynamic_causal_lm.yaml)\n",
       "- [models/abstract/load_model.yaml](../../templates/base/models/abstract/load_model.yaml)\n",
       "- [project.yaml](templates/project.yaml)\n",
       "- [trainers/accel_trainer.yaml](../../templates/base/trainers/accel_trainer.yaml)\n",
       "- [trainers/base_trainer.yaml](../../templates/base/trainers/base_trainer.yaml)\n",
       "- [trainers/hf_trainer.yaml](../../templates/base/trainers/hf_trainer.yaml)\n",
       "- [trainers/minimal_trainer.yaml](../../templates/base/trainers/minimal_trainer.yaml)\n",
       "- [trainers/simple_trainer.yaml](../../templates/base/trainers/simple_trainer.yaml)\n",
       "- [trainers/trainer.yaml](../../templates/base/trainers/trainer.yaml)\n",
       "- [types/meta_template.yaml](../../templates/base/types/meta_template.yaml)\n",
       "- [types/model/model_type.yaml](../../templates/base/types/model/model_type.yaml)\n",
       "- [types/tokenizer/bpe/bpe.yaml](../../templates/base/types/tokenizer/bpe/bpe.yaml)\n",
       "- [types/tokenizer/tokenizer.yaml](../../templates/base/types/tokenizer/tokenizer.yaml)\n",
       "- [types/training_script/causal_lm/causal_lm.yaml](../../templates/base/types/training_script/causal_lm/causal_lm.yaml)\n",
       "- [types/training_script/training_script.yaml](../../templates/base/types/training_script/training_script.yaml)\n",
       "- [types/type.yaml](../../templates/base/types/type.yaml)\n",
       "\n",
       "## Included Templates\n",
       "- [experiments/baseline.yaml](templates/experiments/baseline.yaml)\n",
       "    - [project.yaml](templates/project.yaml)\n",
       "        - [types/training_script/training_script.yaml](../../templates/base/types/training_script/training_script.yaml)\n",
       "            - [types/type.yaml](../../templates/base/types/type.yaml)\n",
       "                - [base_directories.yaml](../../forgather_workspace/base_directories.yaml)\n",
       "            - [inc/formatting.jinja](../../templates/base/inc/formatting.jinja)\n",
       "        - [project.trainer_config](templates/project.yaml)\n",
       "            - [trainers/simple_trainer.yaml](../../templates/base/trainers/simple_trainer.yaml)\n",
       "                - [trainers/minimal_trainer.yaml](../../templates/base/trainers/minimal_trainer.yaml)\n",
       "## Preprocessed Config\n",
       "\n",
       "```yaml\n",
       "#---------------------------------------\n",
       "#          Fashion MNIST Trainer         \n",
       "#---------------------------------------\n",
       "# 2024-08-17T01:33:47\n",
       "# Description: Base configuration, based on Torch tutorial parameters.\n",
       "# Project Dir: /home/dinalt/ai_assets/forgather/tutorials/project_gamma\n",
       "# Current Working Dir: \"/home/dinalt/ai_assets/forgather/tutorials/project_gamma\"\n",
       "# Forgather Config Dir: \"/home/dinalt/.config/forgather\"\n",
       "# Model: base_model\n",
       "# Hostname: hal9000\n",
       "# Versions:\n",
       "#     python: 3.10.13\n",
       "#     torch: 2.3.1\n",
       "#     transformers: 4.41.2\n",
       "#     accelerate: 0.31.0\n",
       "\n",
       "# Source: https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
       "\n",
       "############# Config Vars ##############\n",
       "\n",
       "# ns.forgather_dir: \"/home/dinalt/ai_assets/forgather\"\n",
       "# ns.models_dir: \"/home/dinalt/ai_assets/forgather/tutorials/project_gamma/output_models\"\n",
       "# ns.project_model_src_dir: \"/home/dinalt/ai_assets/forgather/tutorials/project_gamma/model_src\"\n",
       "# ns.tokenizers_dir: \"/home/dinalt/ai_assets/forgather/tokenizers\"\n",
       "# ns.datasets_dir: \"/home/dinalt/ai_assets/forgather/datasets\"\n",
       "# ns.model_src_dir: \"/home/dinalt/ai_assets/forgather/model_src\"\n",
       "# ns.output_dir: \"./output_models/base_model\"\n",
       "# ns.logging_dir: \"./output_models/base_model/runs/base_model_2024-08-17T01-33-47\"\n",
       "# ns.create_new_model: True\n",
       "# ns.save_model: True\n",
       "# ns.train: True\n",
       "# ns.eval: False\n",
       "\n",
       "####### Distributed Environment ########\n",
       "\n",
       ".define: &distributed_env !singleton:forgather.ml.distributed:DistributedEnvironment@distributed_env\n",
       "\n",
       "############# Dependencies #############\n",
       "\n",
       "\n",
       "\n",
       "################ Model #################\n",
       "\n",
       ".define: &model_constructor_args {}\n",
       "\n",
       ".define: &loss_fn !factory:torch.nn:CrossEntropyLoss []\n",
       "\n",
       ".define: &activation_factory !lambda:torch.nn:ReLU@activation_factory []\n",
       "\n",
       ".define: &model_constructor !singleton:./model_src/mlp_model.py:MultilayerPerceptron\n",
       "    # Defaults, from PyTorch Tutorial.\n",
       "    d_input: 784 # The input image dimensions\n",
       "    d_model: 512 # a.k.a \"Hidden Dimension\"\n",
       "    d_output: 10 # The number of categories in the dataset\n",
       "    activation_factory: *activation_factory\n",
       "    loss_fn: *loss_fn    \n",
       "\n",
       "\n",
       "# Copy model mode to output directory.\n",
       ".define: &model !singleton:forgather.ml.construct:dependency_list@model\n",
       "    - *model_constructor\n",
       "    - !singleton:forgather.ml.construct:copy_package_files\n",
       "        - \"./output_models/base_model\"\n",
       "        - *model_constructor\n",
       "\n",
       "\n",
       "# Model does not have dynamic code generation.\n",
       ".define: &model_code_writer null\n",
       "\n",
       "############### Datasets ###############\n",
       "\n",
       ".define: &transform !factory:torchvision.transforms:ToTensor@transform []\n",
       "\n",
       ".define: &train_dataset !singleton:torchvision.datasets:FashionMNIST@train_dataset\n",
       "    root: \"data\"\n",
       "    train: True\n",
       "    download: True\n",
       "    transform: *transform\n",
       "\n",
       ".define: &eval_dataset !singleton:torchvision.datasets:FashionMNIST@eval_dataset\n",
       "    root: \"data\"\n",
       "    train: False\n",
       "    download: True\n",
       "    transform: *transform\n",
       "\n",
       "############ Data Collator #############\n",
       "\n",
       ".define: &data_collator null\n",
       "\n",
       "########## Trainer Callbacks ###########\n",
       "\n",
       ".define: &trainer_callbacks []\n",
       "\n",
       "############### Trainer ################\n",
       "\n",
       "# Name: Simple Trainer\n",
       "# Description: A simple trainer class, for illustration purposes.\n",
       "\n",
       "# **Trainer Args**\n",
       "\n",
       ".define: &trainer_args\n",
       "    # Minimal Trainer Defaults\n",
       "    # https://huggingface.co/docs/transformers/en/main_classes/trainer#transformers.TrainingArguments\n",
       "    output_dir: \"./output_models/base_model\"\n",
       "    logging_dir: \"./output_models/base_model/runs/base_model_2024-08-17T01-33-47\"\n",
       "    logging_steps: 500\n",
       "    per_device_train_batch_size: 16\n",
       "    per_device_eval_batch_size: 32\n",
       "    learning_rate: 5e-5\n",
       "    num_train_epochs: 1\n",
       "    \n",
       "    # Fashion MNIST Trainer Overrides\n",
       "    logging_steps: 100\n",
       "    per_device_train_batch_size: 64\n",
       "    per_device_eval_batch_size: 64\n",
       "    learning_rate: 1.0e-3\n",
       "    num_train_epochs: 5\n",
       "\n",
       "# **Trainer Constructor**\n",
       "\n",
       ".define: &trainer !singleton:forgather.ml.simple_trainer:SimpleTrainer@trainer\n",
       "    model: *model\n",
       "    args: !singleton:forgather.ml.trainer_types:MinimalTrainingArguments@trainer_args\n",
       "        <<: *trainer_args\n",
       "    train_dataset: *train_dataset\n",
       "    eval_dataset: *eval_dataset\n",
       "\n",
       "#---------------------------------------\n",
       "#          Configuration Output          \n",
       "#---------------------------------------\n",
       "meta: &meta_output !dict:@meta\n",
       "    config_name: \"Fashion MNIST Trainer\"\n",
       "    config_description: \"Base configuration, based on Torch tutorial parameters.\"\n",
       "    config_class: \"type.training_script.torch_vision\"\n",
       "    project_dir: \".\"\n",
       "    workspace_root: \"/home/dinalt/ai_assets/forgather\"\n",
       "    forgather_dir: \"/home/dinalt/ai_assets/forgather\"\n",
       "    models_dir: \"./output_models\"\n",
       "    tokenizers_dir: \"/home/dinalt/ai_assets/forgather/tokenizers\"\n",
       "    datasets_dir: \"/home/dinalt/ai_assets/forgather/datasets\"\n",
       "    output_dir: \"./output_models/base_model\"\n",
       "    model_src_dir: \"/home/dinalt/ai_assets/forgather/model_src\"\n",
       "    logging_dir: \"./output_models/base_model/runs/base_model_2024-08-17T01-33-47\"\n",
       "    create_new_model: \"True\"\n",
       "    save_model: \"True\"\n",
       "    train: \"True\"\n",
       "    eval: \"False\"\n",
       "\n",
       "main: !singleton:forgather.ml.training_script:TrainingScript@training_script\n",
       "    meta: *meta_output\n",
       "    do_save: True\n",
       "    do_train: True\n",
       "    do_eval: False\n",
       "    # Init distributed envrionment before initializing anyting which depends on it.\n",
       "    distributed_env: *distributed_env\n",
       "    trainer: *trainer\n",
       "    pp_config: !var \"pp_config\"\n",
       "\n",
       "model_code_writer: *model_code_writer\n",
       "distributed_env: *distributed_env\n",
       "model: *model\n",
       "trainer: *trainer\n",
       "train_dataset: *train_dataset\n",
       "eval_dataset: *eval_dataset\n",
       "data_collator: *data_collator\n",
       "trainer_callbacks: *trainer_callbacks\n",
       "\n",
       "```\n",
       "\n",
       "### Config Metadata:\n",
       "\n",
       "```python\n",
       "{'config_class': 'type.training_script.torch_vision',\n",
       " 'config_description': 'Base configuration, based on Torch tutorial '\n",
       "                       'parameters.',\n",
       " 'config_name': 'Fashion MNIST Trainer',\n",
       " 'create_new_model': 'True',\n",
       " 'datasets_dir': '/home/dinalt/ai_assets/forgather/datasets',\n",
       " 'eval': 'False',\n",
       " 'forgather_dir': '/home/dinalt/ai_assets/forgather',\n",
       " 'logging_dir': './output_models/base_model/runs/base_model_2024-08-17T01-33-47',\n",
       " 'model_src_dir': '/home/dinalt/ai_assets/forgather/model_src',\n",
       " 'models_dir': './output_models',\n",
       " 'output_dir': './output_models/base_model',\n",
       " 'project_dir': '.',\n",
       " 'save_model': 'True',\n",
       " 'tokenizers_dir': '/home/dinalt/ai_assets/forgather/tokenizers',\n",
       " 'train': 'True',\n",
       " 'workspace_root': '/home/dinalt/ai_assets/forgather'}\n",
       "\n",
       "```\n",
       "\n",
       "## Modules\n",
       "- [./model_src/mlp_model.py](model_src/mlp_model.py) : MultilayerPerceptron\n",
       "    - [/home/dinalt/ai_assets/forgather/tutorials/project_gamma/./model_src/mlp_model.py](model_src/mlp_model.py) : mlp_model\n",
       "## Output Targets\n",
       "- meta\n",
       "- main\n",
       "- model_code_writer\n",
       "- distributed_env\n",
       "- model\n",
       "- trainer\n",
       "- train_dataset\n",
       "- eval_dataset\n",
       "- data_collator\n",
       "- trainer_callbacks\n",
       "\n",
       "## Generated Code\n",
       "\n",
       "```python\n",
       "from torch.nn import CrossEntropyLoss\n",
       "from forgather.ml.construct import copy_package_files\n",
       "from torchvision.transforms import ToTensor\n",
       "from forgather.ml.distributed import DistributedEnvironment\n",
       "from forgather.ml.construct import dependency_list\n",
       "from forgather.ml.trainer_types import MinimalTrainingArguments\n",
       "from torchvision.datasets import FashionMNIST\n",
       "from forgather.ml.simple_trainer import SimpleTrainer\n",
       "from torch.nn import ReLU\n",
       "from forgather.ml.training_script import TrainingScript\n",
       "from importlib.util import spec_from_file_location, module_from_spec\n",
       "import os\n",
       "import sys\n",
       "\n",
       "# Import a dynamic module.\n",
       "def dynimport(module, name, searchpath):\n",
       "    module_path = module\n",
       "    module_name = os.path.basename(module).split(\".\")[0]\n",
       "    module_spec = spec_from_file_location(\n",
       "        module_name,\n",
       "        module_path,\n",
       "        submodule_search_locations=searchpath,\n",
       "    )\n",
       "    mod = module_from_spec(module_spec)\n",
       "    sys.modules[module_name] = mod\n",
       "    module_spec.loader.exec_module(mod)\n",
       "    for symbol in name.split(\".\"):\n",
       "        mod = getattr(mod, symbol)\n",
       "    return mod\n",
       "\n",
       "MultilayerPerceptron = lambda: dynimport(\"./model_src/mlp_model.py\", \"MultilayerPerceptron\", [])\n",
       "\n",
       "def construct(\n",
       "    pp_config,\n",
       "):\n",
       "    meta = {\n",
       "        'config_name': 'Fashion MNIST Trainer',\n",
       "        'config_description': 'Base configuration, based on Torch tutorial parameters.',\n",
       "        'config_class': 'type.training_script.torch_vision',\n",
       "        'project_dir': '.',\n",
       "        'workspace_root': '/home/dinalt/ai_assets/forgather',\n",
       "        'forgather_dir': '/home/dinalt/ai_assets/forgather',\n",
       "        'models_dir': './output_models',\n",
       "        'tokenizers_dir': '/home/dinalt/ai_assets/forgather/tokenizers',\n",
       "        'datasets_dir': '/home/dinalt/ai_assets/forgather/datasets',\n",
       "        'output_dir': './output_models/base_model',\n",
       "        'model_src_dir': '/home/dinalt/ai_assets/forgather/model_src',\n",
       "        'logging_dir': './output_models/base_model/runs/base_model_2024-08-17T01-33-47',\n",
       "        'create_new_model': 'True',\n",
       "        'save_model': 'True',\n",
       "        'train': 'True',\n",
       "        'eval': 'False',\n",
       "    }\n",
       "\n",
       "    distributed_env = DistributedEnvironment()\n",
       "\n",
       "    activation_factory = lambda: ReLU()\n",
       "\n",
       "    alpha_ = MultilayerPerceptron()(\n",
       "        d_input=784,\n",
       "        d_model=512,\n",
       "        d_output=10,\n",
       "        activation_factory=activation_factory,\n",
       "        loss_fn=CrossEntropyLoss(),\n",
       "    )\n",
       "\n",
       "    model = dependency_list(\n",
       "        alpha_,\n",
       "        copy_package_files(\n",
       "            './output_models/base_model',\n",
       "            alpha_,\n",
       "        ),\n",
       "    )\n",
       "\n",
       "    trainer_args = MinimalTrainingArguments(\n",
       "        output_dir='./output_models/base_model',\n",
       "        logging_dir='./output_models/base_model/runs/base_model_2024-08-17T01-33-47',\n",
       "        logging_steps=100,\n",
       "        per_device_train_batch_size=64,\n",
       "        per_device_eval_batch_size=64,\n",
       "        learning_rate=0.001,\n",
       "        num_train_epochs=5,\n",
       "    )\n",
       "\n",
       "    transform = lambda: ToTensor()\n",
       "\n",
       "    train_dataset = FashionMNIST(\n",
       "        root='data',\n",
       "        train=True,\n",
       "        download=True,\n",
       "        transform=transform(),\n",
       "    )\n",
       "\n",
       "    eval_dataset = FashionMNIST(\n",
       "        root='data',\n",
       "        train=False,\n",
       "        download=True,\n",
       "        transform=transform(),\n",
       "    )\n",
       "\n",
       "    trainer = SimpleTrainer(\n",
       "        model=model,\n",
       "        args=trainer_args,\n",
       "        train_dataset=train_dataset,\n",
       "        eval_dataset=eval_dataset,\n",
       "    )\n",
       "\n",
       "    training_script = TrainingScript(\n",
       "        meta=meta,\n",
       "        do_save=True,\n",
       "        do_train=True,\n",
       "        do_eval=False,\n",
       "        distributed_env=distributed_env,\n",
       "        trainer=trainer,\n",
       "        pp_config=pp_config,\n",
       "    )\n",
       "    \n",
       "    return training_script\n",
       "\n",
       "```\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import forgather.nb.notebooks as nb\n",
    "\n",
    "nb.display_project_index(config_template=\"\", show_available_templates=True, show_pp_config=True, show_generated_code=True, pp_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5eab2-edbe-47e1-b83e-b1858970740e",
   "metadata": {},
   "source": [
    "## Construct Baseline Configuration\n",
    "\n",
    "The \"main\" output is the model trainer, but we also get the model and the test-dataset as auxiliary outputs as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf482ee-2bf6-4a40-bd81-f188a0f1e6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgather.project import Project\n",
    "import forgather.nb.notebooks as nb\n",
    "from pprint import pp\n",
    "\n",
    "# Load default baseline config\n",
    "proj = Project()\n",
    "\n",
    "outputs = proj([\"main\", \"meta\", \"trainer\", \"model\", \"eval_dataset\"])\n",
    "\n",
    "# For easier access...\n",
    "training_script = outputs[\"main\"]\n",
    "project_metadata = outputs[\"meta\"]\n",
    "trainer = outputs[\"trainer\"]\n",
    "model = outputs[\"model\"]\n",
    "eval_dataset = outputs[\"eval_dataset\"]\n",
    "\n",
    "# Print the trainer, as it contains most of the components.\n",
    "pp(trainer)\n",
    "\n",
    "# If present, ignore the warning about missing 'image.so'; we don't use it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb55e6b8-7c2d-402e-8008-4d7f2073e5d6",
   "metadata": {},
   "source": [
    "## Examine Dataset and Predictions\n",
    "\n",
    "We can take a look at what's in the dataset using [Meerkat](http://meerkat.wiki/docs/start/tutorials/tutorial-data-frames.html).\n",
    "\n",
    "The raw images are 32x32 tensors, which we can convert to a greyscale image for rendering with the PIL library.\n",
    "\n",
    "In the table, the \"label\" is the is the ground-truth target the model is expected to predict, while the \"prediction\" is what the model thought the item was.\n",
    "\n",
    "As the model has not yet been trained, it is to be expected that it will fail miserably. We will train the model and then retest it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c343d53c-1ce9-4992-bab8-b31e87875202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import meerkat as mk\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, device, x):\n",
    "    \"\"\"\n",
    "    Given a raw image, get the model's prediction.\n",
    "    \"\"\"\n",
    "    # The image is stored as a 32x32 uint8 Tensor\n",
    "    # Convert to float and add batch dimension\n",
    "    model.to(device)\n",
    "    model_input = (x / 255).unsqueeze(0).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # Get model's prediciton logits for input\n",
    "    logits = model(model_input)\n",
    "\n",
    "    # Get the index for the strongest prediction.\n",
    "    return logits.argmax(1).item()\n",
    "\n",
    "def make_datapanel(eval_dataset, model, device):\n",
    "    # Convert the test dataset's raw images into a Meerkat TensorColumn\n",
    "    raw_img_column = mk.TensorColumn(eval_dataset.data)\n",
    "    \n",
    "    # This maps class indices to names\n",
    "    classes = eval_dataset.classes\n",
    "\n",
    "    # Create DataPanel\n",
    "    dp = mk.DataPanel(\n",
    "        {\n",
    "            # Get label and convert to Python int\n",
    "            \"label\": mk.TensorColumn(eval_dataset.targets).defer(lambda x: classes[x.item()]),\n",
    "            # Lazy model inference; get model's prediction from raw image\n",
    "            \"prediction\": raw_img_column.defer(lambda x: classes[predict(model, device, x)]),\n",
    "            # Lazy conversion of raw images to images\n",
    "            \"image\": raw_img_column.defer(lambda x: Image.fromarray(x.numpy()))\n",
    "        }\n",
    "    )\n",
    "    return dp\n",
    "\n",
    "# Construct the Meerkat DataPanel and display the first 10 cells.\n",
    "dp = make_datapanel(eval_dataset, model, trainer.args.device)\n",
    "\n",
    "# Note: You can change the selected slice to see other ranges of the dataset.\n",
    "dp[:10]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33df259d-4ce8-4a24-9c53-7ecfcef918c5",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "The training-script can be started by calling the \"run()\" method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92a2a9f-bc40-464f-bd1e-f336d52f6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_script.run()\n",
    "\n",
    "# Display this when done training.\n",
    "nb.display_markdown(f\"\"\"\n",
    "### Outputs\n",
    "Note that we have automatically saved a copy of both the config and the model's source code with the weights.\n",
    "- Output Directory: {project_metadata['output_dir']}\n",
    "- Logging Directory: {project_metadata['logging_dir']}\n",
    "- [Saved Model Source]({os.path.join(project_metadata['output_dir'], \"mlp_model.py\")})\n",
    "- [Saved Configuration]({os.path.join(project_metadata['logging_dir'], \"config.yaml\")})\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c39617d-032b-4c2c-93f2-4dc336c80194",
   "metadata": {},
   "source": [
    "### View Training Runs in Tensorboard\n",
    "\n",
    "We have automatically logged the training session to TensorBoard.\n",
    "Run the following cell and go to the provided link to see the results.\n",
    "\n",
    "If the notebook is running on the same machine as the trainer, remove \"--bind_all\"\n",
    "\n",
    "When done, **stop the cell**, as Tensorboard will by running synchronously in the cell and will block execution of other cells.\n",
    "\n",
    "You can run Tensorboard in a terminal or in another notebook to avoid blocking this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6f5c3-0834-4af2-add9-9fe89a43db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --bind_all --logdir \"{project_metadata['models_dir']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38cd550-ac32-4dcb-ad2e-e6e5c94135ed",
   "metadata": {},
   "source": [
    "### Test the Trained Model\n",
    "\n",
    "We will display the same 10 data-cells as before, but now that the model has been trained, it's much less awful at the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccffa4f-d932-441d-b906-8fe30fd921ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp[:10]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd1717-cf76-4661-a9ae-68df074acf06",
   "metadata": {},
   "source": [
    "## Construct and Train with Adam Optimizer\n",
    "\n",
    "We hava an alternate configuration, where the original SGD optimizer is replaced with Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448a90cd-e419-490b-a8b6-278cfef3e168",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.display_project_index(config_template=\"adam.yaml\", show_pp_config=True, show_generated_code=True, pp_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9131188-a9a2-46c4-84a9-3e207e194e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgather.project import Project\n",
    "import forgather.nb.notebooks as nb\n",
    "from pprint import pp\n",
    "\n",
    "proj = Project(config_name=\"adam.yaml\")\n",
    "outputs = proj([\"main\", \"meta\", \"trainer\", \"model\", \"eval_dataset\"])\n",
    "\n",
    "# For easier access...\n",
    "training_script = outputs[\"main\"]\n",
    "project_metadata = outputs[\"meta\"]\n",
    "trainer = outputs[\"trainer\"]\n",
    "model = outputs[\"model\"]\n",
    "eval_dataset = outputs[\"eval_dataset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d204bc33-1c69-42ff-ab1b-c374eecd4c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_script.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdcb66-1494-498d-a34d-ff87f21c9354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regenerate the DataPanel and show predictions.\n",
    "dp = make_datapanel(eval_dataset, model, trainer.args.device)\n",
    "dp[:10]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb9c6f0-5a3d-445f-82d5-0ef56927c6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
