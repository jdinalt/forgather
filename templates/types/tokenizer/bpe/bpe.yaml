-- extends 'types/tokenizer/tokenizer.yaml'

-- block config_metadata
    == super()
    -- set ns.config_name = "Custom BPE Tokenizer"
    -- set ns.config_description = "A custom BPE tokenizer definition."
    ## -- set ns.dataset_id = 'dataset_id'
    ## -- set ns.output_dir = path_join(ns.tokenizers_dir, 'custom_tokenizer')
-- endblock config_metadata


-- block tokenizer_trainer
    == super()
    model: !callable:tokenizers:models.BPE
        cache_capacity: 16
        unk_token: "{{ ns.unk_token }}"
        byte_fallback: True
    normalizer: !callable:tokenizers:normalizers.NFC []
    pre_tokenizer: !callable:tokenizers:pre_tokenizers.ByteLevel []
    decoder: !callable:tokenizers:decoders.ByteLevel []
    # Automatically add bos token to sequence start
    post_processor: !callable:tokenizers:processors.TemplateProcessing
        single: "<bos> $A"
        special_tokens: [ !tuple [ "<bos>", {{ ns.bos_token_id }} ] ]
    trainer: !callable:tokenizers.trainers:BpeTrainer
        vocab_size: {{ ns.vocab_size }}
        initial_alphabet: !callable:tokenizers:pre_tokenizers.ByteLevel.alphabet []
        special_tokens: !callable:forgather.construct:values [ *special_tokens_map ]
        show_progress: False
<< endblock tokenizer_trainer