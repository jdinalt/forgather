-- set datasets_ns = namespace()
-- from 'inc/formatting.jinja' import h3
-- filter trim()

-- block datasets_meta_config
-- set datasets_ns.train_dataset_split = "train"
-- set datasets_ns.eval_dataset_split = "validation"
## The callable used for loading
-- set datasets_ns.train_load_method = "datasets:load_dataset"
-- set datasets_ns.eval_load_method = "datasets:load_dataset"
## The following args are required
## -- set datasets_ns.train_dataset_id = "dataset_id_or_path"
## -- set datasets_ns.eval_dataset_id = "dataset_id_or_path"
-- endblock datasets_meta_config

## Alias train dataset, if they are the same?
## As long as there are no other references to the eval dataset,
## it will be eliminated when the "dot-keys" are stripped.
-- if datasets_ns.train_dataset_id == datasets_ns.eval_dataset_id
    -- set datasets_ns.eval_source_dataset_name = "train_source_dataset"
-- else
    -- set datasets_ns.eval_source_dataset_name = "eval_source_dataset"
-- endif

-- endfilter
-- block datasets_header
# Train Dataset: "{{ datasets_ns.train_dataset_id }}" : "{{ datasets_ns.train_dataset_split }}"
# Eval Dataset: "{{ datasets_ns.eval_dataset_id }}" : "{{ datasets_ns.eval_dataset_id }}"
<< endblock datasets_header


== h3('Source Datasets')

-- filter trim()
-- block load_train_dataset
.define: &train_source_dataset !callable:{{datasets_ns.train_load_method}}
    args:
        - "{{ datasets_ns.train_dataset_id }}"
<< endblock load_train_dataset
-- endfilter

-- filter trim()

-- block load_eval_dataset
.define: &eval_source_dataset !callable:{{datasets_ns.eval_load_method}}
    args:
        - "{{ datasets_ns.eval_dataset_id }}"
<< endblock load_eval_dataset
-- endfilter


== h3('Dataset Splits')

-- filter trim()
-- block dataset_splits
.define: &train_dataset_split !callable:forgather.construct:get_item
    - *train_source_dataset
    - "{{ datasets_ns.train_dataset_split }}"

.define: &eval_dataset_split !callable:forgather.construct:get_item
    - *{{ datasets_ns.eval_source_dataset_name }}
    - "{{ datasets_ns.eval_dataset_split }}"
<< endblock dataset_splits
-- endfilter


== h3('Tokenized Datasets')

-- filter trim()
-- block datasets
.define: &train_dataset !callable:aiws.datasets:tokenize_dataset
    dataset: *train_dataset_split
    tokenizer: *tokenizer

.define: &eval_dataset !callable:aiws.datasets:tokenize_dataset
    dataset: *eval_dataset_split
    tokenizer: *tokenizer
<< endblock datasets
-- endfilter