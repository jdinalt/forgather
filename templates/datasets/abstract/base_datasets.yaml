-- set datasets_ns = namespace()
-- from 'inc/formatting.jinja' import h3
-- filter trim()

-- block datasets_meta_config
-- set datasets_ns.name = "Undefined"
-- set datasets_ns.description = ""
-- set datasets_ns.source = ""
-- set datasets_ns.train_dataset_split = "train"
-- set datasets_ns.eval_dataset_split = "validation"
## The callable used for loading
-- set datasets_ns.train_load_method = "datasets:load_dataset"
-- set datasets_ns.eval_load_method = "datasets:load_dataset"
-- set datasets_ns.train_select_range = "null"
-- set datasets_ns.eval_select_range = "null"
## The following args are required
## -- set datasets_ns.train_dataset_id = "dataset_id_or_path"
## -- set datasets_ns.eval_dataset_id = "dataset_id_or_path"
-- endblock datasets_meta_config

## Alias train dataset, if they are the same?
## As long as there are no other references to the eval dataset,
## it will be eliminated when the "dot-keys" are stripped.
-- if datasets_ns.train_dataset_id == datasets_ns.eval_dataset_id
    -- set datasets_ns.eval_source_dataset_name = "train_source_dataset"
-- else
    -- set datasets_ns.eval_source_dataset_name = "eval_source_dataset"
-- endif

-- endfilter
-- block datasets_header
# Name: {{ datasets_ns.name }}
# Define: {{ datasets_ns.description }}
# Source: {{ datasets_ns.source }}
# Train Dataset: "{{ datasets_ns.train_dataset_id }}" : "{{ datasets_ns.train_dataset_split }}"
# Eval Dataset: "{{ datasets_ns.eval_dataset_id }}" : "{{ datasets_ns.eval_dataset_split }}"
<< endblock datasets_header


== h3('Source Datasets')

-- filter trim()
-- block load_train_dataset
.define: &train_source_dataset !callable:{{datasets_ns.train_load_method}}
    args:
        - "{{ datasets_ns.train_dataset_id }}"
<< endblock load_train_dataset
-- endfilter


-- filter trim()

-- block load_eval_dataset
.define: &eval_source_dataset !callable:{{datasets_ns.eval_load_method}}
    args:
        - "{{ datasets_ns.eval_dataset_id }}"
<< endblock load_eval_dataset
-- endfilter


== h3('Dataset Splits')

-- filter trim()
-- block dataset_splits
.define: &train_dataset_split !callable:forgather.construct:get_item
    - *train_source_dataset
    - "{{ datasets_ns.train_dataset_split }}"

.define: &eval_dataset_split !callable:forgather.construct:get_item
    - *{{ datasets_ns.eval_source_dataset_name }}
    - "{{ datasets_ns.eval_dataset_split }}"
<< endblock dataset_splits
-- endfilter


== h3('Tokenize Args')

-- filter trim()
-- block tokenize_args
## See: https://huggingface.co/docs/transformers/main_classes/tokenizer
.define: &tokenize_args
    truncation: True
<< endblock tokenize_args
-- endfilter


== h3('Tokenized Datasets')

-- filter trim()
-- block datasets
    -- filter trim()
    -- block tokenize_train
.define: &train_dataset !callable:aiws.datasets:tokenize_dataset
    dataset: *train_dataset_split
    tokenizer: *tokenizer
    select_range: {{ datasets_ns.train_select_range }}
    desc: "{{ "Tokenizing " + datasets_ns.train_dataset_split }}"
    fn_kwargs:
        <<: *tokenize_args
    << endblock tokenize_train
    -- endfilter


    -- filter trim()
    -- block tokenize_eval
.define: &eval_dataset !callable:aiws.datasets:tokenize_dataset
    dataset: *eval_dataset_split
    tokenizer: *tokenizer
    select_range: {{ datasets_ns.eval_select_range }}
    desc: "{{ "Tokenizing " + datasets_ns.eval_dataset_split + " split" }}"
    fn_kwargs:
        <<: *tokenize_args
    << endblock tokenize_eval
    -- endfilter
<< endblock datasets
-- endfilter