##
## Loads a single pre-tokenized dataset from disk
##
-- set datasets_def = namespace()
-- from 'inc/formatting.jinja' import h2, h3, sep
-- filter trim()
-- block datasets_meta_config
    -- set datasets_def.name = "Local Dataset"
    -- set datasets_def.description = "Load a pretokenized dataset from a local file-system"
    -- set datasets_def.dataset_train_split = "train"
    -- set datasets_def.dataset_validation_split = "validation"
    ## Define the following variables
    ##  -- set datasets_def.dataset_name_or_path = "<local path to dataset or hub id>"
<< endblock datasets_meta_config

-- endfilter ## trim
-- filter trim()
-- block datasets_header
# Name: {{ datasets_def.name }}
# Description: {{ datasets_def.description }}

# datasets_def.dataset_name_or_path = "{{ datasets_def.dataset_name_or_path }}"
# datasets_def.dataset_train_split = "{{ datasets_def.dataset_train_split }}"
# datasets_def.dataset_validation_split = "{{ datasets_def.dataset_validation_split }}"
<< endblock datasets_header
-- endfilter


== h3('Load Datasets')

-- filter trim()
-- block datasets_loader
.define: &dataset !singleton:datasets:load_from_disk [ "{{ datasets_def.dataset_name_or_path }}" ]
<< endblock datasets_loader
-- endfilter


== h3('Get Splits')

-- filter trim()
-- block datasets_splits
.define: &train_dataset !singleton:operator:getitem [ *dataset, "{{ datasets_def.dataset_train_split }}" ]
.define: &eval_dataset !singleton:operator:getitem [ *dataset, "{{ datasets_def.dataset_validation_split }}" ]
<< endblock datasets_splits
-- endfilter