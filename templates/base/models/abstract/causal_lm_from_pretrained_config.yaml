## Given an id-or-path, construct a newly initialized model from that config.
## This can be substituted for "load_model.yaml" to construct a model from
## a configuration, without loading the weights. This can be useful for 
## constructing the model on the "meta" device for inspection or for
## customizing how the weights are loaded.
-- extends 'models/abstract/base_language_model.yaml'

-- block model_meta_config
    == super()
    -- set model_def.name = "Causal Language Model from Pretrained Config"
    -- set model_def.description = "A newly initialized model from a pretrained config model id-or-path."
    -- set model_def.source = ""
    -- set model_def.model_id_or_path = ns.output_dir
<< endblock model_meta_config


-- block model_header
    == super()

# model_def.model_id_or_path = "{{ model_def.model_id_or_path }}"
<< endblock model_header


-- block model_tokenizer
tokenizer: &tokenizer !singleton:transformers:AutoTokenizer.from_pretrained@tokenizer
    - "{{ model_def.model_id_or_path }}"
<< endblock model_tokenizer


-- block model_config
model_config: &model_config !singleton:transformers:AutoConfig.from_pretrained@model_config
    args: [ "{{ model_def.model_id_or_path }}" ]
    kwargs:
    -- if ns.trust_remote_code
        trust_remote_code: True
    -- endif
<< endblock model_config


-- block model_constructor
# Custom transformer model; registers for AutoClass and will save code with weights.
model: &model !lambda:transformers:AutoModelForCausalLM.from_config@model
    args:
        - *model_config
    kwargs:
        <<: *model_constructor_args
<< endblock model_constructor