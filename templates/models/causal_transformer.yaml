-- extends 'models/abstract/custom_causal_lm.yaml'

-- block model_meta_config
    == super()
    -- set model_def.name = "Causal Transformer"
    -- set model_def.description = "A causal transformer model, based upon 'Attention is All You Need'"
    -- set model_def.cls = 'CausalTransformer'
    -- set model_def.cfg_cls = 'CausalTransformerConfig'
    -- set model_def.config_path = joinpath(ns.model_src_dir, 'causal_transformer.py')
    -- set model_def.model_path = model_def.config_path
-- endblock model_meta_config


-- block model_tokenizer
    -- include 'tokenizers/tiny_2k.yaml'
<< endblock model_tokenizer


-- block model_config
    == super()
    max_sequence_length: !singleton:getattr [ *tokenizer, 'model_max_length' ]
<< endblock model_config


-- block model_submodule_searchpath
# Add 'bits' to model's module.
.define: &model_submodule_searchpath
    - "{{ joinpath(ns.forgather_dir, 'model_src', 'bits', 'transformer') }}"
<< endblock model_submodule_searchpath