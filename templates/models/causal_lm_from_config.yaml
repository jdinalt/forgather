-- extends 'models/base_language_model.yaml'

-- block model_meta_config
    == super()
    -- set model_def.name = "HF Language Model"
    -- set model_def.description = "A newly initialized HF language model"
    -- set model_def.source = ""
    ## Define the following variables
##  -- set model_def.model_config_id = '<model configuration class>'
##  -- set model_def.tokenizer_path_or_id = '<path to existing tokenizer>'
##  -- set model_def.source = 'URI or other info'
<< endblock model_meta_config


-- block model_header
    == super()

# model_def.model_config_id = "{{ model_def.model_config_id }}"
# model_def.tokenizer_path_or_id = "{{ model_def.tokenizer_path_or_id }}"
<< endblock model_header


-- block model_tokenizer
# Load a tokenizer from a file or hub id
.define: &tokenizer !callable:transformers:AutoTokenizer.from_pretrained
    - "{{ model_def.tokenizer_path_or_id }}"
<< endblock model_tokenizer


-- block model_config
.define: &model_config !callable:transformers:AutoConfig.from_pretrained
    args:
        - "{{ model_def.model_config_id }}"
    kwargs:
        vocab_size: !callable:forgather.construct:length [ *tokenizer ]
<< endblock model_config


-- block model_constructor
# Custom transformer model; registers for AutoClass and will save code with weights.
.define: &model !callable:transformers:AutoModelForCausalLM.from_config
    args:
        - *model_config
    kwargs:
        <<: *model_constructor_args
<< endblock model_constructor