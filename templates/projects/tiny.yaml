## This is an example of a project template; useful where similar configurations
## may be used in multiple projects.
##
## Specifically, this sets up training for a very small model over one epoch
## on the 'abridged' version of the Tiny Stories dataset.
-- extends "types/training_script/causal_lm/causal_lm.yaml"


## Setup base directories for the example projects
-- block base_directories
    -- set ns.forgather_dir = normpath(joinpath(project_dir, '..', '..', '..'))
    -- include 'paths/example_paths.yaml'
-- endblock base_directories


-- block config_metadata
    == super()
    ## Overrides
    -- set ns.config_name = "Tiny Experiments"
    -- set ns.config_description = "A project template for running tiny model experiments."
    ## Defines
    -- set ns.trainer_class = 'trainers/trainer.yaml'
    ## We make use of custom models in these projects
    -- set ns.trust_remote_code = True
-- endblock config_metadata


-- block pre_model_setup
    ## Add assets needed for text-gen sampling.
    ## This adds a set of prompts and text-gen parameters.
    == super()
    -- include "prompts/tiny_stories.yaml"
-- endblock pre_model_setup


-- block datasets_definition
    ## Note: Switch to 'datasets/tiny/tiny_stories.yaml' for the full dataset.
    -- include 'datasets/tiny/tiny_stories_abridged.yaml'
-- endblock datasets_definition


## Defaults to the basic trainer implementation
## Note: This is unsuitable for multiple GPUs.
## Override 'ns.trainer_class' to change the trainer class.
-- block trainer_definition
    ## See definition below
    -- include 'tiny.trainer_config'
-- endblock trainer_definition


-- block construct_new_model
    ## See definition below
    -- include 'tiny.model_config'
-- endblock construct_new_model


-- block trainer_callbacks
    ## See definition below
    -- include 'tiny.callbacks'
<< endblock trainer_callbacks


#-------------------- tiny.trainer_config --------------------
-- extends ns.trainer_class
## Note: We use dynamic inheritance for the trainer-class
## This has a side effect of not being able to statically resolve the
## parent template, which is named in the 'ns.trainer_class' variable,
## the value of which is defined in the 'config_metadata' block, above.

## Set sane trainer defaults for 'tiny' projects.
-- block trainer_meta_config
    == super()
    -- set trainer_def.name = "Custom " + trainer_def.name
-- endblock trainer_meta_config


-- block trainer_args
    == super()
    # Tiny Project Overrides
    per_device_train_batch_size: 32
    per_device_eval_batch_size: 64
    logging_steps: 100
    eval_steps: 500
    learning_rate: 1.0e-3
    num_train_epochs: 1
    lr_scheduler_type: "cosine"
-- endblock trainer_args

#-------------------- tiny.model_config --------------------
-- extends 'models/tiny/tiny_causal.yaml'
## Default to tiny-causal model definition.


#-------------------- tiny.callbacks --------------------
-- extends 'callbacks/loggers.yaml'
## Add experiment loggers to the callbacks list.
## The parent creates a Tensor Board SummaryWriter, which we can use.

-- block callback_dependencies
    == super()

    -- filter trim()
    -- block text_gen_callback_args
.define: &text_gen_callback_args
    summary_writer: *summary_writer
    prompts: *testprompts
    generation_config: *generation_config
    max_new_tokens: 40
    generation_steps: 2000
    << endblock text_gen_callback_args
    -- endfilter
<< endblock callback_dependencies

## This adds a text-generationn sample every 'generation_steps'
-- block callback_list
    == super()
    - !singleton:forgather.ml.textgen_callback:TextgenCallback
        <<: *text_gen_callback_args
<< endblock callback_list